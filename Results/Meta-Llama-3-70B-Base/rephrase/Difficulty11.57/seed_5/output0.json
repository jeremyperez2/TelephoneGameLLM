{
    "adjacency_matrix": [
        [
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0
        ]
    ],
    "prompt_init": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "prompt_update": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "personality_list": [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        ""
    ],
    "format_prompt": [
        ""
    ],
    "initial_story": "having the potential for high speed, high throughput, and low energy cost,optical neural networks (onns) have emerged as a promising candidate foraccelerating deep learning tasks. in conventional onns, light amplitudes aremodulated at the input and detected at the output. however, the light phasesare still ignored in conventional structures, although they can also carryinformation for computing. to address this issue, in this paper, we propose aframework called oplixnet to compress the areas of onns by modulating inputimage data into the amplitudes and phase parts of light signals. the input andoutput parts of the onns are redesigned to make full use of both amplitude andphase information. moreover, mutual learning across different onn structures isintroduced to maintain the accuracy. experimental results demonstrate that theproposed framework significantly reduces the areas of onns with the accuracywithin an acceptable range. for instance, 75.03% area is reduced with a 0.33%accuracy decrease on fully connected neural network (fcnn) and 74.88% area isreduced with a 2.38% accuracy decrease on resnet-32. ",
    "stories": [
        [
            "Optical neural networks (ONNs) are emerging as a promising candidate for accelerating deep learning tasks due to their potential for high speed, high throughput, and low energy cost. Conventional ONNs use light amplitudes to modulate the input and detect the output, but they ignore the light phases, which can also carry information for computing. In this paper, we propose a framework called OPLIXNET to compress the areas of ONNs by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32."
        ],
        [
            "Optical Neural Networks (ONNs) are emerging as a promising candidate for accelerating deep learning tasks due to their potential for high speed, high throughput, and low energy cost. Conventional ONNs use light amplitudes to modulate the input and detect the output, but they ignore the light phases, which can also carry information for computing. In this paper, we propose a framework called OPLIXNET to compress the areas of ONNs by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32."
        ],
        [
            "In this paper, we propose a framework called OPLIXNET to compress the areas of Optical Neural Networks (ONNs) by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32."
        ],
        [
            "In this paper, we suggest a framework called OPLIXNET to decrease the size of Optical Neural Networks (ONNs) by adjusting input image data into the intensities and phase components of light signals. The input and output sections of the ONNs are redesigned to make complete use of both intensity and phase information. In addition, mutual learning across different ONN structures is applied to preserve the accuracy. Experimental results prove that the proposed framework greatly reduces the size of ONNs with the accuracy within an acceptable range. For example, 75.03% size is reduced with a 0.33% accuracy reduction on fully connected neural network (FCNN) and 74.88% size is reduced with a 2.38% accuracy reduction on ResNet-32."
        ],
        [
            "In this study, we suggest an approach called OPLIXNET to minimize the dimensionality of Optical Neural Networks (ONNs) by transforming input image data into the intensities and phase components of light signals. The input and output segments of the ONNs are redesigned to make full utilization of both intensity and phase information. Moreover, mutual learning across diverse ONN structures is implemented to maintain the precision. Experimental outcomes demonstrate that the proposed approach significantly decreases the dimensionality of ONNs while maintaining the precision within a reasonable range. For instance, 75.03% dimensionality is reduced with a 0.33% precision reduction on fully connected neural network (FCNN) and 74.88% dimensionality is reduced with a 2.38% precision reduction on ResNet-32."
        ],
        [
            "In this study, we present an approach called OPLIXNET to reduce the dimensionality of Optical Neural Networks (ONNs) by converting input image data into the intensities and phase components of light signals. The input and output segments of the ONNs are redesigned to fully utilize both intensity and phase information. Moreover, mutual learning across different ONN structures is implemented to maintain the precision. Experimental outcomes demonstrate that the proposed approach significantly reduces the dimensionality of ONNs while maintaining the precision within a reasonable range. For example, 75.03% dimensionality is reduced with a 0.33% precision reduction on fully connected neural network (FCNN) and 74.88% dimensionality is reduced with a 2.38% precision reduction on ResNet-32."
        ],
        [
            "In this study, we present an approach called OPLIXNET to reduce the dimensionality of Optical Neural Networks (ONNs) by converting input image data into the intensities and phase components of light signals. The input and output segments of the ONNs are redesigned to fully utilize both intensity and phase information. Moreover, mutual learning across different ONN structures is implemented to maintain the precision. Experimental outcomes demonstrate that the proposed approach significantly reduces the dimensionality of ONNs while maintaining the precision within a reasonable range. For example, 75.03% dimensionality is reduced with a 0.33% precision reduction on fully connected neural network (FCNN) and 74.88% dimensionality is reduced with a 2.38% precision reduction on ResNet-32."
        ],
        [
            "In this study, we introduce a new approach called OPLIXNET that can reduce the dimensionality of Optical Neural Networks (ONNs). This is done by transforming input image data into the intensities and phase components of light signals. The input and output segments of the ONNs are modified to make use of both intensity and phase information. Additionally, mutual learning across different ONN structures is implemented to preserve the precision. The experimental results show that the proposed approach can significantly reduce the dimensionality of ONNs while preserving the precision within a reasonable range. For example, 75.03% dimensionality is reduced with a 0.33% precision reduction on fully connected neural network (FCNN) and 74.88% dimensionality is reduced with a 2.38% precision reduction on ResNet-32."
        ],
        [
            "In this study, we present a novel approach called OPLIXNET that can reduce the dimensionality of Optical Neural Networks (ONNs) by transforming input image data into the intensities and phase components of light signals. The input and output segments of the ONNs are modified to utilize both intensity and phase information. Mutual learning is also employed to maintain the precision across different ONN structures. The experimental results demonstrate that the proposed approach can considerably reduce the dimensionality of ONNs while preserving the precision within an acceptable range. Specifically, 75.03% dimensionality is reduced with a 0.33% precision reduction on a fully connected neural network (FCNN) and 74.88% dimensionality is reduced with a 2.38% precision reduction on ResNet-32."
        ],
        [
            "We introduce a novel approach named OPLIXNET for reducing the dimensionality of Optical Neural Networks (ONNs) through converting input image data into light signal intensities and phases. The input and output segments of the ONNs are modified to make use of both intensity and phase information. Mutual learning is also used to maintain the precision across different ONN structures. Experimental results show that the proposed approach can substantially reduce the dimensionality of ONNs while keeping the precision within an acceptable range. Specifically, 75.03% dimensionality is reduced with a 0.33% precision reduction on a fully connected neural network (FCNN) and 74.88% dimensionality is reduced with a 2.38% precision reduction on ResNet-32."
        ],
        [
            "We introduce a novel approach named OPLIXNET for reducing the dimensionality of Optical Neural Networks (ONNs) by converting input image data into light signal intensities and phases. The input and output segments of the ONNs are modified to make use of both intensity and phase information. Mutual learning is also used to maintain the precision across different ONN structures. Experimental results show that the proposed approach can substantially reduce the dimensionality of ONNs while keeping the precision within an acceptable range. Specifically, 75.03% dimensionality is reduced with a 0.33% precision reduction on a fully connected neural network (FCNN) and 74.88% dimensionality is reduced with a 2.38% precision reduction on ResNet-32."
        ],
        [
            "We propose a novel approach called OPLIXNET for reducing the dimensionality of Optical Neural Networks (ONNs). We convert the input image data into light signal intensities and phases, and modify the input and output segments of the ONNs to make use of both intensity and phase information. Mutual learning is used to maintain the precision across different ONN structures. Our experimental results show that the proposed approach can substantially reduce the dimensionality of ONNs while keeping the precision within an acceptable range. Specifically, 75.03% dimensionality is reduced with a 0.33% precision reduction on a fully connected neural network (FCNN) and 74.88% dimensionality is reduced with a 2.38% precision reduction on ResNet-32."
        ],
        [
            "In this paper, we present a novel approach to reducing the dimensionality of Optical Neural Networks (ONNs). We transform the input image data into light signal intensities and phases, and modify the input and output segments of the ONNs to make use of both intensity and phase information. Mutual learning is used to maintain the precision across different ONN structures. Our experimental results show that the proposed approach can substantially reduce the dimensionality of ONNs while keeping the precision within an acceptable range. Specifically, 75.03% dimensionality is reduced with a 0.33% precision reduction on a fully connected neural network (FCNN) and 74.88% dimensionality is reduced with a 2.38% precision reduction on ResNet-32."
        ],
        [
            "In this paper, we present a novel approach to reducing the dimensionality of Optical Neural Networks (ONNs). We transform the input image data into light signal intensities and phases, and modify the input and output segments of the ONNs to make use of both intensity and phase information. Mutual learning is used to maintain the precision across different ONN structures. Our experimental results show that the proposed approach can substantially reduce the dimensionality of ONNs while keeping the precision within an acceptable range. Specifically, 75.03% dimensionality is reduced with a 0.33% precision reduction on a fully connected neural network (FCNN) and 74.88% dimensionality is reduced with a 2.38% precision reduction on ResNet-32."
        ],
        [
            "In this paper, we propose a novel approach to reduce the size of optical neural networks (ONNs). We represent the input data as light signals with intensities and phases, and modify the input and output segments of the ONNs to use both intensity and phase information. To keep the accuracy across different ONN structures, we use mutual learning. Our experiments show that the proposed method can significantly reduce the size of ONNs while keeping the accuracy within a reasonable range. Specifically, 75.03% of the size is reduced with a 0.33% accuracy reduction on a fully connected neural network (FCNN) and 74.88% of the size is reduced with a 2.38% accuracy reduction on ResNet-32."
        ],
        [
            "In this paper, we present a new method for reducing the size of optical neural networks (ONNs). We represent the input data as light signals with intensities and phases, and modify the input and output segments of the ONNs to use both intensity and phase information. To keep the accuracy across different ONN structures, we use mutual learning. Our experiments show that the proposed method can significantly reduce the size of ONNs while keeping the accuracy within a reasonable range. Specifically, 75.03% of the size is reduced with a 0.33% accuracy reduction on a fully connected neural network (FCNN) and 74.88% of the size is reduced with a 2.38% accuracy reduction on ResNet-32."
        ],
        [
            "This paper proposes a novel approach to reduce the size of optical neural networks (ONNs). The proposed method represents the input data as light signals with intensities and phases and modifies the input and output segments of ONNs to use both intensity and phase information. To maintain the accuracy across different ONN structures, mutual learning is employed. The results of the experiments demonstrate that the proposed method can significantly reduce the size of ONNs while maintaining the accuracy within a reasonable range. Specifically, 75.03% of the size is reduced with a 0.33% accuracy reduction on a fully connected neural network (FCNN), and 74.88% of the size is reduced with a 2.38% accuracy reduction on ResNet-32."
        ],
        [
            "This paper proposes a novel approach to reduce the size of optical neural networks (ONNs). The proposed method represents the input data as light signals with intensities and phases and modifies the input and output segments of ONNs to use both intensity and phase information. To maintain the accuracy across different ONN structures, mutual learning is employed. The results of the experiments demonstrate that the proposed method can significantly reduce the size of ONNs while maintaining the accuracy within a reasonable range. Specifically, 75.03% of the size is reduced with a 0.33% accuracy reduction on a fully connected neural network (FCNN), and 74.88% of the size is reduced with a 2.38% accuracy reduction on ResNet-32."
        ],
        [
            "This paper presents a new approach to reduce the size of optical neural networks (ONNs). The proposed method encodes input data as light signals with intensities and phases, and modifies the input and output segments of ONNs to exploit both intensity and phase information. To ensure accuracy across different ONN architectures, mutual learning is used. Experimental results demonstrate that the proposed method can significantly reduce the size of ONNs while maintaining accuracy within a reasonable range. Specifically, 75.03% of the size is reduced with a 0.33% accuracy reduction on a fully connected neural network (FCNN), and 74.88% of the size is reduced with a 2.38% accuracy reduction on ResNet-32."
        ],
        [
            "This paper proposes a novel technique to reduce the dimensions of optical neural networks (ONNs). The proposed technique encodes input data as light signals with intensities and phases, and modifies the input and output layers of ONNs to leverage both intensity and phase information. To ensure accuracy across various ONN architectures, mutual learning is employed. Experimental results demonstrate that the proposed technique can substantially decrease the dimensions of ONNs while maintaining accuracy within a reasonable range. Specifically, 75.03% of the dimensions are reduced with a 0.33% accuracy reduction on a fully connected neural network (FCNN), and 74.88% of the dimensions are reduced with a 2.38% accuracy reduction on ResNet-32."
        ],
        [
            "In this paper, we introduce a novel method for reducing the dimensionality of optical neural networks (ONNs). The proposed technique encodes input data as light signals with intensities and phases, and modifies the input and output layers of ONNs to take advantage of both intensity and phase information. Mutual learning is used to ensure accuracy across different ONN architectures. Experimental results show that the proposed technique can significantly reduce the dimensions of ONNs while maintaining accuracy within a reasonable range. Specifically, 75.03% of the dimensions are reduced with a 0.33% accuracy reduction on a fully connected neural network (FCNN), and 74.88% of the dimensions are reduced with a 2.38% accuracy reduction on ResNet-32."
        ],
        [
            "In this paper, we present a novel approach for reducing the complexity of optical neural networks (ONNs). The technique involves encoding input data as light signals with intensities and phases, and then modifying the input and output layers of ONNs to take advantage of both intensity and phase information. Mutual learning is employed to ensure accuracy across different ONN architectures. Experimental results show that the proposed technique can significantly reduce the dimensions of ONNs while maintaining accuracy within a reasonable range. Specifically, 75.03% of the dimensions are reduced with a 0.33% accuracy reduction on a fully connected neural network (FCNN), and 74.88% of the dimensions are reduced with a 2.38% accuracy reduction on ResNet-32."
        ],
        [
            "In this study, we suggest a new method to simplify the structure of optical neural networks. The method involves representing the input data as light signals with different intensities and phases, and then changing the input and output layers of the networks to use both intensity and phase information. Mutual learning is used to make sure that the accuracy is the same across different types of optical neural networks. The results of the experiments show that the proposed method can reduce the size of the networks by a significant amount without reducing the accuracy too much. In particular, 75.03% of the dimensions are reduced with a 0.33% accuracy reduction on a fully connected neural network (FCNN), and 74.88% of the dimensions are reduced with a 2.38% accuracy reduction on ResNet-32."
        ],
        [
            "In this paper, we introduce a new method for simplifying the architecture of optical neural networks. This method involves encoding the input data as light signals with varying intensities and phases, and then adjusting the input and output layers of the networks to utilize both intensity and phase information. Mutual learning is employed to ensure that the accuracy is maintained across different types of optical neural networks. The experimental results show that the proposed method can significantly reduce the size of the networks without compromising the accuracy. In particular, the method achieves a reduction in dimensions of 75.03% with only a 0.33% reduction in accuracy on a fully connected neural network (FCNN), and a reduction in dimensions of 74.88% with a 2.38% reduction in accuracy on ResNet-32."
        ],
        [
            "This paper proposes a new method to reduce the complexity of optical neural networks. The method encodes input data as light signals with varying intensities and phases, and modifies the input and output layers to utilize both types of information. Mutual learning ensures accuracy is maintained across different types of optical neural networks. Experimental results show the proposed method can significantly reduce the size of the networks without compromising accuracy. The method achieves a 75.03% reduction in dimensions with only a 0.33% reduction in accuracy on a fully connected neural network (FCNN), and a 74.88% reduction in dimensions with a 2.38% reduction in accuracy on ResNet-32."
        ],
        [
            "The proposed method of this paper is to reduce the complexity of optical neural networks by encoding input data as light signals with varying intensities and phases. Additionally, the input and output layers are modified to take advantage of this type of information. To ensure accuracy is maintained across different types of optical neural networks, mutual learning is employed. Experimental results show that the proposed method can significantly reduce the size of the networks without sacrificing accuracy. For example, on a fully connected neural network (FCNN), the method achieved a 75.03% reduction in dimensions with only a 0.33% reduction in accuracy. Similarly, on ResNet-32, the method achieved a 74.88% reduction in dimensions with a 2.38% reduction in accuracy."
        ],
        [
            "The proposed method of this paper is to reduce the complexity of optical neural networks by encoding input data as light signals with varying intensities and phases. Additionally, the input and output layers are modified to take advantage of this type of information. To ensure accuracy is maintained across different types of optical neural networks, mutual learning is employed. Experimental results show that the proposed method can significantly reduce the size of the networks without sacrificing accuracy. For example, on a fully connected neural network (FCNN), the method achieved a 75.03% reduction in dimensions with only a 0.33% reduction in accuracy. Similarly, on ResNet-32, the method achieved a 74.88% reduction in dimensions with a 2.38% reduction in accuracy."
        ],
        [
            "The proposed method of this paper is to reduce the complexity of optical neural networks by encoding input data as light signals with varying intensities and phases. Additionally, the input and output layers are modified to take advantage of this type of information. To ensure accuracy is maintained across different types of optical neural networks, mutual learning is employed. Experimental results show that the proposed method can significantly reduce the size of the networks without sacrificing accuracy. For example, on a fully connected neural network (FCNN), the method achieved a 75.03% reduction in dimensions with only a 0.33% reduction in accuracy. Similarly, on ResNet-32, the method achieved a 74.88% reduction in dimensions with a 2.38% reduction in accuracy."
        ],
        [
            "The proposed method of this paper aims to simplify optical neural networks by representing input data as light signals with varying strengths and directions. To take full advantage of this approach, we also make changes to the input and output layers. To ensure consistent accuracy across various types of optical neural networks, we use mutual learning. Experimental results indicate that our method significantly reduces network complexity without compromising accuracy. For instance, on a fully connected neural network (FCNN), our method reduced dimensions by 75.03% with only a 0.33% decrease in accuracy. On ResNet-32, we achieved a 74.88% reduction in dimensions with a 2.38% decrease in accuracy."
        ],
        [
            "The proposed method of this paper aims to simplify optical neural networks by representing input data as light signals with varying strengths and directions. To take full advantage of this approach, we also make changes to the input and output layers. To ensure consistent accuracy across various types of optical neural networks, we use mutual learning. Experimental results indicate that our method significantly reduces network complexity without compromising accuracy. For instance, on a fully connected neural network (FCNN), our method reduced dimensions by 75.03% with only a 0.33% decrease in accuracy. On ResNet-32, we achieved a 74.88% reduction in dimensions with a 2.38% decrease in accuracy."
        ],
        [
            "The proposed method of this paper aims to simplify optical neural networks by representing input data as light signals with varying strengths and directions. To take full advantage of this approach, we also make changes to the input and output layers. To ensure consistent accuracy across various types of optical neural networks, we use mutual learning. Experimental results indicate that our method significantly reduces network complexity without compromising accuracy. For instance, on a fully connected neural network (FCNN), our method reduced dimensions by 75.03% with only a 0.33% decrease in accuracy. On ResNet-32, we achieved a 74.88% reduction in dimensions with a 2.38% decrease in accuracy."
        ],
        [
            "This paper proposes a method to simplify optical neural networks by representing input data as light signals with varying strengths and directions. To take full advantage of this approach, we also make changes to the input and output layers. To ensure consistent accuracy across various types of optical neural networks, we use mutual learning. Experimental results indicate that our method significantly reduces network complexity without compromising accuracy. For instance, on a fully connected neural network (FCNN), our method reduced dimensions by 75.03% with only a 0.33% decrease in accuracy. On ResNet-32, we achieved a 74.88% reduction in dimensions with a 2.38% decrease in accuracy."
        ],
        [
            "In this paper, we present a novel technique for simplifying optical neural networks by encoding input data as light signals with varying intensities and directions. To fully leverage this method, we also modify the input and output layers of the network. To ensure consistent accuracy across different types of optical neural networks, we employ mutual learning. Our experimental results demonstrate that our approach significantly reduces network complexity while maintaining accuracy. For example, we achieved a 75.03% reduction in dimensions with only a 0.33% decrease in accuracy on a fully connected neural network (FCNN). Similarly, on ResNet-32, we achieved a 74.88% reduction in dimensions with a 2.38% decrease in accuracy."
        ],
        [
            "In this paper, we introduce a new approach to simplifying optical neural networks by encoding input data as light signals with varying intensities and directions. To make full use of this technique, we also modify the input and output layers of the network. To ensure consistency in accuracy across different types of optical neural networks, we use mutual learning. Our experimental results show that our approach significantly reduces network complexity while maintaining accuracy. For example, we achieved a 75.03% reduction in dimensions with only a 0.33% decrease in accuracy on a fully connected neural network (FCNN). Similarly, on ResNet-32, we achieved a 74.88% reduction in dimensions with a 2.38% decrease in accuracy."
        ],
        [
            "We present a new method for reducing the complexity of optical neural networks by encoding input data as light signals with varying intensities and directions. To fully utilize this approach, we also modify the input and output layers of the network. To maintain consistent accuracy across different types of optical neural networks, we use mutual learning. Our experimental results demonstrate that our approach significantly reduces network complexity while maintaining accuracy. For example, we achieved a 75.03% reduction in dimensions with only a 0.33% decrease in accuracy on a fully connected neural network (FCNN). Similarly, on ResNet-32, we achieved a 74.88% reduction in dimensions with a 2.38% decrease in accuracy."
        ],
        [
            "We introduce a novel approach for simplifying the architecture of optical neural networks, by encoding input data as light signals with varying intensities and directions. To fully leverage this approach, we also modify the input and output layers of the network. To ensure consistent performance across different types of optical neural networks, we employ mutual learning. Our experimental results demonstrate that our approach significantly reduces network complexity while maintaining accuracy. For instance, we achieved a 75.03% reduction in dimensions with only a 0.33% decrease in accuracy on a fully connected neural network (FCNN). Similarly, on ResNet-32, we achieved a 74.88% reduction in dimensions with a 2.38% decrease in accuracy."
        ],
        [
            "We present a novel method to simplify the design of optical neural networks by encoding input data as light signals of different intensities and directions. To optimize the performance of the network, we also modify the input and output layers. We use mutual learning to ensure that the network performs well on different types of optical neural networks. Our experiments show that our method significantly reduces the complexity of the network while maintaining accuracy. For example, we achieved a 75.03% reduction in dimensions with only a 0.33% decrease in accuracy on a fully connected neural network (FCNN). Similarly, on ResNet-32, we achieved a 74.88% reduction in dimensions with a 2.38% decrease in accuracy."
        ],
        [
            "We propose a method to simplify the design of optical neural networks by encoding input data as light signals of different intensities and directions. To optimize the performance of the network, we modify the input and output layers. We use mutual learning to ensure that the network performs well on different types of optical neural networks. Our experiments show that our method significantly reduces the complexity of the network while maintaining accuracy. For example, we achieved a 75.03% reduction in dimensions with only a 0.33% decrease in accuracy on a fully connected neural network (FCNN). Similarly, on ResNet-32, we achieved a 74.88% reduction in dimensions with a 2.38% decrease in accuracy."
        ],
        [
            "The proposed method simplifies the design of optical neural networks by encoding input data as light signals with varying intensities and directions. To optimize performance, the input and output layers are modified. Mutual learning is used to ensure that the network performs well on different types of optical neural networks. The method significantly reduces the complexity of the network while maintaining accuracy. For example, a 75.03% reduction in dimensions with only a 0.33% decrease in accuracy was achieved on a fully connected neural network (FCNN). On ResNet-32, a 74.88% reduction in dimensions with a 2.38% decrease in accuracy was achieved."
        ],
        [
            "The proposed method simplifies the design of optical neural networks by encoding input data as light signals with varying intensities and directions. To optimize performance, the input and output layers are modified. Mutual learning is used to ensure that the network performs well on different types of optical neural networks. The method significantly reduces the complexity of the network while maintaining accuracy. For example, a 75.03% reduction in dimensions with only a 0.33% decrease in accuracy was achieved on a fully connected neural network (FCNN). On ResNet-32, a 74.88% reduction in dimensions with a 2.38% decrease in accuracy was achieved."
        ],
        [
            "The proposed method simplifies the design of optical neural networks by encoding input data as light signals with varying intensities and directions. To optimize performance, the input and output layers are modified. Mutual learning is used to ensure that the network performs well on different types of optical neural networks. The method significantly reduces the complexity of the network while maintaining accuracy. For example, a 75.03% reduction in dimensions with only a 0.33% decrease in accuracy was achieved on a fully connected neural network (FCNN). On ResNet-32, a 74.88% reduction in dimensions with a 2.38% decrease in accuracy was achieved."
        ],
        [
            "The proposed method simplifies the design of optical neural networks by encoding input data as light signals with varying intensities and directions. To optimize performance, the input and output layers are modified. Mutual learning is used to ensure that the network performs well on different types of optical neural networks. The method significantly reduces the complexity of the network while maintaining accuracy. For example, a 75.03% reduction in dimensions with only a 0.33% decrease in accuracy was achieved on a fully connected neural network (FCNN). On ResNet-32, a 74.88% reduction in dimensions with a 2.38% decrease in accuracy was achieved."
        ],
        [
            "The proposed method simplifies the design of optical neural networks by encoding input data as light signals with varying intensities and directions. To optimize performance, the input and output layers are modified. Mutual learning is used to ensure that the network performs well on different types of optical neural networks. The method significantly reduces the complexity of the network while maintaining accuracy. For example, a 75.03% reduction in dimensions with only a 0.33% decrease in accuracy was achieved on a fully connected neural network (FCNN). On ResNet-32, a 74.88% reduction in dimensions with a 2.38% decrease in accuracy was achieved."
        ],
        [
            "The suggested technique decreases the complexity of optical neural networks by encoding input data as light signals of varying intensity and direction. In order to optimize performance, the input and output layers are changed. Mutual learning is used to make sure the network performs well on different types of optical neural networks. The technique greatly reduces the complexity of the network while keeping accuracy. For instance, a 75.03% decrease in dimensions with only a 0.33% decline in accuracy was attained on a fully connected neural network (FCNN). On ResNet-32, a 74.88% decrease in dimensions with a 2.38% decline in accuracy was achieved."
        ],
        [
            "The proposed method reduces the complexity of optical neural networks by representing input data as light signals with varying intensity and direction. In order to achieve optimal performance, the input and output layers are modified. Mutual learning is employed to ensure that the network performs well on different types of optical neural networks. The technique significantly decreases the complexity of the network while preserving accuracy. For example, a 75.03% reduction in dimensions with only a 0.33% loss in accuracy was achieved on a fully connected neural network (FCNN). On ResNet-32, a 74.88% reduction in dimensions with a 2.38% loss in accuracy was achieved."
        ],
        [
            "The suggested technique decreases the intricacy of optical neural networks by portraying input data as light signals with fluctuating intensity and direction. To attain optimum performance, the input and output layers are adjusted. Mutual learning is applied to guarantee that the network executes well on diverse types of optical neural networks. The approach considerably decreases the complexity of the network while sustaining accuracy. For instance, a 75.03% decrease in dimensions with just a 0.33% loss in accuracy was attained on a fully connected neural network (FCNN). On ResNet-32, a 74.88% reduction in dimensions with a 2.38% loss in accuracy was attained."
        ],
        [
            "The proposed method reduces the complexity of optical neural networks by representing input data as light signals with varying intensity and direction. To achieve optimal performance, the input and output layers are optimized. Mutual learning is used to ensure that the network performs well on different types of optical neural networks. The method significantly reduces the complexity of the network while maintaining accuracy. For example, a 75.03% reduction in dimensions with only a 0.33% loss in accuracy was achieved on a fully connected neural network (FCNN). On ResNet-32, a 74.88% reduction in dimensions with a 2.38% loss in accuracy was achieved."
        ],
        [
            "The proposed method reduces the complexity of optical neural networks by encoding input data as light signals with varying intensity and direction. To optimize performance, the input and output layers are optimized using mutual learning to ensure that the network performs well on different types of optical neural networks. The method significantly reduces the complexity of the network while maintaining accuracy. For example, on a fully connected neural network (FCNN), a 75.03% reduction in dimensions was achieved with only a 0.33% loss in accuracy. On ResNet-32, a 74.88% reduction in dimensions was achieved with a 2.38% loss in accuracy."
        ],
        [
            "The proposed method simplifies optical neural networks by representing input data as light signals with varying intensity and direction. The input and output layers are optimized using mutual learning to ensure that the network performs well on different types of optical neural networks. The method significantly reduces the complexity of the network while maintaining accuracy. For example, on a fully connected neural network (FCNN), a 75.03% reduction in dimensions was achieved with only a 0.33% loss in accuracy. On ResNet-32, a 74.88% reduction in dimensions was achieved with a 2.38% loss in accuracy."
        ],
        [
            "This paper introduces a novel technique for simplifying optical neural networks by encoding input data using light intensity and directionality. By optimizing both the input and output layers through mutual learning, the authors are able to achieve significant dimensionality reduction without compromising accuracy. In fact, their approach yields a 75.03% reduction in dimensions for an FCNN with only a 0.33% loss in accuracy, and a 74.88% reduction in dimensions for a ResNet-32 with a 2.38% loss in accuracy."
        ]
    ]
}