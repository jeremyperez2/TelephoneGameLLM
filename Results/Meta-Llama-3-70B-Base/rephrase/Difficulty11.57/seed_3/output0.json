{
    "adjacency_matrix": [
        [
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0
        ]
    ],
    "prompt_init": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "prompt_update": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "personality_list": [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        ""
    ],
    "format_prompt": [
        ""
    ],
    "initial_story": "having the potential for high speed, high throughput, and low energy cost,optical neural networks (onns) have emerged as a promising candidate foraccelerating deep learning tasks. in conventional onns, light amplitudes aremodulated at the input and detected at the output. however, the light phasesare still ignored in conventional structures, although they can also carryinformation for computing. to address this issue, in this paper, we propose aframework called oplixnet to compress the areas of onns by modulating inputimage data into the amplitudes and phase parts of light signals. the input andoutput parts of the onns are redesigned to make full use of both amplitude andphase information. moreover, mutual learning across different onn structures isintroduced to maintain the accuracy. experimental results demonstrate that theproposed framework significantly reduces the areas of onns with the accuracywithin an acceptable range. for instance, 75.03% area is reduced with a 0.33%accuracy decrease on fully connected neural network (fcnn) and 74.88% area isreduced with a 2.38% accuracy decrease on resnet-32. ",
    "stories": [
        [
            "Optical neural networks (ONNs) have the potential for high speed, high throughput, and low energy cost, making them a promising candidate for accelerating deep learning tasks. In conventional ONNs, light amplitudes are modulated at the input and detected at the output. However, the light phases are still ignored in conventional structures, even though they can also carry information for computing. To address this issue, in this paper, we propose a framework called OplixNet to compress the areas of ONNs by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Moreover, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32."
        ],
        [
            "In recent years, Optical Neural Networks (ONNs) have become increasingly popular due to their potential for high-speed processing, large throughput, and low energy consumption. This makes them an ideal candidate for accelerating deep learning tasks. However, despite their advantages, conventional ONNs are limited by the fact that they can only modulate light amplitudes at the input and detect light amplitudes at the output. This leaves the light phases largely unused, even though they can also carry information for computing.\n\nTo address this issue, we propose a framework called OplixNet which compresses the area of ONNs by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Moreover, mutual learning across different ONN structures is introduced to maintain the accuracy.\n\nThe experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs while maintaining an acceptable level of accuracy. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on FCNN and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32. This shows that the proposed framework is effective in optimizing the area of ONNs while preserving the accuracy."
        ],
        [
            "In recent years, Optical Neural Networks (ONNs) have become increasingly popular due to their potential for high-speed processing, large throughput, and low energy consumption. This makes them an ideal candidate for accelerating deep learning tasks. However, despite their advantages, conventional ONNs are limited by the fact that they can only modulate light amplitudes at the input and detect light amplitudes at the output. This leaves the light phases largely unused, even though they can also carry information for computing.\n\nTo address this issue, we propose a framework called OplixNet which compresses the area of ONNs by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Moreover, mutual learning across different ONN structures is introduced to maintain the accuracy.\n\nThe experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs while maintaining an acceptable level of accuracy. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on FCNN and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32. This shows that the proposed framework is effective in optimizing the area of ONNs while preserving the accuracy."
        ],
        [
            "Optical Neural Networks (ONNs) have become increasingly popular in recent years due to their potential for high-speed processing, large throughput, and low energy consumption, making them an ideal candidate for accelerating deep learning tasks. However, conventional ONNs are limited by the fact that they can only modulate light amplitudes at the input and detect light amplitudes at the output, leaving the light phases largely unused even though they can also carry information for computing.\n\nTo address this issue, we propose a framework called OplixNet which compresses the area of ONNs by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Moreover, mutual learning across different ONN structures is introduced to maintain the accuracy.\n\nThe experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs while maintaining an acceptable level of accuracy. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on FCNN and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32. This shows that the proposed framework is effective in optimizing the area of ONNs while preserving the accuracy."
        ],
        [
            "Optical Neural Networks (ONNs) are gaining popularity due to their potential for high-speed processing, large throughput, and low energy consumption, making them ideal for accelerating deep learning tasks. However, conventional ONNs can only modulate light amplitudes at the input and detect light amplitudes at the output, leaving the light phases largely unused for computing, even though they can also carry information.\n\nThe proposed framework, OplixNet, compresses the area of ONNs by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Moreover, mutual learning across different ONN structures is introduced to maintain the accuracy.\n\nThe experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs while maintaining an acceptable level of accuracy. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on FCNN and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32. This shows that the proposed framework is effective in optimizing the area of ONNs while preserving the accuracy."
        ],
        [
            "Optical Neural Networks (ONNs) are gaining popularity due to their potential for high-speed processing, large throughput, and low energy consumption, making them ideal for accelerating deep learning tasks. However, conventional ONNs can only modulate light amplitudes at the input and detect light amplitudes at the output, leaving the light phases largely unused for computing, even though they can also carry information.\n\nTo address this issue, a framework called OplixNet was proposed that compresses the area of ONNs by modulating input image data into the amplitudes and phase parts of light signals. This framework redesigns the input and output parts of the ONNs to make full use of both amplitude and phase information. Additionally, mutual learning across different ONN structures is introduced to maintain the accuracy.\n\nThe experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs while maintaining an acceptable level of accuracy. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on FCNN and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32. This shows that the proposed framework is effective in optimizing the area of ONNs while preserving the accuracy."
        ],
        [
            "Optical neural networks (ONNs) are gaining popularity due to their potential for high-speed processing, large throughput, and low energy consumption, making them ideal for accelerating deep learning tasks. However, conventional ONNs can only modulate light amplitudes at the input and detect light amplitudes at the output, leaving the light phases largely unused for computing, even though they can also carry information.\n\nTo address this issue, a framework called OplixNet was proposed that compresses the area of ONNs by modulating input image data into the amplitudes and phase parts of light signals. This framework redesigns the input and output parts of the ONNs to make full use of both amplitude and phase information. Additionally, mutual learning across different ONN structures is introduced to maintain the accuracy.\n\nThe experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs while maintaining an acceptable level of accuracy. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on FCNN and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32. This shows that the proposed framework is effective in optimizing the area of ONNs while preserving the accuracy."
        ],
        [
            "Optical Neural Networks (ONNs) are gaining popularity because of their potential for high speed processing, large throughput, and low energy consumption, making them ideal for accelerating deep learning tasks. However, conventional ONNs can only modulate light amplitudes at the input and detect light amplitudes at the output, leaving the light phases largely unused for computing, even though they can also carry information.\n\nTo address this issue, a framework called OplixNet was proposed that compresses the area of ONNs by modulating input image data into the amplitudes and phase parts of light signals. This framework redesigns the input and output parts of the ONNs to make full use of both amplitude and phase information. Additionally, mutual learning across different ONN structures is introduced to maintain the accuracy.\n\nThe experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs while maintaining an acceptable level of accuracy. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on FCNN and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32. This shows that the proposed framework is effective in optimizing the area of ONNs while preserving the accuracy."
        ],
        [
            "The rise of Optical Neural Networks (ONNs) has been due to their potential for high-speed processing, large throughput, and low energy consumption, making them ideal for accelerating deep learning tasks. However, conventional ONNs can only modulate light amplitudes at the input and detect light amplitudes at the output, leaving the light phases largely unused for computing, even though they can also carry information.\n\nTo tackle this issue, a framework called OplixNet was proposed that compresses the area of ONNs by modulating input image data into the amplitudes and phase parts of light signals. This framework redesigns the input and output parts of the ONNs to make full use of both amplitude and phase information. Moreover, mutual learning across different ONN structures is introduced to maintain the accuracy.\n\nThe experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs while maintaining an acceptable level of accuracy. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on FCNN and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32. This shows that the proposed framework is effective in optimizing the area of ONNs while preserving the accuracy."
        ],
        [
            "The rise of Optical Neural Networks (ONNs) has been due to their potential for high-speed processing, large throughput, and low energy consumption, making them ideal for accelerating deep learning tasks. However, conventional ONNs can only modulate light amplitudes at the input and detect light amplitudes at the output, leaving the light phases largely unused for computing, even though they can also carry information.\n\nTo tackle this issue, a framework called OplixNet was proposed that compresses the area of ONNs by modulating input image data into the amplitudes and phase parts of light signals. This framework redesigns the input and output parts of the ONNs to make full use of both amplitude and phase information. Moreover, mutual learning across different ONN structures is introduced to maintain the accuracy.\n\nThe experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs while maintaining an acceptable level of accuracy. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on FCNN and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32. This shows that the proposed framework is effective in optimizing the area of ONNs while preserving the accuracy."
        ],
        [
            "The rapid growth of Optical Neural Networks (ONNs) has been attributed to their potential for high-speed processing, large throughput, and low energy consumption, making them ideal for accelerating deep learning tasks. However, traditional ONNs can only modulate light amplitudes at the input and detect light amplitudes at the output, leaving the light phases largely unused for computing, even though they can also carry information.\n\nTo address this issue, a framework called OplixNet was proposed that compresses the area of ONNs by modulating input image data into the amplitudes and phase parts of light signals. This framework redesigns the input and output parts of the ONNs to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy.\n\nThe experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs while maintaining an acceptable level of accuracy. For example, 75.03% area is reduced with a 0.33% accuracy decrease on FCNN and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32. This shows that the proposed framework is effective in optimizing the area of ONNs while preserving the accuracy."
        ],
        [
            "The rapid growth of optical neural networks (ONNs) has been attributed to their potential for high-speed processing, large throughput, and low energy consumption, making them ideal for accelerating deep learning tasks. However, traditional ONNs can only modulate light amplitudes at the input and detect light amplitudes at the output, leaving the light phases largely unused for computing, even though they can also carry information.\n\nTo address this issue, a framework called OplixNet was proposed that compresses the area of ONNs by modulating input image data into the amplitudes and phase parts of light signals. This framework redesigns the input and output parts of the ONNs to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy.\n\nThe experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs while maintaining an acceptable level of accuracy. For example, 75.03% area is reduced with a 0.33% accuracy decrease on FCNN and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32. This shows that the proposed framework is effective in optimizing the area of ONNs while preserving the accuracy."
        ],
        [
            "Optical neural networks (ONNs) have gained popularity due to their ability to process information at high speeds, handle large amounts of data, and consume less energy, making them suitable for deep learning applications. However, conventional ONNs only modulate the amplitude of light signals at the input and detect the amplitude of light signals at the output, leaving the phase of light signals largely unused for computing. This is despite the fact that the phase of light signals can also carry information.\n\nTo address this issue, a framework called OplixNet has been proposed that compresses the area of ONNs by modulating input image data into the amplitude and phase parts of light signals. This framework redesigns the input and output parts of the ONNs to make full use of both amplitude and phase information. In addition, mutual learning across different ONN structures is introduced to maintain the accuracy.\n\nThe experimental results show that the proposed framework significantly reduces the areas of ONNs while maintaining an acceptable level of accuracy. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on FCNN and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32. This demonstrates that the proposed framework is effective in optimizing the area of ONNs while preserving the accuracy."
        ],
        [
            "Optical neural networks (ONNs) have recently gained attention due to their ability to process information quickly, handle large amounts of data, and use less energy, which makes them well-suited for deep learning applications. However, conventional ONNs only modulate the amplitude of light signals at the input and detect the amplitude of light signals at the output, leaving the phase of light signals largely unused for computing. This is despite the fact that the phase of light signals can also carry information.\n\nTo address this issue, a framework called OplixNet has been proposed that compresses the area of ONNs by modulating input image data into the amplitude and phase parts of light signals. This framework redesigns the input and output parts of the ONNs to make full use of both amplitude and phase information. In addition, mutual learning across different ONN structures is introduced to maintain the accuracy.\n\nThe experimental results show that the proposed framework significantly reduces the areas of ONNs while maintaining an acceptable level of accuracy. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on FCNN and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32. This demonstrates that the proposed framework is effective in optimizing the area of ONNs while preserving the accuracy."
        ],
        [
            "Optical neural networks (ONNs) have emerged as an attractive solution for deep learning applications due to their ability to process information rapidly, handle large data volumes, and consume less power. Despite their potential, conventional ONNs mainly focus on modulating the amplitude of light signals at the input and detecting the amplitude of light signals at the output, neglecting the valuable information contained in the phase of light signals.\n\nTo overcome this limitation, researchers have proposed a new framework called OplixNet that compresses the area of ONNs by modulating input image data into the amplitude and phase components of light signals. This framework redesigns the input and output parts of the ONNs to fully exploit both the amplitude and phase information. Additionally, mutual learning across different ONN structures is introduced to maintain the accuracy of the system.\n\nThe experimental results show that the proposed framework significantly reduces the areas of ONNs while preserving an acceptable level of accuracy. For example, the framework reduces the area by 75.03% with a 0.33% decrease in accuracy on FCNN and by 74.88% with a 2.38% decrease in accuracy on ResNet-32. These results demonstrate the effectiveness of the proposed framework in optimizing the area of ONNs while maintaining accuracy."
        ],
        [
            "A new framework called OplixNet compresses the area of Optical Neural Networks (ONNs) by modulating input image data into the amplitude and phase components of light signals. This framework redesigns the input and output parts of the ONNs to fully exploit both the amplitude and phase information. Additionally, mutual learning across different ONN structures is introduced to maintain the accuracy of the system.\n\nThe experimental results show that the proposed framework significantly reduces the areas of ONNs while preserving an acceptable level of accuracy. For example, the framework reduces the area by 75.03% with a 0.33% decrease in accuracy on FCNN and by 74.88% with a 2.38% decrease in accuracy on ResNet-32. These results demonstrate the effectiveness of the proposed framework in optimizing the area of ONNs while maintaining accuracy."
        ],
        [
            "The OplixNet framework compresses the area of Optical Neural Networks (ONNs) by modulating input image data into the amplitude and phase components of light signals. This framework redesigns the input and output parts of the ONNs to fully exploit both the amplitude and phase information. In addition, mutual learning across different ONN structures is introduced to maintain the accuracy of the system.\n\nThe experimental results show that the proposed framework significantly reduces the areas of ONNs while preserving an acceptable level of accuracy. For example, the framework reduces the area by 75.03% with a 0.33% decrease in accuracy on FCNN and by 74.88% with a 2.38% decrease in accuracy on ResNet-32. These results demonstrate the effectiveness of the proposed framework in optimizing the area of ONNs while maintaining accuracy."
        ],
        [
            "The OplixNet framework is a technique for compressing the size of optical neural networks (ONNs) by modulating the input image data into the amplitude and phase components of light signals. This framework redesigns the input and output components of the ONNs to fully exploit both the amplitude and phase information. Additionally, mutual learning across different ONN structures is introduced to maintain the accuracy of the system.\n\nThe experimental results show that the proposed framework significantly reduces the size of ONNs while maintaining an acceptable level of accuracy. For example, the framework reduces the size by 75.03% with a 0.33% decrease in accuracy on FCNN and by 74.88% with a 2.38% decrease in accuracy on ResNet-32. These results demonstrate the effectiveness of the proposed framework in optimizing the size of ONNs while maintaining accuracy."
        ],
        [
            "The OplixNet framework is a technique for compressing the size of optical neural networks (ONNs) by modulating the input image data into the amplitude and phase components of light signals. This framework redesigns the input and output components of the ONNs to fully exploit both the amplitude and phase information. Additionally, mutual learning across different ONN structures is introduced to maintain the accuracy of the system.\n\nThe experimental results show that the proposed framework significantly reduces the size of ONNs while maintaining an acceptable level of accuracy. For example, the framework reduces the size by 75.03% with a 0.33% decrease in accuracy on FCNN and by 74.88% with a 2.38% decrease in accuracy on ResNet-32. These results demonstrate the effectiveness of the proposed framework in optimizing the size of ONNs while maintaining accuracy."
        ],
        [
            "The OplixNet framework is a method for shrinking the size of optical neural networks (ONNs) by altering the input image data into the strength and direction of light signals. This framework redesigns the input and output components of the ONNs to completely use both the strength and direction information. Moreover, mutual learning across different ONN structures is added to maintain the precision of the system.\n\nThe experimental outcomes show that the suggested framework considerably reduces the size of ONNs while maintaining an acceptable level of precision. For example, the framework reduces the size by 75.03% with a 0.33% drop in precision on FCNN and by 74.88% with a 2.38% drop in precision on ResNet-32. These outcomes demonstrate the effectiveness of the suggested framework in optimizing the size of ONNs while maintaining precision."
        ],
        [
            "The OplixNet framework is a method for reducing the size of optical neural networks (ONNs) by modifying the input image data into the strength and direction of light signals. The framework modifies the input and output components of the ONNs to completely use both the strength and direction information. Moreover, mutual learning across different ONN structures is added to maintain the precision of the system.\n\nThe experimental outcomes show that the suggested framework significantly reduces the size of ONNs while maintaining an acceptable level of precision. For example, the framework reduces the size by 75.03% with a 0.33% drop in precision on FCNN and by 74.88% with a 2.38% drop in precision on ResNet-32. These outcomes demonstrate the effectiveness of the suggested framework in optimizing the size of ONNs while maintaining precision."
        ],
        [
            "The OplixNet framework is a method for reducing the size of optical neural networks (ONNs) by modifying the input image data into the strength and direction of light signals. The framework modifies the input and output components of the ONNs to completely use both the strength and direction information. Moreover, mutual learning across different ONN structures is added to maintain the precision of the system.\n\nThe experimental outcomes show that the suggested framework significantly reduces the size of ONNs while maintaining an acceptable level of precision. For example, the framework reduces the size by 75.03% with a 0.33% drop in precision on FCNN and by 74.88% with a 2.38% drop in precision on ResNet-32. These outcomes demonstrate the effectiveness of the suggested framework in optimizing the size of ONNs while maintaining precision."
        ],
        [
            "OplixNet framework is a method for reducing the size of optical neural networks (ONNs) by modifying the input image data into the strength and direction of light signals. The framework modifies the input and output components of the ONNs to completely use both the strength and direction information. Moreover, mutual learning across different ONN structures is added to maintain the precision of the system.\n\nThe experimental outcomes show that the suggested framework significantly reduces the size of ONNs while maintaining an acceptable level of precision. For example, the framework reduces the size by 75.03% with a 0.33% drop in precision on FCNN and by 74.88% with a 2.38% drop in precision on ResNet-32. These outcomes demonstrate the effectiveness of the suggested framework in optimizing the size of ONNs while maintaining precision."
        ],
        [
            "The OplixNet framework is a technique for reducing the size of optical neural networks (ONNs) by altering the input image data into the strength and direction of light signals. The framework modifies the input and output components of the ONNs to fully use both the strength and direction information. Moreover, mutual learning across different ONN structures is added to maintain the accuracy of the system.\n\nThe experimental results show that the proposed framework significantly reduces the size of ONNs while maintaining an acceptable level of accuracy. For example, the framework reduces the size by 75.03% with a 0.33% drop in accuracy on FCNN and by 74.88% with a 2.38% drop in accuracy on ResNet-32. These results demonstrate the effectiveness of the proposed framework in optimizing the size of ONNs while maintaining accuracy."
        ],
        [
            "The OplixNet framework is a method for decreasing the size of optical neural networks (ONNs) by changing the input image data into the strength and direction of light signals. The framework modifies the input and output components of the ONNs to fully utilize both the strength and direction information. In addition, mutual learning across different ONN structures is included to preserve the accuracy of the system.\n\nThe experimental results show that the proposed framework significantly reduces the size of ONNs while maintaining an acceptable level of accuracy. For example, the framework reduces the size by 75.03% with a 0.33% drop in accuracy on FCNN and by 74.88% with a 2.38% drop in accuracy on ResNet-32. These results demonstrate the effectiveness of the proposed framework in optimizing the size of ONNs while maintaining accuracy."
        ],
        [
            "A novel approach for reducing the size of optical neural networks (ONNs) is proposed, which involves altering the input image data into the intensity and direction of light signals. The framework modifies the input and output components of the ONNs to fully utilize both the intensity and direction information. In addition, mutual learning across different ONN structures is included to preserve the accuracy of the system.\n\nThe experimental results show that the proposed framework significantly reduces the size of ONNs while maintaining an acceptable level of accuracy. For example, the framework reduces the size by 75.03% with a 0.33% drop in accuracy on FCNN and by 74.88% with a 2.38% drop in accuracy on ResNet-32. These results demonstrate the effectiveness of the proposed framework in optimizing the size of ONNs while maintaining accuracy."
        ],
        [
            "In this paper, we propose a new method for reducing the size of optical neural networks (ONNs) while maintaining accuracy. Our approach involves modifying the input and output components of the ONNs to fully utilize both the intensity and direction information of light signals. Additionally, we incorporate mutual learning across different ONN structures to preserve accuracy. Our experimental results show that our framework significantly reduces the size of ONNs while maintaining an acceptable level of accuracy. For example, our framework reduces the size by 75.03% with a 0.33% drop in accuracy on FCNN and by 74.88% with a 2.38% drop in accuracy on ResNet-32. These results demonstrate the effectiveness of our proposed framework in optimizing the size of ONNs while maintaining accuracy."
        ],
        [
            "In this paper, we propose a new method for reducing the size of optical neural networks (ONNs) while maintaining accuracy. Our approach involves modifying the input and output components of the ONNs to fully utilize both the intensity and direction information of light signals. Additionally, we incorporate mutual learning across different ONN structures to preserve accuracy. Our experimental results show that our framework significantly reduces the size of ONNs while maintaining an acceptable level of accuracy. For example, our framework reduces the size by 75.03% with a 0.33% drop in accuracy on FCNN and by 74.88% with a 2.38% drop in accuracy on ResNet-32. These results demonstrate the effectiveness of our proposed framework in optimizing the size of ONNs while maintaining accuracy."
        ],
        [
            "In this paper, we suggest a novel method for reducing the size of optical neural networks (ONNs) while preserving precision. Our technique involves altering the input and output parts of the ONNs to fully utilize both the intensity and direction information of light signals. Additionally, we integrate mutual learning across different ONN structures to maintain accuracy. Our experimental results show that our framework dramatically reduces the size of ONNs while keeping an adequate level of accuracy. For example, our framework reduces the size by 75.03% with a 0.33% decline in accuracy on FCNN and by 74.88% with a 2.38% drop in accuracy on ResNet-32. These results show the effectiveness of our proposed framework in optimizing the size of ONNs while maintaining accuracy."
        ],
        [
            "We propose a novel technique to minimize the size of optical neural networks (ONNs) while preserving precision. Our technique involves modifying the input and output parts of the ONNs to fully utilize both the intensity and direction information of light signals. Additionally, we integrate mutual learning across different ONN structures to maintain accuracy. Our experimental results demonstrate that our framework drastically reduces the size of ONNs while keeping an adequate level of accuracy. For instance, our framework reduces the size by 75.03% with a 0.33% decline in accuracy on FCNN and by 74.88% with a 2.38% drop in accuracy on ResNet-32. These results demonstrate the effectiveness of our proposed framework in optimizing the size of ONNs while maintaining accuracy."
        ],
        [
            "We introduce a new method for reducing the size of optical neural networks (ONNs) while maintaining precision. Our approach involves adjusting the input and output sections of the ONNs to take advantage of both the intensity and direction information of light signals. Additionally, we implement mutual learning across different ONN structures to maintain accuracy. Our experimental findings show that our framework significantly decreases the size of ONNs while keeping an acceptable level of accuracy. For example, our framework reduces the size by 75.03% with a 0.33% loss in accuracy on FCNN and by 74.88% with a 2.38% reduction in accuracy on ResNet-32. These results demonstrate the effectiveness of our proposed framework in optimizing the size of ONNs while preserving accuracy."
        ],
        [
            "We propose a novel approach for reducing the size of optical neural networks (ONNs) while preserving accuracy. Our method involves modifying the input and output sections of the ONNs to leverage both the intensity and direction of light signals. Moreover, we employ mutual learning across different ONN structures to maintain accuracy. Our experimental results demonstrate that our framework significantly reduces the size of ONNs while maintaining an acceptable level of accuracy. For instance, our framework reduces the size by 75.03% with a 0.33% loss in accuracy on FCNN and by 74.88% with a 2.38% reduction in accuracy on ResNet-32. These findings highlight the effectiveness of our proposed framework in optimizing the size of ONNs while preserving accuracy."
        ],
        [
            "We suggest a new approach to make optical neural networks (ONNs) smaller while keeping their accuracy. Our method involves changing the parts of ONNs that deal with inputs and outputs, so they can use both the brightness and direction of light signals. We also use something called mutual learning between different ONN structures to keep accuracy high. Our experiments show that our system makes ONNs much smaller while still having good accuracy. For example, our system makes FCNNs 75.03% smaller with only a 0.33% loss in accuracy and ResNet-32s 74.88% smaller with only a 2.38% reduction in accuracy. This shows that our proposed system works well for making ONNs smaller without losing accuracy."
        ],
        [
            "We propose a novel approach to make optical neural networks (ONNs) more compact while maintaining their performance. Our method involves modifying the input and output layers of ONNs to support both the amplitude and phase of optical signals, and employing mutual learning among different ONN structures to maintain high accuracy. Experiments demonstrate that our system can significantly reduce the size of ONNs without compromising accuracy. For instance, our system reduces the size of FCNNs by 75.03% with only a 0.33% loss in accuracy and ResNet-32s by 74.88% with only a 2.38% reduction in accuracy. These results demonstrate the effectiveness of our proposed system in making ONNs more compact without sacrificing accuracy."
        ],
        [
            "We present a new approach to designing optical neural networks (ONNs) that are smaller while still performing well. Our method involves changing the input and output layers of ONNs so that they can handle both the strength and timing of optical signals, and using shared learning between different ONN structures to maintain high accuracy. Experiments show that our system can significantly reduce the size of ONNs without sacrificing accuracy. For example, our system reduces the size of fully-connected neural networks (FCNNs) by 75.03% with only a 0.33% loss in accuracy, and reduces the size of ResNet-32s by 74.88% with only a 2.38% reduction in accuracy. These results show that our system is effective at making ONNs smaller without sacrificing accuracy."
        ],
        [
            "We propose a method for reducing the size of optical neural networks (ONNs) while maintaining performance. Our approach involves modifying the input and output layers of ONNs to handle both the strength and timing of optical signals, and using shared learning across ONN structures to preserve accuracy. Experiments demonstrate that our method can significantly reduce ONN size with minimal accuracy loss. Specifically, our method reduces the size of fully-connected neural networks (FCNNs) by 75.03% with only a 0.33% accuracy drop, and reduces the size of ResNet-32s by 74.88% with only a 2.38% accuracy reduction. These results indicate that our method is effective for reducing ONN size without sacrificing performance."
        ],
        [
            "We present a technique for minimizing the size of optical neural networks (ONNs) without compromising performance. Our approach involves modifying the input and output layers of ONNs to handle the intensity and timing of optical signals, and utilizing shared learning across ONN structures to maintain precision. Experiments show that our method can significantly reduce ONN size with minimal accuracy loss. In particular, our method reduces the size of fully-connected neural networks (FCNNs) by 75.03% with only a 0.33% accuracy drop, and reduces the size of ResNet-32s by 74.88% with only a 2.38% accuracy reduction. These results demonstrate that our method is effective for reducing ONN size without sacrificing performance."
        ],
        [
            "We present a technique for reducing the size of optical neural networks (ONNs) while still maintaining performance. Our approach involves changing the input and output layers of ONNs to deal with the intensity and timing of optical signals, and using shared learning across ONN structures to maintain precision. Experiments show that our method can significantly reduce ONN size with minimal accuracy loss. In particular, our method reduces the size of fully-connected neural networks (FCNNs) by 75.03% with only a 0.33% accuracy drop, and reduces the size of ResNet-32s by 74.88% with only a 2.38% accuracy reduction. These results demonstrate that our method is effective for reducing ONN size without sacrificing performance."
        ],
        [
            "In this paper, we describe a technique for shrinking the size of optical neural networks (ONNs) without sacrificing performance. Our approach involves adapting the input and output layers of ONNs to handle the intensity and timing of optical signals, and leveraging shared learning across ONN structures to maintain precision. Experiments show that our method can significantly reduce ONN size with minimal accuracy loss. Specifically, our method reduces the size of fully-connected neural networks (FCNNs) by 75.03% with only a 0.33% accuracy drop, and reduces the size of ResNet-32s by 74.88% with only a 2.38% accuracy reduction. These results indicate that our method is effective for reducing ONN size without compromising performance."
        ],
        [
            "We propose a method for reducing the size of optical neural networks (ONNs) while maintaining performance. Our approach involves adapting the input and output layers of ONNs to handle the intensity and timing of optical signals, and leveraging shared learning across ONN structures to maintain precision. Experiments show that our method can significantly reduce ONN size with minimal accuracy loss. Specifically, our method reduces the size of fully-connected neural networks (FCNNs) by 75.03% with only a 0.33% accuracy drop, and reduces the size of ResNet-32s by 74.88% with only a 2.38% accuracy reduction. These results indicate that our method is effective for reducing ONN size without compromising performance."
        ],
        [
            "We present a method for reducing the size of optical neural networks (ONNs) while preserving performance. Our approach involves adapting the input and output layers of ONNs to handle the intensity and timing of optical signals, and leveraging shared learning across ONN structures to maintain precision. Experiments show that our method can significantly reduce ONN size with minimal accuracy loss. Specifically, our method reduces the size of fully-connected neural networks (FCNNs) by 75.03% with only a 0.33% accuracy drop, and reduces the size of ResNet-32s by 74.88% with only a 2.38% accuracy reduction. These results indicate that our method is effective for reducing ONN size without compromising performance."
        ],
        [
            "We present a method for reducing the size of optical neural networks (ONNs) while maintaining their performance. The proposed approach involves adapting the input and output layers of ONNs to handle the intensity and timing of optical signals, and leveraging shared learning across ONN structures to maintain precision. Experiments show that our method can significantly reduce ONN size without sacrificing accuracy. Specifically, our method reduces the size of fully-connected neural networks (FCNNs) by 75.03% with only a 0.33% accuracy loss, and reduces the size of ResNet-32s by 74.88% with only a 2.38% accuracy reduction. These results demonstrate the effectiveness of our method in reducing ONN size while preserving performance."
        ],
        [
            "Our study introduces an approach to downsize optical neural networks (ONNs) without sacrificing their performance. By adjusting the input and output layers of ONNs to accommodate the intensity and timing of optical signals, and leveraging shared learning across ONN structures to preserve precision, we demonstrate that our approach can achieve significant reductions in ONN size. Specifically, our experiments show that our method can downsize fully-connected neural networks (FCNNs) by 75.03% with only a 0.33% accuracy loss, and reduce the size of ResNet-32s by 74.88% with only a 2.38% accuracy reduction. These results highlight the effectiveness of our method in reducing ONN size while preserving performance."
        ],
        [
            "Our study proposes a method for reducing the size of optical neural networks (ONNs) without compromising their performance. By modifying the input and output layers of ONNs to account for the intensity and timing of optical signals, and utilizing shared learning across ONN structures to maintain precision, we demonstrate that our approach can significantly reduce the size of ONNs. In particular, our experiments show that our method can reduce the size of fully-connected neural networks (FCNNs) by 75.03% with only a 0.33% accuracy loss, and reduce the size of ResNet-32s by 74.88% with only a 2.38% accuracy reduction. These results highlight the effectiveness of our method in reducing ONN size while preserving performance."
        ],
        [
            "We have developed a method to reduce the size of optical neural networks (ONNs) without sacrificing their performance. By modifying the input and output layers of ONNs to account for the intensity and timing of optical signals, and using shared learning across ONN structures to maintain precision, we demonstrate that our approach can significantly reduce the size of ONNs. In particular, our experiments show that our method can reduce the size of fully-connected neural networks (FCNNs) by 75.03% with only a 0.33% accuracy loss, and reduce the size of ResNet-32s by 74.88% with only a 2.38% accuracy reduction. These results highlight the effectiveness of our method in reducing ONN size while preserving performance."
        ],
        [
            "In this paper, we have proposed a method to reduce the size of optical neural networks (ONNs) without sacrificing their performance. By modifying the input and output layers of ONNs to account for the intensity and timing of optical signals, and using shared learning across ONN structures to maintain precision, we demonstrate that our approach can significantly reduce the size of ONNs. In particular, our experiments show that our method can reduce the size of fully-connected neural networks (FCNNs) by 75.03% with only a 0.33% accuracy loss, and reduce the size of ResNet-32s by 74.88% with only a 2.38% accuracy reduction. These results highlight the effectiveness of our method in reducing ONN size while preserving performance."
        ],
        [
            "We propose a method to reduce the size of optical neural networks (ONNs) without sacrificing their performance. To do this, we modify the input and output layers of ONNs to account for the intensity and timing of optical signals. Additionally, we use shared learning across ONN structures to maintain precision. Our experiments show that our method can reduce the size of fully-connected neural networks (FCNNs) by 75.03% with only a 0.33% accuracy loss, and reduce the size of ResNet-32s by 74.88% with only a 2.38% accuracy reduction. These results demonstrate the effectiveness of our method in reducing ONN size while preserving performance."
        ],
        [
            "We present a method for reducing the size of optical neural networks (ONNs) without compromising performance. Our approach modifies the input and output layers of ONNs to consider the intensity and timing of optical signals. We also employ shared learning across ONN structures to maintain precision. Experimental results show that our method can reduce the size of fully-connected neural networks (FCNNs) by 75.03% with only a 0.33% accuracy loss, and reduce the size of ResNet-32s by 74.88% with only a 2.38% accuracy reduction. These results demonstrate the effectiveness of our method in reducing ONN size while preserving performance."
        ],
        [
            "We propose a method to reduce the size of optical neural networks (ONNs) without compromising their performance. Our approach modifies the input and output layers of ONNs to take into account the intensity and timing of optical signals. We also use shared learning across ONN structures to maintain precision. Experimental results demonstrate that our method can reduce the size of fully-connected neural networks (FCNNs) by 75.03% with only a 0.33% accuracy loss, and reduce the size of ResNet-32s by 74.88% with only a 2.38% accuracy reduction. These results highlight the effectiveness of our method in reducing ONN size while preserving performance."
        ],
        [
            "We propose a method to decrease the size of optical neural networks (ONNs) while maintaining their performance. Our approach adjusts the input and output layers of ONNs to account for the intensity and timing of optical signals. We also use shared learning across ONN structures to preserve precision. Experimental results show that our method can reduce the size of fully-connected neural networks (FCNNs) by 75.03% with only a 0.33% accuracy loss, and reduce the size of ResNet-32s by 74.88% with only a 2.38% accuracy reduction. These results demonstrate the effectiveness of our method in reducing ONN size while maintaining performance."
        ]
    ]
}