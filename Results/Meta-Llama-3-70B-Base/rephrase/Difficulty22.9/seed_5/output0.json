{
    "adjacency_matrix": [
        [
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0
        ]
    ],
    "prompt_init": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "prompt_update": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "personality_list": [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        ""
    ],
    "format_prompt": [
        ""
    ],
    "initial_story": "musculoskeletal diseases and cognitive impairments in patients lead todifficulties in movement as well as negative effects on their psychologicalhealth. clinical gait analysis, a vital tool for early diagnosis and treatment,traditionally relies on expensive optical motion capture systems. recentadvances in computer vision and deep learning have opened the door to moreaccessible and cost-effective alternatives. this paper introduces a novelspatio-temporal transformer network to estimate critical gait parameters fromrgb videos captured by a single-view camera. empirical evaluations on a publicdataset of cerebral palsy patients indicate that the proposed frameworksurpasses current state-of-the-art approaches and show significant improvementsin predicting general gait parameters (including walking speed, gait deviationindex - gdi, and knee flexion angle at maximum extension), while utilizingfewer parameters and alleviating the need for manual feature extraction. ",
    "stories": [
        [
            "musculoskeletal diseases and cognitive impairments in patients lead todifficulties in movement as well as negative effects on their psychologicalhealth. clinical gait analysis, a vital tool for early diagnosis andtreatment, traditionally relies on expensive optical motion capture systems.recent advances in computer vision and deep learning have opened the door tomore accessible and cost-effective alternatives. this paper introduces aspatio-temporal transformer network to estimate critical gait parametersfrom rgb videos captured by a single-view camera. empirical evaluations on apublic dataset of cerebral palsy patients indicate that the proposedframework surpasses current state-of-the-art approaches and show significantimprovements in predicting general gait parameters (including walking speed,gait deviation index - gdi, and knee flexion angle at maximum extension),while utilizing fewer parameters and alleviating the need for manual featureextraction."
        ],
        [
            "Musculoskeletal diseases and cognitive impairments in patients lead to difficulties in movement as well as negative effects on their psychological health. Clinical gait analysis, a vital tool for early diagnosis and treatment, traditionally relies on expensive optical motion capture systems. Recent advances in computer vision and deep learning have opened the door to more accessible and cost-effective alternatives. This paper introduces a spatio-temporal transformer network to estimate critical gait parameters from RGB videos captured by a single-view camera. Empirical evaluations on a public dataset of cerebral palsy patients indicate that the proposed framework surpasses current state-of-the-art approaches and show significant improvements in predicting general gait parameters (including walking speed, Gait Deviation Index - GDI, and knee flexion angle at maximum extension), while utilizing fewer parameters and alleviating the need for manual feature extraction."
        ],
        [
            "Musculoskeletal diseases and cognitive impairments in patients often lead to difficulties in movement as well as negative psychological effects. Clinical gait analysis is an important tool for early diagnosis and treatment, but it traditionally relies on expensive optical motion capture systems. Recent advances in computer vision and deep learning have made more accessible and cost-effective alternatives possible. This paper introduces a spatio-temporal transformer network to estimate critical gait parameters from RGB videos captured by a single-view camera. Empirical evaluations on a public dataset of cerebral palsy patients show that the proposed framework surpasses current state-of-the-art approaches in predicting general gait parameters (including walking speed, Gait Deviation Index - GDI, and knee flexion angle at maximum extension), while utilizing fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Musculoskeletal diseases and cognitive impairments in patients frequently lead to challenges with movement and negative psychological effects. Clinical gait analysis is a crucial tool for early detection and treatment, yet it typically depends on expensive optical motion capture systems. Advances in computer vision and deep learning have enabled more available and cost-effective solutions. This study presents a spatio-temporal transformer network to estimate key gait parameters from RGB videos recorded by a single-view camera. Empirical assessments on a public dataset of cerebral palsy patients demonstrate that the proposed framework outperforms current state-of-the-art approaches in predicting general gait parameters (such as walking speed, Gait Deviation Index - GDI, and knee flexion angle at maximum extension), while using fewer parameters and avoiding the necessity for manual feature extraction."
        ],
        [
            "Musculoskeletal and cognitive impairments can make it difficult for patients to move around and cause psychological distress. Clinical gait analysis is a valuable tool for early detection and treatment of these conditions, but it often relies on expensive optical motion capture systems. Recent advances in computer vision and deep learning have made more accessible and cost-effective solutions possible. In this study, we present a spatio-temporal transformer network that can estimate key gait parameters from RGB videos captured by a single-view camera. Our empirical assessments on a public dataset of cerebral palsy patients show that the proposed framework outperforms current state-of-the-art approaches in predicting general gait parameters (such as walking speed, Gait Deviation Index - GDI, and knee flexion angle at maximum extension), while using fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Musculoskeletal and cognitive impairments can make it difficult for patients to move around and cause psychological distress. Clinical gait analysis is a valuable tool for early detection and treatment of these conditions, but it often relies on expensive optical motion capture systems. Recent advances in computer vision and deep learning have made more accessible and cost-effective solutions possible. In this study, we present a spatio-temporal transformer network that can estimate key gait parameters from RGB videos captured by a single-view camera. Our empirical assessments on a public dataset of cerebral palsy patients show that the proposed framework outperforms current state-of-the-art approaches in predicting general gait parameters (such as walking speed, Gait Deviation Index - GDI, and knee flexion angle at maximum extension), while using fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Musculoskeletal and cognitive impairments can make it difficult for patients to move around and cause psychological distress. Clinical gait analysis is a valuable tool for early detection and treatment of these conditions, but it often relies on expensive optical motion capture systems. Recent advances in computer vision and deep learning have made more accessible and cost-effective solutions possible. In this study, we present a spatio-temporal transformer network that can estimate key gait parameters from RGB videos captured by a single-view camera. Our empirical assessments on a public dataset of cerebral palsy patients show that the proposed framework outperforms current state-of-the-art approaches in predicting general gait parameters (such as walking speed, Gait Deviation Index - GDI, and knee flexion angle at maximum extension), while using fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Musculoskeletal and cognitive impairments can make it difficult for patients to move around and cause psychological distress. Clinical gait analysis is a valuable tool for early detection and treatment of these conditions, but it often relies on expensive optical motion capture systems. Recent advances in computer vision and deep learning have made more accessible and cost-effective solutions possible. In this study, we present a spatio-temporal transformer network that can estimate key gait parameters from RGB videos captured by a single-view camera. Our empirical assessments on a public dataset of cerebral palsy patients show that the proposed framework outperforms current state-of-the-art approaches in predicting general gait parameters (such as walking speed, Gait Deviation Index - GDI, and knee flexion angle at maximum extension), while using fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Musculoskeletal and cognitive impairments can cause difficulty in moving around and lead to psychological distress. Early detection and treatment of these conditions is possible with clinical gait analysis, but it typically relies on expensive optical motion capture systems. Recent advances in computer vision and deep learning have allowed for more accessible and cost-effective solutions. In this study, we present a spatio-temporal transformer network that can estimate key gait parameters from RGB videos captured by a single-view camera. Our empirical assessments on a public dataset of cerebral palsy patients demonstrate that the proposed framework outperforms current state-of-the-art approaches in predicting general gait parameters (such as walking speed, Gait Deviation Index - GDI, and knee flexion angle at maximum extension), while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Musculoskeletal and cognitive impairments can cause difficulty in moving around and lead to psychological distress. Early detection and treatment of these conditions is possible with clinical gait analysis, but it typically relies on expensive optical motion capture systems. Recent advances in computer vision and deep learning have allowed for more accessible and cost-effective solutions. In this study, we present a spatio-temporal transformer network that can estimate key gait parameters from RGB videos captured by a single-view camera. Our empirical assessments on a public dataset of cerebral palsy patients demonstrate that the proposed framework outperforms current state-of-the-art approaches in predicting general gait parameters (such as walking speed, Gait Deviation Index - GDI, and knee flexion angle at maximum extension), while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Musculoskeletal and cognitive impairments can lead to difficulty in mobility and psychological distress. Early identification and management of these issues is possible through clinical gait analysis, but it usually relies on costly optical motion capture systems. Recent progress in computer vision and deep learning have led to more affordable and accessible solutions. In this study, we introduce a spatio-temporal transformer network that estimates key gait parameters from RGB videos captured by a single-view camera. Our empirical evaluation on a public dataset of cerebral palsy patients demonstrates that the proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters (e.g., walking speed, Gait Deviation Index - GDI, and knee flexion angle at maximum extension), while requiring less parameters and eliminating manual feature extraction."
        ],
        [
            "Musculoskeletal and cognitive impairments can lead to difficulty in mobility and psychological distress. Early identification and management of these issues is possible through clinical gait analysis, but it usually relies on costly optical motion capture systems. Recent progress in computer vision and deep learning have led to more affordable and accessible solutions. In this study, we introduce a spatio-temporal transformer network that estimates key gait parameters from RGB videos captured by a single-view camera. Our empirical evaluation on a public dataset of cerebral palsy patients demonstrates that the proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters (e.g., walking speed, Gait Deviation Index - GDI, and knee flexion angle at maximum extension), while requiring less parameters and eliminating manual feature extraction."
        ],
        [
            "Musculoskeletal and cognitive impairments can lead to difficulty in mobility and psychological distress. Early identification and management of these issues is possible through clinical gait analysis, but it usually relies on costly optical motion capture systems. Recent progress in computer vision and deep learning have led to more affordable and accessible solutions. In this study, we introduce a spatio-temporal transformer network that estimates key gait parameters from RGB videos captured by a single-view camera. Our empirical evaluation on a public dataset of cerebral palsy patients demonstrates that the proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters (e.g., walking speed, Gait Deviation Index - GDI, and knee flexion angle at maximum extension), while requiring less parameters and eliminating manual feature extraction."
        ],
        [
            "Musculoskeletal and cognitive impairments can lead to difficulty in mobility and psychological distress. Early identification and management of these issues is possible through clinical gait analysis, but it usually relies on costly optical motion capture systems. Recent progress in computer vision and deep learning have led to more affordable and accessible solutions. In this study, we introduce a spatio-temporal transformer network that estimates key gait parameters from RGB videos captured by a single-view camera. Our empirical evaluation on a public dataset of cerebral palsy patients demonstrates that the proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters (e.g., walking speed, Gait Deviation Index - GDI, and knee flexion angle at maximum extension), while requiring less parameters and eliminating manual feature extraction. The main contribution of this work is the introduction of a spatio-temporal transformer network for gait parameter estimation from RGB videos. The proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters, while requiring less parameters and eliminating manual feature extraction. This is an important contribution to the field of gait analysis, as it provides a more affordable and accessible solution for early identification and management of musculoskeletal and cognitive impairments."
        ],
        [
            "Recent progress in computer vision and deep learning has led to more affordable and accessible solutions for early identification and management of musculoskeletal and cognitive impairments. In this study, we introduce a spatio-temporal transformer network that estimates key gait parameters from RGB videos captured by a single-view camera. Our empirical evaluation on a public dataset of cerebral palsy patients demonstrates that the proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters (e.g., walking speed, Gait Deviation Index - GDI, and knee flexion angle at maximum extension), while requiring less parameters and eliminating manual feature extraction. The main contribution of this work is the introduction of a spatio-temporal transformer network for gait parameter estimation from RGB videos. The proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters, while requiring less parameters and eliminating manual feature extraction. This is an important contribution to the field of gait analysis, as it provides a more affordable and accessible solution for early identification and management of musculoskeletal and cognitive impairments."
        ],
        [
            "Recent progress in computer vision and deep learning has led to more affordable and accessible solutions for early identification and management of musculoskeletal and cognitive impairments. In this study, we introduce a spatio-temporal transformer network that estimates key gait parameters from RGB videos captured by a single-view camera. Our empirical evaluation on a public dataset of cerebral palsy patients demonstrates that the proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters (e.g., walking speed, Gait Deviation Index - GDI, and knee flexion angle at maximum extension), while requiring less parameters and eliminating manual feature extraction. The main contribution of this work is the introduction of a spatio-temporal transformer network for gait parameter estimation from RGB videos. The proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters, while requiring less parameters and eliminating manual feature extraction. This is an important contribution to the field of gait analysis, as it provides a more affordable and accessible solution for early identification and management of musculoskeletal and cognitive impairments."
        ],
        [
            "Recent advances in computer vision and deep learning have made it easier to identify and manage musculoskeletal and cognitive impairments early. In this study, we present a spatio-temporal transformer network that estimates key gait parameters from RGB videos recorded by a single-view camera. Our experiments on a public dataset of cerebral palsy patients show that the proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters (e.g., walking speed, Gait Deviation Index - GDI, and knee flexion angle at maximum extension), while requiring fewer parameters and eliminating manual feature extraction. The main contribution of this work is the introduction of a spatio-temporal transformer network for gait parameter estimation from RGB videos. The proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters, while requiring fewer parameters and eliminating manual feature extraction. This is an important contribution to the field of gait analysis, as it provides a more affordable and accessible solution for early identification and management of musculoskeletal and cognitive impairments."
        ],
        [
            "Advances in computer vision and deep learning have made it easier to identify and manage musculoskeletal and cognitive impairments early. In this study, we present a spatio-temporal transformer network that estimates key gait parameters from RGB videos recorded by a single-view camera. Our experiments on a public dataset of cerebral palsy patients show that the proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters (e.g., walking speed, Gait Deviation Index - GDI, and knee flexion angle at maximum extension), while requiring fewer parameters and eliminating manual feature extraction. The main contribution of this work is the introduction of a spatio-temporal transformer network for gait parameter estimation from RGB videos. The proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters, while requiring fewer parameters and eliminating manual feature extraction. This is an important contribution to the field of gait analysis, as it provides a more affordable and accessible solution for early identification and management of musculoskeletal and cognitive impairments."
        ],
        [
            "Recent advances in computer vision and deep learning have made it possible to identify and manage musculoskeletal and cognitive impairments at an early stage. In this study, we present a spatio-temporal transformer network that estimates key gait parameters from RGB videos recorded by a single-view camera. Our experiments on a public dataset of cerebral palsy patients demonstrate that the proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. This is achieved while requiring fewer parameters and eliminating the need for manual feature extraction. The main contribution of this work is the introduction of a spatio-temporal transformer network for gait parameter estimation from RGB videos. The proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters, while requiring fewer parameters and eliminating manual feature extraction. This is an important contribution to the field of gait analysis, as it provides a more affordable and accessible solution for early identification and management of musculoskeletal and cognitive impairments."
        ],
        [
            "Advances in computer vision and deep learning have made it possible to identify and manage musculoskeletal and cognitive impairments at an early stage. In this study, we present a spatio-temporal transformer network that estimates key gait parameters from RGB videos recorded by a single-view camera. Our experiments on a public dataset of cerebral palsy patients demonstrate that the proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. This is achieved while requiring fewer parameters and eliminating the need for manual feature extraction. The main contribution of this work is the introduction of a spatio-temporal transformer network for gait parameter estimation from RGB videos. The proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters, while requiring fewer parameters and eliminating manual feature extraction. This is an important contribution to the field of gait analysis, as it provides a more affordable and accessible solution for early identification and management of musculoskeletal and cognitive impairments."
        ],
        [
            "Advances in computer vision and deep learning have made it possible to identify and manage musculoskeletal and cognitive impairments at an early stage. In this study, we present a spatio-temporal transformer network that estimates key gait parameters from RGB videos recorded by a single-view camera. Our experiments on a public dataset of cerebral palsy patients demonstrate that the proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. This is achieved while requiring fewer parameters and eliminating the need for manual feature extraction. The main contribution of this work is the introduction of a spatio-temporal transformer network for gait parameter estimation from RGB videos. The proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters, while requiring fewer parameters and eliminating manual feature extraction. This is an important contribution to the field of gait analysis, as it provides a more affordable and accessible solution for early identification and management of musculoskeletal and cognitive impairments."
        ],
        [
            "Recent developments in computer vision and deep learning have enabled the early detection and management of musculoskeletal and cognitive impairments. In this study, a spatio-temporal transformer network is proposed to estimate key gait parameters from RGB videos recorded by a single-view camera. The experimental results on a public dataset of cerebral palsy patients show that the proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. This is achieved while requiring fewer parameters and eliminating the need for manual feature extraction. The main contribution of this work is the introduction of a spatio-temporal transformer network for gait parameter estimation from RGB videos. The proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters, while requiring fewer parameters and eliminating manual feature extraction. This is a significant contribution to the field of gait analysis, as it provides a more affordable and accessible solution for early identification and management of musculoskeletal and cognitive impairments."
        ],
        [
            "Recent advancements in computer vision and deep learning have made it possible to detect and manage musculoskeletal and cognitive impairments at an early stage. In this study, we propose a spatio-temporal transformer network for estimating key gait parameters from RGB videos recorded by a single-view camera. Our experimental results on a public dataset of cerebral palsy patients show that the proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. This is achieved with fewer parameters and without the need for manual feature extraction. Our main contribution is the introduction of a spatio-temporal transformer network for gait parameter estimation from RGB videos. The proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters, while requiring fewer parameters and eliminating manual feature extraction. This is a significant contribution to the field of gait analysis, as it provides a more affordable and accessible solution for early identification and management of musculoskeletal and cognitive impairments."
        ],
        [
            "Recent advancements in computer vision and deep learning have made it possible to detect and manage musculoskeletal and cognitive impairments at an early stage. In this study, we propose a spatio-temporal transformer network for estimating key gait parameters from RGB videos recorded by a single-view camera. Our experimental results on a public dataset of cerebral palsy patients show that the proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. This is achieved with fewer parameters and without the need for manual feature extraction. Our main contribution is the introduction of a spatio-temporal transformer network for gait parameter estimation from RGB videos. The proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters, while requiring fewer parameters and eliminating manual feature extraction. This is a significant contribution to the field of gait analysis, as it provides a more affordable and accessible solution for early identification and management of musculoskeletal and cognitive impairments."
        ],
        [
            "Recent developments in computer vision and deep learning have made it feasible to detect and manage musculoskeletal and cognitive impairments at an early stage. In this study, we suggest a spatio-temporal transformer network for estimating key gait parameters from RGB videos recorded by a single-view camera. Our experimental results on a public dataset of cerebral palsy patients show that the proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. This is achieved with fewer parameters and without the need for manual feature extraction. Our main contribution is the introduction of a spatio-temporal transformer network for gait parameter estimation from RGB videos. The proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters, while requiring fewer parameters and eliminating manual feature extraction. This is a substantial contribution to the field of gait analysis, as it provides a more economical and accessible solution for early identification and management of musculoskeletal and cognitive impairments."
        ],
        [
            "Recent advances in computer vision and deep learning have made it possible to detect and manage musculoskeletal and cognitive impairments at an early stage. In this study, we present a spatio-temporal transformer network for estimating key gait parameters from RGB videos recorded by a single-view camera. Our experimental results on a public dataset of cerebral palsy patients show that the proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. This is achieved with fewer parameters and without the need for manual feature extraction. Our main contribution is the introduction of a spatio-temporal transformer network for gait parameter estimation from RGB videos. The proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters, while requiring fewer parameters and eliminating manual feature extraction. This is a significant contribution to the field of gait analysis, as it provides a more cost-effective and accessible solution for early identification and management of musculoskeletal and cognitive impairments."
        ],
        [
            "Recent advances in computer vision and deep learning have made it possible to detect and manage musculoskeletal and cognitive impairments at an early stage. In this study, we present a spatio-temporal transformer network for estimating key gait parameters from RGB videos recorded by a single-view camera. Our experimental results on a public dataset of cerebral palsy patients show that the proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. This is achieved with fewer parameters and without the need for manual feature extraction. Our main contribution is the introduction of a spatio-temporal transformer network for gait parameter estimation from RGB videos. The proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters, while requiring fewer parameters and eliminating manual feature extraction. This is a significant contribution to the field of gait analysis, as it provides a more cost-effective and accessible solution for early identification and management of musculoskeletal and cognitive impairments."
        ],
        [
            "Recent advances in computer vision and deep learning have made it possible to detect and manage musculoskeletal and cognitive impairments at an early stage. In this study, we present a spatio-temporal transformer network for estimating key gait parameters from RGB videos recorded by a single-view camera. Our experimental results on a public dataset of cerebral palsy patients show that the proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. This is achieved with fewer parameters and without the need for manual feature extraction. Our main contribution is the introduction of a spatio-temporal transformer network for gait parameter estimation from RGB videos. The proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters, while requiring fewer parameters and eliminating manual feature extraction. This is a significant contribution to the field of gait analysis, as it provides a more cost-effective and accessible solution for early identification and management of musculoskeletal and cognitive impairments."
        ],
        [
            "Recent advances in computer vision and deep learning have made it possible to detect and manage musculoskeletal and cognitive impairments at an early stage. In this study, we present a spatio-temporal transformer network for estimating key gait parameters from RGB videos recorded by a single-view camera. Our experimental results on a public dataset of cerebral palsy patients show that the proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. This is achieved with fewer parameters and without the need for manual feature extraction. Our main contribution is the introduction of a spatio-temporal transformer network for gait parameter estimation from RGB videos. The proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters, while requiring fewer parameters and eliminating manual feature extraction. This is a significant contribution to the field of gait analysis, as it provides a more cost-effective and accessible solution for early identification and management of musculoskeletal and cognitive impairments."
        ],
        [
            "In recent years, advances in computer vision and deep learning have made it possible to detect and manage musculoskeletal and cognitive impairments at an early stage. One area where this technology has been particularly successful is in the field of gait analysis. In this study, we present a spatio-temporal transformer network for estimating key gait parameters from RGB videos recorded by a single-view camera. Our experimental results on a public dataset of cerebral palsy patients show that the proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. This is achieved with fewer parameters and without the need for manual feature extraction. Our main contribution is the introduction of a spatio-temporal transformer network for gait parameter estimation from RGB videos. The proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters, while requiring fewer parameters and eliminating manual feature extraction. This is a significant contribution to the field of gait analysis, as it provides a more cost-effective and accessible solution for early identification and management of musculoskeletal and cognitive impairments."
        ],
        [
            "In recent years, advances in computer vision and deep learning have made it possible to detect and manage musculoskeletal and cognitive impairments at an early stage. One area where this technology has been particularly successful is in the field of gait analysis. In this study, we present a spatio-temporal transformer network for estimating key gait parameters from RGB videos recorded by a single-view camera. Our experimental results on a public dataset of cerebral palsy patients show that the proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. This is achieved with fewer parameters and without the need for manual feature extraction. Our main contribution is the introduction of a spatio-temporal transformer network for gait parameter estimation from RGB videos. The proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters, while requiring fewer parameters and eliminating manual feature extraction. This is a significant contribution to the field of gait analysis, as it provides a more cost-effective and accessible solution for early identification and management of musculoskeletal and cognitive impairments."
        ],
        [
            "In recent years, computer vision and deep learning have made it possible to detect and manage musculoskeletal and cognitive impairments at an early stage. One area where this technology has been particularly successful is in the field of gait analysis. In this study, we present a spatio-temporal transformer network for estimating key gait parameters from RGB videos recorded by a single-view camera. Our experimental results on a public dataset of cerebral palsy patients show that the proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. This is achieved with fewer parameters and without the need for manual feature extraction. Our main contribution is the introduction of a spatio-temporal transformer network for gait parameter estimation from RGB videos. The proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters, while requiring fewer parameters and eliminating manual feature extraction. This is a significant contribution to the field of gait analysis, as it provides a more cost-effective and accessible solution for early identification and management of musculoskeletal and cognitive impairments."
        ],
        [
            "In recent years, computer vision and deep learning have made it possible to detect and manage musculoskeletal and cognitive impairments at an early stage. One area where this technology has been particularly successful is in the field of gait analysis. In this study, we present a spatio-temporal transformer network for estimating key gait parameters from RGB videos recorded by a single-view camera. Our experimental results on a public dataset of cerebral palsy patients show that the proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. This is achieved with fewer parameters and without the need for manual feature extraction. Our main contribution is the introduction of a spatio-temporal transformer network for gait parameter estimation from RGB videos. The proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters, while requiring fewer parameters and eliminating manual feature extraction. This is a significant contribution to the field of gait analysis, as it provides a more cost-effective and accessible solution for early identification and management of musculoskeletal and cognitive impairments."
        ],
        [
            "In recent years, computer vision and deep learning have made it possible to detect and manage musculoskeletal and cognitive impairments at an early stage. One area where this technology has been particularly successful is in the field of gait analysis. In this study, we present a spatio-temporal transformer network for estimating key gait parameters from RGB videos recorded by a single-view camera. Our experimental results on a public dataset of cerebral palsy patients show that the proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. This is achieved with fewer parameters and without the need for manual feature extraction. Our main contribution is the introduction of a spatio-temporal transformer network for gait parameter estimation from RGB videos. The proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters, while requiring fewer parameters and eliminating manual feature extraction. This is a significant contribution to the field of gait analysis, as it provides a more cost-effective and accessible solution for early identification and management of musculoskeletal and cognitive impairments."
        ],
        [
            "In recent years, computer vision and deep learning have made it possible to detect and manage musculoskeletal and cognitive impairments at an early stage. One area where this technology has been particularly successful is in the field of gait analysis. In this study, we present a spatio-temporal transformer network for estimating key gait parameters from RGB videos recorded by a single-view camera. Our experimental results on a public dataset of cerebral palsy patients show that the proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. This is achieved with fewer parameters and without the need for manual feature extraction. Our main contribution is the introduction of a spatio-temporal transformer network for gait parameter estimation from RGB videos. The proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters, while requiring fewer parameters and eliminating manual feature extraction. This is a significant contribution to the field of gait analysis, as it provides a more cost-effective and accessible solution for early identification and management of musculoskeletal and cognitive impairments."
        ],
        [
            "Computer vision and deep learning have made it possible to detect and manage musculoskeletal and cognitive impairments at an early stage. One area where this technology has been particularly successful is in the field of gait analysis. In this study, we present a spatio-temporal transformer network for estimating key gait parameters from RGB videos recorded by a single-view camera. Our experimental results on a public dataset of cerebral palsy patients show that the proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. This is achieved with fewer parameters and without the need for manual feature extraction. Our main contribution is the introduction of a spatio-temporal transformer network for gait parameter estimation from RGB videos. The proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters, while requiring fewer parameters and eliminating manual feature extraction. This is a significant contribution to the field of gait analysis, as it provides a more cost-effective and accessible solution for early identification and management of musculoskeletal and cognitive impairments."
        ],
        [
            "Early detection and management of musculoskeletal and cognitive impairments have been made possible with computer vision and deep learning. One area where this technology has been particularly successful is in gait analysis. In this study, we present a spatio-temporal transformer network for estimating key gait parameters from RGB videos recorded by a single-view camera. Our experimental results on a public dataset of cerebral palsy patients show that the proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. This is achieved with fewer parameters and without the need for manual feature extraction. Our main contribution is the introduction of a spatio-temporal transformer network for gait parameter estimation from RGB videos. The proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters, while requiring fewer parameters and eliminating manual feature extraction. This is a significant contribution to the field of gait analysis, as it provides a more cost-effective and accessible solution for early identification and management of musculoskeletal and cognitive impairments."
        ],
        [
            "The study presents a new method for estimating gait parameters from RGB videos using a single-view camera. The proposed spatio-temporal transformer network was tested on a public dataset of cerebral palsy patients and outperformed existing state-of-the-art methods in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. This was achieved with fewer parameters and without the need for manual feature extraction. The main contribution of the study is the introduction of a spatio-temporal transformer network for gait parameter estimation from RGB videos. The proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters, while requiring fewer parameters and eliminating manual feature extraction. This is a significant contribution to the field of gait analysis, as it provides a more cost-effective and accessible solution for early identification and management of musculoskeletal and cognitive impairments."
        ],
        [
            "A new method for estimating gait parameters from RGB videos using a single-view camera has been proposed in a recent study. The spatio-temporal transformer network developed by the researchers was tested on a public dataset of cerebral palsy patients, and it outperformed existing state-of-the-art methods in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. This was achieved with fewer parameters and without the need for manual feature extraction. The main contribution of the study is the introduction of a spatio-temporal transformer network for gait parameter estimation from RGB videos. The proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters, while requiring fewer parameters and eliminating manual feature extraction. This is a significant contribution to the field of gait analysis, as it provides a more cost-effective and accessible solution for early identification and management of musculoskeletal and cognitive impairments."
        ],
        [
            "A new method for estimating gait parameters from RGB videos using a single-view camera has been proposed. The spatio-temporal transformer network developed by the researchers was tested on a public dataset of cerebral palsy patients, and it outperformed existing state-of-the-art methods in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. This was achieved with fewer parameters and without the need for manual feature extraction. The main contribution of the study is the introduction of a spatio-temporal transformer network for gait parameter estimation from RGB videos. The proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters, while requiring fewer parameters and eliminating manual feature extraction. This is a significant contribution to the field of gait analysis, as it provides a more cost-effective and accessible solution for early identification and management of musculoskeletal and cognitive impairments."
        ],
        [
            "A novel approach to gait parameter estimation from RGB videos using a single-view camera is presented. The spatio-temporal transformer network developed by the researchers outperformed existing state-of-the-art methods in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. This was achieved with fewer parameters and without the need for manual feature extraction. The main contribution of the study is the introduction of a spatio-temporal transformer network for gait parameter estimation from RGB videos. The proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters, while requiring fewer parameters and eliminating manual feature extraction. This is a significant contribution to the field of gait analysis, as it provides a more cost-effective and accessible solution for early identification and management of musculoskeletal and cognitive impairments."
        ],
        [
            "A novel approach to gait parameter estimation from RGB videos using a single-view camera has been developed. The spatio-temporal transformer network developed by the researchers has been shown to outperform existing state-of-the-art methods in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. This was achieved with fewer parameters and without the need for manual feature extraction. The main contribution of the study is the introduction of a spatio-temporal transformer network for gait parameter estimation from RGB videos. The proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters, while requiring fewer parameters and eliminating manual feature extraction. This is a significant contribution to the field of gait analysis, as it provides a more cost-effective and accessible solution for early identification and management of musculoskeletal and cognitive impairments."
        ],
        [
            "A novel approach to gait parameter estimation from RGB videos using a single-view camera has been developed. The spatio-temporal transformer network developed by the researchers has been shown to outperform existing state-of-the-art methods in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. This was achieved with fewer parameters and without the need for manual feature extraction. The main contribution of the study is the introduction of a spatio-temporal transformer network for gait parameter estimation from RGB videos. The proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters, while requiring fewer parameters and eliminating manual feature extraction. This is a significant contribution to the field of gait analysis, as it provides a more cost-effective and accessible solution for early identification and management of musculoskeletal and cognitive impairments."
        ],
        [
            "A novel approach for gait parameter estimation from RGB videos using a single-view camera has been developed. The spatio-temporal transformer network developed by the researchers has been shown to outperform existing state-of-the-art methods in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. This was achieved with fewer parameters and without the need for manual feature extraction. The main contribution of the study is the introduction of a spatio-temporal transformer network for gait parameter estimation from RGB videos. The proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters, while requiring fewer parameters and eliminating manual feature extraction. This is a significant contribution to the field of gait analysis, as it provides a more cost-effective and accessible solution for early identification and management of musculoskeletal and cognitive impairments."
        ],
        [
            "A novel approach for gait parameter estimation from RGB videos has been developed using a single-view camera. The spatio-temporal transformer network developed by the researchers outperforms existing state-of-the-art methods in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. This was achieved with fewer parameters and without the need for manual feature extraction. The main contribution of the study is the introduction of a spatio-temporal transformer network for gait parameter estimation from RGB videos. The proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters, while requiring fewer parameters and eliminating manual feature extraction. This is a significant contribution to the field of gait analysis, as it provides a more cost-effective and accessible solution for early identification and management of musculoskeletal and cognitive impairments."
        ],
        [
            "A novel approach for estimating gait parameters from RGB videos has been developed using a single-view camera. The spatio-temporal transformer network developed by the researchers outperforms existing state-of-the-art methods in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. This was achieved with fewer parameters and without the need for manual feature extraction. The main contribution of the study is the introduction of a spatio-temporal transformer network for gait parameter estimation from RGB videos. The proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters, while requiring fewer parameters and eliminating manual feature extraction. This is a significant contribution to the field of gait analysis, as it provides a more cost-effective and accessible solution for early identification and management of musculoskeletal and cognitive impairments."
        ],
        [
            "A novel approach for estimating gait parameters from RGB videos has been developed using a single-view camera. The spatio-temporal transformer network developed by the researchers outperforms existing state-of-the-art methods in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. This was achieved with fewer parameters and without the need for manual feature extraction. The main contribution of the study is the introduction of a spatio-temporal transformer network for gait parameter estimation from RGB videos. The proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters, while requiring fewer parameters and eliminating manual feature extraction. This is a significant contribution to the field of gait analysis, as it provides a more cost-effective and accessible solution for early identification and management of musculoskeletal and cognitive impairments."
        ],
        [
            "We have developed a novel approach to estimate gait parameters from RGB videos using only a single-view camera. Our spatio-temporal transformer network outperforms existing state-of-the-art methods for predicting general gait parameters like walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. We achieved this without the need for manual feature extraction and with fewer parameters. Our main contribution is introducing a spatio-temporal transformer network for gait parameter estimation from RGB videos. Our proposed framework outperforms existing state-of-the-art methods in predicting general gait parameters, while requiring fewer parameters and eliminating manual feature extraction. This is a significant contribution to the field of gait analysis, as it provides a more cost-effective and accessible solution for early identification and management of musculoskeletal and cognitive impairments."
        ],
        [
            "We present a novel approach for estimating gait parameters from RGB videos using a single-view camera. Our spatio-temporal transformer network outperforms existing methods for predicting general gait parameters like walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. The network requires fewer parameters and eliminates manual feature extraction, making it a more cost-effective and accessible solution for early identification and management of musculoskeletal and cognitive impairments."
        ],
        [
            "We propose a new method for estimating gait parameters from RGB videos captured with a single-view camera. Our spatio-temporal transformer network outperforms existing methods in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. The network is designed to reduce the number of parameters and eliminate manual feature extraction, making it a cost-effective and accessible tool for early identification and management of musculoskeletal and cognitive impairments."
        ]
    ]
}