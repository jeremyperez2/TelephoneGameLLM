{
    "adjacency_matrix": [
        [
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0
        ]
    ],
    "prompt_init": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "prompt_update": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "personality_list": [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        ""
    ],
    "format_prompt": [
        ""
    ],
    "initial_story": "musculoskeletal diseases and cognitive impairments in patients lead todifficulties in movement as well as negative effects on their psychologicalhealth. clinical gait analysis, a vital tool for early diagnosis and treatment,traditionally relies on expensive optical motion capture systems. recentadvances in computer vision and deep learning have opened the door to moreaccessible and cost-effective alternatives. this paper introduces a novelspatio-temporal transformer network to estimate critical gait parameters fromrgb videos captured by a single-view camera. empirical evaluations on a publicdataset of cerebral palsy patients indicate that the proposed frameworksurpasses current state-of-the-art approaches and show significant improvementsin predicting general gait parameters (including walking speed, gait deviationindex - gdi, and knee flexion angle at maximum extension), while utilizingfewer parameters and alleviating the need for manual feature extraction. ",
    "stories": [
        [
            "Musculoskeletal diseases and cognitive impairments can lead to difficulties in movement and negative effects on psychological health in patients. Clinical gait analysis, an important tool for early diagnosis and treatment, traditionally requires expensive optical motion capture systems. However, recent advances in computer vision and deep learning have made more accessible and cost-effective alternatives possible. In this paper, we introduce a novel spatio-temporal transformer network to estimate critical gait parameters from RGB videos captured by a single-view camera. Empirical evaluations on a public dataset of cerebral palsy patients show that the proposed framework outperforms current state-of-the-art approaches and shows significant improvements in predicting general gait parameters (including walking speed, gait deviation index - GDI, and knee flexion angle at maximum extension), while using fewer parameters and avoiding the need for manual feature extraction."
        ],
        [
            "Musculoskeletal diseases and cognitive impairments can lead to difficulties in movement and negative effects on psychological health in patients. Clinical gait analysis, an important tool for early diagnosis and treatment, traditionally requires expensive optical motion capture systems. However, recent advances in computer vision and deep learning have made more accessible and cost-effective alternatives possible. In this paper, we introduce a novel spatio-temporal transformer network to estimate critical gait parameters from RGB videos captured by a single-view camera. Empirical evaluations on a public dataset of cerebral palsy patients show that the proposed framework outperforms current state-of-the-art approaches and shows significant improvements in predicting general gait parameters (including walking speed, gait deviation index - GDI, and knee flexion angle at maximum extension), while using fewer parameters and avoiding the need for manual feature extraction."
        ],
        [
            "Musculoskeletal diseases and cognitive impairments can lead to difficulties in movement and negative effects on psychological health in patients. Clinical gait analysis, an important tool for early diagnosis and treatment, traditionally requires expensive optical motion capture systems. However, recent advances in computer vision and deep learning have made more accessible and cost-effective alternatives possible. In this paper, we introduce a novel spatio-temporal transformer network to estimate critical gait parameters from RGB videos captured by a single-view camera. Empirical evaluations on a public dataset of cerebral palsy patients show that the proposed framework outperforms current state-of-the-art approaches and shows significant improvements in predicting general gait parameters (including walking speed, gait deviation index - GDI, and knee flexion angle at maximum extension), while using fewer parameters and avoiding the need for manual feature extraction."
        ],
        [
            "Musculoskeletal diseases and cognitive impairments can lead to difficulties in movement and negative effects on psychological health in patients. Clinical gait analysis, an important tool for early diagnosis and treatment, traditionally requires expensive optical motion capture systems. However, recent advances in computer vision and deep learning have made more accessible and cost-effective alternatives possible. In this paper, we introduce a novel spatio-temporal transformer network to estimate critical gait parameters from RGB videos captured by a single-view camera. Empirical evaluations on a public dataset of cerebral palsy patients show that the proposed framework outperforms current state-of-the-art approaches and shows significant improvements in predicting general gait parameters (including walking speed, gait deviation index - GDI, and knee flexion angle at maximum extension), while using fewer parameters and avoiding the need for manual feature extraction."
        ],
        [
            "Musculoskeletal diseases and cognitive impairments can lead to difficulties in movement and negative effects on psychological health in patients. Clinical gait analysis, an important tool for early diagnosis and treatment, traditionally requires expensive optical motion capture systems. However, recent advances in computer vision and deep learning have made more accessible and cost-effective alternatives possible. In this paper, we introduce a novel spatio-temporal transformer network to estimate critical gait parameters from RGB videos captured by a single-view camera. Empirical evaluations on a public dataset of cerebral palsy patients show that the proposed framework outperforms current state-of-the-art approaches and shows significant improvements in predicting general gait parameters (including walking speed, gait deviation index - GDI, and knee flexion angle at maximum extension), while using fewer parameters and avoiding the need for manual feature extraction."
        ],
        [
            "Musculoskeletal illnesses and cognitive deficiencies can result in mobility difficulties and adverse psychological impacts on affected individuals. Traditional clinical gait analysis, an essential tool for early diagnosis and treatment, has historically required the use of costly optical motion capture systems. Nonetheless, recent developments in computer vision and deep learning have made more accessible and cost-effective alternatives available. In this paper, we propose a novel spatiotemporal transformer network for predicting critical gait parameters from RGB videos captured by a single-view camera. Empirical evaluations on a publicly available dataset of cerebral palsy patients demonstrate that the proposed framework outperforms current state-of-the-art approaches and achieves substantial improvements in predicting general gait parameters (including walking speed, gait deviation index - GDI, and knee flexion angle at maximum extension), while using fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Musculoskeletal illnesses and cognitive deficiencies can lead to mobility issues and negative psychological effects on those affected. Traditional clinical gait analysis, a key tool for early detection and treatment, typically requires the use of expensive optical motion capture systems. However, recent advancements in computer vision and deep learning have made more accessible and cost-effective solutions available. In this paper, we present a novel spatiotemporal transformer network for predicting important gait parameters from RGB videos captured by a single-view camera. Empirical evaluations on a publicly available dataset of cerebral palsy patients show that the proposed framework outperforms current state-of-the-art approaches and achieves significant improvements in predicting general gait parameters (such as walking speed, gait deviation index - GDI, and knee flexion angle at maximum extension), while using fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Mobility issues and psychological effects caused by musculoskeletal illnesses and cognitive deficiencies can be early detected and treated using traditional clinical gait analysis. However, this process requires the use of expensive optical motion capture systems. With recent advancements in computer vision and deep learning, more accessible and cost-effective solutions are now available. In this paper, we present a novel spatiotemporal transformer network for predicting important gait parameters from RGB videos captured by a single-view camera. Empirical evaluations on a publicly available dataset of cerebral palsy patients show that the proposed framework outperforms current state-of-the-art approaches and achieves significant improvements in predicting general gait parameters (such as walking speed, gait deviation index - GDI, and knee flexion angle at maximum extension), while using fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Mobility issues and psychological effects caused by musculoskeletal illnesses and cognitive deficiencies can be early detected and treated using traditional clinical gait analysis. However, this process requires the use of expensive optical motion capture systems. With recent advancements in computer vision and deep learning, more accessible and cost-effective solutions are now available. In this paper, we present a novel spatiotemporal transformer network for predicting important gait parameters from RGB videos captured by a single-view camera. Empirical evaluations on a publicly available dataset of cerebral palsy patients show that the proposed framework outperforms current state-of-the-art approaches and achieves significant improvements in predicting general gait parameters (such as walking speed, gait deviation index - GDI, and knee flexion angle at maximum extension), while using fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Mobility issues and psychological effects caused by musculoskeletal illnesses and cognitive deficiencies can be early detected and treated using traditional clinical gait analysis. However, this process requires the use of expensive optical motion capture systems. With recent advancements in computer vision and deep learning, more accessible and cost-effective solutions are now available. In this paper, we present a novel spatiotemporal transformer network for predicting important gait parameters from RGB videos captured by a single-view camera. Empirical evaluations on a publicly available dataset of cerebral palsy patients show that the proposed framework outperforms current state-of-the-art approaches and achieves significant improvements in predicting general gait parameters (such as walking speed, gait deviation index - GDI, and knee flexion angle at maximum extension), while using fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Sufferers of musculoskeletal diseases and cognitive impairments often experience mobility issues and psychological effects, which can be detected and treated early through traditional clinical gait analysis. Unfortunately, this process requires the use of expensive optical motion capture systems. With the advancement of computer vision and deep learning, more accessible and cost-effective solutions are now available. In this paper, we propose a novel spatiotemporal transformer network for predicting important gait parameters from RGB videos captured by a single-view camera. Our empirical evaluation on a publicly available dataset of cerebral palsy patients demonstrates that our proposed framework outperforms current state-of-the-art approaches, achieving significant improvements in predicting general gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Moreover, our approach requires fewer parameters and eliminates the need for manual feature extraction."
        ],
        [
            "People suffering from musculoskeletal diseases and cognitive impairments often have difficulty moving around and may experience psychological effects. These issues can be identified and treated early on through traditional clinical gait analysis. Unfortunately, this process typically involves using expensive optical motion capture systems. However, with advances in computer vision and deep learning, more accessible and cost-effective solutions are now available. In this paper, we suggest a new type of spatiotemporal transformer network that can predict important gait parameters from RGB videos taken by a single-view camera. Our experiments with a public dataset of cerebral palsy patients show that our proposed framework outperforms current state-of-the-art approaches and achieves significant improvements in predicting general gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Additionally, our approach requires fewer parameters and eliminates the need for manual feature extraction."
        ],
        [
            "People suffering from musculoskeletal diseases and cognitive impairments often have difficulty moving around and may experience psychological effects. These issues can be identified and treated early on through traditional clinical gait analysis. Unfortunately, this process typically involves using expensive optical motion capture systems. However, with advances in computer vision and deep learning, more accessible and cost-effective solutions are now available. In this paper, we suggest a new type of spatiotemporal transformer network that can predict important gait parameters from RGB videos taken by a single-view camera. Our experiments with a public dataset of cerebral palsy patients show that our proposed framework outperforms current state-of-the-art approaches and achieves significant improvements in predicting general gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Additionally, our approach requires fewer parameters and eliminates the need for manual feature extraction."
        ],
        [
            "People who suffer from musculoskeletal diseases and cognitive impairments often have difficulty moving around, which can lead to psychological effects. Traditional clinical gait analysis can help identify and treat these issues early on, but it typically involves expensive optical motion capture systems. However, recent advances in computer vision and deep learning have made more accessible and cost-effective solutions possible. In this paper, we propose a new type of spatiotemporal transformer network that can predict important gait parameters from RGB videos taken by a single-view camera. Our experiments on a public dataset of cerebral palsy patients show that our proposed framework outperforms current state-of-the-art approaches and significantly improves the prediction of general gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Our approach also requires fewer parameters and eliminates the need for manual feature extraction."
        ],
        [
            "People who suffer from musculoskeletal diseases and cognitive impairments often have difficulty moving around, which can lead to psychological effects. Traditional clinical gait analysis can help identify and treat these issues early on, but it typically involves expensive optical motion capture systems. However, recent advances in computer vision and deep learning have made more accessible and cost-effective solutions possible. In this paper, we propose a new type of spatiotemporal transformer network that can predict important gait parameters from RGB videos taken by a single-view camera. Our experiments on a public dataset of cerebral palsy patients show that our proposed framework outperforms current state-of-the-art approaches and significantly improves the prediction of general gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Our approach also requires fewer parameters and eliminates the need for manual feature extraction."
        ],
        [
            "Gait analysis is an important tool for diagnosing and treating musculoskeletal and cognitive impairments. Traditional methods of gait analysis, such as optical motion capture, can be expensive and may not be accessible to all patients. However, recent advances in computer vision and deep learning have made more affordable and accessible options available. In this paper, we propose a spatiotemporal transformer network that can predict gait parameters from RGB videos taken by a single-view camera. Our experiments on a dataset of cerebral palsy patients show that our proposed framework outperforms current state-of-the-art approaches and significantly improves the prediction of important gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Additionally, our approach requires fewer parameters and eliminates the need for manual feature extraction."
        ],
        [
            "Gait analysis is an important tool for diagnosing and treating musculoskeletal and cognitive impairments. However, traditional methods of gait analysis, such as optical motion capture, can be expensive and may not be accessible to all patients. Recent advances in computer vision and deep learning have made more affordable and accessible options available. In this paper, we propose a spatiotemporal transformer network that can predict gait parameters from RGB videos taken by a single-view camera. Our experiments on a dataset of cerebral palsy patients show that our proposed framework outperforms current state-of-the-art approaches and significantly improves the prediction of important gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Additionally, our approach requires fewer parameters and eliminates the need for manual feature extraction."
        ],
        [
            "Gait analysis is an important tool for diagnosing and treating musculoskeletal and cognitive impairments. However, traditional methods of gait analysis, such as optical motion capture, can be expensive and may not be accessible to all patients. Recent advances in computer vision and deep learning have made more affordable and accessible options available. In this paper, we propose a spatiotemporal transformer network that can predict gait parameters from RGB videos taken by a single-view camera. Our experiments on a dataset of cerebral palsy patients show that our proposed framework outperforms current state-of-the-art approaches and significantly improves the prediction of important gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Additionally, our approach requires fewer parameters and eliminates the need for manual feature extraction."
        ],
        [
            "Gait analysis is an important tool for diagnosing and treating musculoskeletal and cognitive impairments. However, traditional methods of gait analysis, such as optical motion capture, can be expensive and may not be accessible to all patients. Recent advances in computer vision and deep learning have made more affordable and accessible options available. In this paper, we propose a spatiotemporal transformer network that can predict gait parameters from RGB videos taken by a single-view camera. Our experiments on a dataset of cerebral palsy patients show that our proposed framework outperforms current state-of-the-art approaches and significantly improves the prediction of important gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Additionally, our approach requires fewer parameters and eliminates the need for manual feature extraction."
        ],
        [
            "Gait analysis is an important tool for diagnosing and treating musculoskeletal and cognitive impairments. However, traditional methods of gait analysis, such as optical motion capture, can be expensive and may not be accessible to all patients. Recent advances in computer vision and deep learning have made more affordable and accessible options available. In this paper, we propose a spatiotemporal transformer network that can predict gait parameters from RGB videos taken by a single-view camera. Our experiments on a dataset of cerebral palsy patients show that our proposed framework outperforms current state-of-the-art approaches and significantly improves the prediction of important gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Additionally, our approach requires fewer parameters and eliminates the need for manual feature extraction."
        ],
        [
            "Gait analysis is an essential tool for diagnosing and treating musculoskeletal and cognitive impairments. However, traditional methods of gait analysis, such as optical motion capture, can be expensive and may not be accessible to all patients. Recent advances in computer vision and deep learning have made more affordable and accessible options available. In this paper, we propose a spatiotemporal transformer network that can predict gait parameters from RGB videos taken by a single-view camera. Our experiments on a dataset of cerebral palsy patients show that our proposed framework outperforms current state-of-the-art approaches and significantly improves the prediction of important gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Additionally, our approach requires fewer parameters and eliminates the need for manual feature extraction."
        ],
        [
            "Gait analysis is an essential tool for diagnosing and treating musculoskeletal and cognitive impairments. However, traditional methods of gait analysis, such as optical motion capture, can be expensive and may not be accessible to all patients. Recent advances in computer vision and deep learning have made more affordable and accessible options available. In this paper, we propose a spatiotemporal transformer network that can predict gait parameters from RGB videos taken by a single-view camera. Our experiments on a dataset of cerebral palsy patients show that our proposed framework outperforms current state-of-the-art approaches and significantly improves the prediction of important gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Additionally, our approach requires fewer parameters and eliminates the need for manual feature extraction."
        ],
        [
            "Gait analysis is a crucial tool for identifying and treating musculoskeletal and cognitive issues. However, traditional techniques like optical motion capture can be pricey and may not be available to everyone. Fortunately, recent breakthroughs in computer vision and deep learning have made cheaper and more accessible alternatives available. In this paper, we propose a spatiotemporal transformer network that can predict gait parameters from RGB videos taken by a single-view camera. Our experiments on a dataset of cerebral palsy patients demonstrate that our proposed framework outperforms current state-of-the-art approaches and considerably improves the prediction of important gait parameters like walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Moreover, our approach needs fewer parameters and eliminates the need for manual feature extraction."
        ],
        [
            "Gait analysis is crucial in identifying and treating musculoskeletal and cognitive problems. Unfortunately, traditional methods like optical motion capture can be costly and may not be available to everyone. Fortunately, recent advances in computer vision and deep learning have made affordable and accessible alternatives available. In this paper, we suggest a spatiotemporal transformer network that can predict gait parameters from RGB videos taken by a single-view camera. Our experiments on a dataset of cerebral palsy patients show that our proposed framework outperforms current state-of-the-art approaches and significantly improves the prediction of important gait parameters like walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Furthermore, our approach requires fewer parameters and eliminates the need for manual feature extraction."
        ],
        [
            "Gait analysis is an important tool for identifying and treating musculoskeletal and cognitive problems. Unfortunately, traditional methods such as optical motion capture can be expensive and may not be accessible to everyone. Fortunately, recent advances in computer vision and deep learning have made affordable and accessible alternatives available. In this paper, we propose a spatiotemporal transformer network that can predict gait parameters from RGB videos captured by a single-view camera. Our experiments on a dataset of cerebral palsy patients show that our proposed framework outperforms current state-of-the-art approaches and significantly improves the prediction of important gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Moreover, our approach requires fewer parameters and eliminates the need for manual feature extraction."
        ],
        [
            "The use of gait analysis to identify and treat musculoskeletal and cognitive issues is an important tool. Unfortunately, traditional methods such as optical motion capture can be costly and may not be available to everyone. Luckily, recent advances in computer vision and deep learning have made more affordable and accessible alternatives possible. In this paper, we suggest a spatiotemporal transformer network that can anticipate gait parameters from RGB videos captured by a single-view camera. Our experiments on a dataset of cerebral palsy patients demonstrate that our proposed framework surpasses current state-of-the-art methods and dramatically improves the prediction of critical gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Furthermore, our approach necessitates fewer parameters and eliminates the need for manual feature extraction."
        ],
        [
            "Gait analysis is an essential tool for identifying and treating musculoskeletal and cognitive issues, but traditional methods such as optical motion capture can be expensive and inaccessible to some. Fortunately, recent developments in computer vision and deep learning have made more cost-effective and accessible alternatives possible. In this paper, we present a spatiotemporal transformer network that can predict gait parameters from RGB videos captured by a single-view camera. Our experiments on a dataset of cerebral palsy patients show that our proposed framework outperforms current state-of-the-art methods and significantly improves the prediction of key gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Moreover, our approach requires fewer parameters and eliminates the need for manual feature extraction."
        ],
        [
            "Gait analysis is an important tool for diagnosing and treating musculoskeletal and cognitive disorders, but traditional methods such as optical motion capture can be expensive and difficult to access. Luckily, recent advancements in computer vision and deep learning have made more affordable and accessible options available. In this study, we present a spatiotemporal transformer network that can predict gait parameters from RGB videos captured by a single-view camera. Our experiments on a dataset of cerebral palsy patients show that our proposed framework outperforms existing state-of-the-art methods and significantly improves the prediction of key gait parameters like walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. In addition, our approach requires fewer parameters and eliminates the need for manual feature extraction."
        ],
        [
            "The use of gait analysis has become increasingly popular in the diagnosis and treatment of musculoskeletal and cognitive disorders. However, traditional methods such as optical motion capture are expensive and require specialized equipment, making them difficult to access. Recent advancements in computer vision and deep learning have made more affordable and accessible options available. In this study, we present a spatiotemporal transformer network that can predict gait parameters from RGB videos captured by a single-view camera. Our experiments on a dataset of cerebral palsy patients show that our proposed framework outperforms existing state-of-the-art methods and significantly improves the prediction of key gait parameters like walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. In addition, our approach requires fewer parameters and eliminates the need for manual feature extraction, making it a more efficient and cost-effective option."
        ],
        [
            "Advances in computer vision and deep learning have enabled researchers to develop more affordable and accessible methods of gait analysis. These techniques, such as spatiotemporal transformer networks, can predict gait parameters from RGB videos captured by a single-view camera. Our study demonstrates that this proposed framework outperforms existing state-of-the-art methods and significantly improves the prediction of key gait parameters like walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. This approach also reduces the number of required parameters and eliminates the need for manual feature extraction, making it a more efficient and cost-effective option for gait analysis."
        ],
        [
            "Recent breakthroughs in computer vision and deep learning have paved the way for the development of more accessible and affordable methods for gait analysis. Techniques like spatiotemporal transformer networks have been used to accurately predict gait parameters from RGB videos taken from a single-view camera. Our study demonstrates that this proposed framework outperforms existing state-of-the-art methods and significantly improves the prediction of critical gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. This approach requires fewer parameters and eliminates the need for manual feature extraction, making it a more efficient and cost-effective option for gait analysis."
        ],
        [
            "In recent years, the fields of computer vision and deep learning have made significant strides in the development of more accessible and affordable methods for gait analysis. Spatiotemporal transformer networks have been used to predict gait parameters from RGB videos captured by a single-view camera. Our study has shown that the proposed framework outperforms existing state-of-the-art methods and significantly improves the prediction of critical gait parameters, including walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. This approach requires fewer parameters and eliminates the need for manual feature extraction, making it a more efficient and cost-effective option for gait analysis."
        ],
        [
            "The use of deep learning and computer vision for gait analysis has been a hot topic in recent years. One of the most promising developments in this field is the use of spatiotemporal transformer networks to predict gait parameters from RGB videos captured by a single-view camera. Our study has shown that this framework outperforms existing state-of-the-art methods and significantly improves the prediction of critical gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. This approach is more efficient and cost-effective because it requires fewer parameters and eliminates the need for manual feature extraction."
        ],
        [
            "In recent years, the use of deep learning and computer vision for gait analysis has been a hot topic. One of the most promising developments in this field is the use of spatiotemporal transformer networks to predict gait parameters from RGB videos captured by a single-view camera. Our study has shown that this framework outperforms existing state-of-the-art methods and significantly improves the prediction of critical gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. This approach is more efficient and cost-effective because it requires fewer parameters and eliminates the need for manual feature extraction."
        ],
        [
            "Gait analysis using deep learning and computer vision has become increasingly popular in recent years. One of the most promising advancements in this field is the use of spatiotemporal transformer networks to predict gait parameters from RGB videos captured by a single-view camera. Our research has demonstrated that this framework outperforms existing state-of-the-art methods and significantly improves the prediction of critical gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. This approach is more efficient and cost-effective as it requires fewer parameters and eliminates the need for manual feature extraction."
        ],
        [
            "Gait analysis using deep learning and computer vision has become increasingly popular in recent years. One of the most promising advancements in this field is the use of spatiotemporal transformer networks to predict gait parameters from RGB videos captured by a single-view camera. Our research has demonstrated that this framework outperforms existing state-of-the-art methods and significantly improves the prediction of critical gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. This approach is more efficient and cost-effective as it requires fewer parameters and eliminates the need for manual feature extraction."
        ],
        [
            "Gait analysis using deep learning and computer vision has become increasingly popular in recent years. One of the most promising advancements in this field is the use of spatiotemporal transformer networks to predict gait parameters from RGB videos captured by a single-view camera. Our research has demonstrated that this framework outperforms existing state-of-the-art methods and significantly improves the prediction of critical gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. This approach is more efficient and cost-effective as it requires fewer parameters and eliminates the need for manual feature extraction."
        ],
        [
            "In recent years, gait analysis using deep learning and computer vision has become more prevalent. One of the most promising developments in this field is the use of spatiotemporal transformer networks to predict gait parameters from RGB videos captured by a single-view camera. Our research has shown that this framework outperforms existing state-of-the-art methods and significantly improves the prediction of critical gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. This approach is more efficient and cost-effective as it requires fewer parameters and eliminates the need for manual feature extraction."
        ],
        [
            "Over the last few years, deep learning and computer vision have been increasingly used for gait analysis. Recently, a promising development in this field is the use of spatiotemporal transformer networks for predicting gait parameters from RGB videos captured by a single-view camera. Our research has demonstrated that this framework outperforms existing state-of-the-art methods and significantly improves the prediction of critical gait parameters, such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. This approach is more efficient and cost-effective as it requires fewer parameters and eliminates the need for manual feature extraction."
        ],
        [
            "Over the last few years, deep learning and computer vision have been increasingly used for gait analysis. Recently, a promising development in this field is the use of spatiotemporal transformer networks for predicting gait parameters from RGB videos captured by a single-view camera. Our research has demonstrated that this framework outperforms existing state-of-the-art methods and significantly improves the prediction of critical gait parameters, such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. This approach is more efficient and cost-effective as it requires fewer parameters and eliminates the need for manual feature extraction."
        ],
        [
            "In recent years, there has been a growing interest in using deep learning and computer vision for gait analysis. One of the most promising developments in this field is the use of spatiotemporal transformer networks for predicting gait parameters from RGB videos captured by a single-view camera. Our research has shown that this framework outperforms existing state-of-the-art methods and significantly improves the prediction of critical gait parameters, such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. This approach is more efficient and cost-effective as it requires fewer parameters and eliminates the need for manual feature extraction."
        ],
        [
            "In recent years, there has been a growing interest in using deep learning and computer vision for gait analysis. One of the most promising developments in this field is the use of spatiotemporal transformer networks for predicting gait parameters from RGB videos captured by a single-view camera. Our research has shown that this framework outperforms existing state-of-the-art methods and significantly improves the prediction of critical gait parameters, such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. This approach is more efficient and cost-effective as it requires fewer parameters and eliminates the need for manual feature extraction."
        ],
        [
            "In recent years, researchers have shown increasing interest in the application of deep learning and computer vision techniques for gait analysis. One of the most promising developments in this area is the use of spatiotemporal transformer networks for predicting gait parameters from RGB videos captured by a single-view camera. The results of our study have demonstrated that this framework outperforms existing state-of-the-art methods, significantly improving the prediction of crucial gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. This approach is more efficient and cost-effective as it requires fewer parameters and eliminates the need for manual feature extraction."
        ],
        [
            "In recent years, there has been increasing interest among researchers in the application of deep learning and computer vision techniques for gait analysis. One of the most promising developments in this area is the use of spatiotemporal transformer networks for predicting gait parameters from RGB videos captured by a single-view camera. The results of our study have shown that this framework outperforms existing state-of-the-art methods, significantly improving the prediction of important gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. This approach is more efficient and cost-effective, as it requires fewer parameters and eliminates the need for manual feature extraction."
        ],
        [
            "In recent years, researchers have increasingly shown interest in applying deep learning and computer vision techniques to gait analysis. One of the most promising developments in this field is the use of spatiotemporal transformer networks to predict gait parameters from RGB videos captured by a single-view camera. Our study found that this framework outperforms existing state-of-the-art methods, resulting in significantly better predictions of important gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. This approach is more efficient and cost-effective as it requires fewer parameters and eliminates the need for manual feature extraction."
        ],
        [
            "Recent advances in deep learning and computer vision have led to an increased interest in applying these techniques to gait analysis. Spatiotemporal transformer networks have been identified as a promising method for predicting gait parameters from RGB videos captured by a single-view camera. This framework has been found to outperform existing state-of-the-art methods, resulting in significantly better predictions of gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. This approach is more efficient and cost-effective as it requires fewer parameters and eliminates the need for manual feature extraction."
        ],
        [
            "The application of deep learning and computer vision techniques to gait analysis has gained traction in recent years, due to advancements in these fields. Spatiotemporal transformer networks have been identified as a potential method for predicting gait parameters from RGB videos captured by a single-view camera. This framework has been found to outperform existing state-of-the-art methods, resulting in significantly better predictions of gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. This approach is more efficient and cost-effective, as it requires fewer parameters and eliminates the need for manual feature extraction."
        ],
        [
            "Spatiotemporal transformer networks have been identified as a potential method for predicting gait parameters from RGB videos captured by a single-view camera. This framework has been found to outperform existing state-of-the-art methods, resulting in significantly better predictions of gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. This approach is more efficient and cost-effective, as it requires fewer parameters and eliminates the need for manual feature extraction."
        ],
        [
            "Spatiotemporal transformer networks have been identified as a potential method for predicting gait parameters from RGB videos captured by a single-view camera. This framework has been found to outperform existing state-of-the-art methods, resulting in significantly better predictions of gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. This approach is more efficient and cost-effective, as it requires fewer parameters and eliminates the need for manual feature extraction. The spatiotemporal transformer networks can predict gait parameters from RGB videos with a single-view camera, outperforming existing methods and eliminating manual feature extraction. This approach is more efficient and cost-effective, as it requires fewer parameters and eliminates the need for manual feature extraction."
        ],
        [
            "Spatiotemporal transformer networks have been identified as a potential method for predicting gait parameters from RGB videos captured by a single-view camera. This framework has been found to outperform existing state-of-the-art methods, resulting in significantly better predictions of gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. This approach is more efficient and cost-effective, as it requires fewer parameters and eliminates the need for manual feature extraction. The spatiotemporal transformer networks can predict gait parameters from RGB videos with a single-view camera, outperforming existing methods and eliminating manual feature extraction. This approach is more efficient and cost-effective, as it requires fewer parameters and eliminates the need for manual feature extraction."
        ]
    ]
}