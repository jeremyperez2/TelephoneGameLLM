{
    "adjacency_matrix": [
        [
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0
        ]
    ],
    "prompt_init": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "prompt_update": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "personality_list": [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        ""
    ],
    "format_prompt": [
        ""
    ],
    "initial_story": "musculoskeletal diseases and cognitive impairments in patients lead todifficulties in movement as well as negative effects on their psychologicalhealth. clinical gait analysis, a vital tool for early diagnosis and treatment,traditionally relies on expensive optical motion capture systems. recentadvances in computer vision and deep learning have opened the door to moreaccessible and cost-effective alternatives. this paper introduces a novelspatio-temporal transformer network to estimate critical gait parameters fromrgb videos captured by a single-view camera. empirical evaluations on a publicdataset of cerebral palsy patients indicate that the proposed frameworksurpasses current state-of-the-art approaches and show significant improvementsin predicting general gait parameters (including walking speed, gait deviationindex - gdi, and knee flexion angle at maximum extension), while utilizingfewer parameters and alleviating the need for manual feature extraction. ",
    "stories": [
        [
            "musculoskeletal diseases and cognitive impairments in patients lead to difficulties in movement as well as negative effects on their psychological health. clinical gait analysis, a vital tool for early diagnosis and treatment, traditionally relies on expensive optical motion capture systems. recent advances in computer vision and deep learning have opened the door to more accessible and cost-effective alternatives. this paper introduces a novel spatio-temporal transformer network to estimate critical gait parameters from rgb videos captured by a single-view camera. empirical evaluations on a public dataset of cerebral palsy patients indicate that the proposed framework surpasses current state-of-the-art approaches and shows significant improvements in predicting general gait parameters (including walking speed, gait deviation index - gdi, and knee flexion angle at maximum extension), while utilizing fewer parameters and alleviating the need for manual feature extraction."
        ],
        [
            "musculoskeletal diseases and cognitive impairments in patients lead to difficulties in movement as well as negative effects on their psychological health. clinical gait analysis, a vital tool for early diagnosis and treatment, traditionally relies on expensive optical motion capture systems. recent advances in computer vision and deep learning have opened the door to more accessible and cost-effective alternatives. this paper introduces a novel spatio-temporal transformer network to estimate critical gait parameters from rgb videos captured by a single-view camera. empirical evaluations on a public dataset of cerebral palsy patients indicate that the proposed framework surpasses current state-of-the-art approaches and shows significant improvements in predicting general gait parameters (including walking speed, gait deviation index - gdi, and knee flexion angle at maximum extension), while utilizing fewer parameters and alleviating the need for manual feature extraction."
        ],
        [
            "Musculoskeletal diseases and cognitive impairments in patients can lead to difficulties in movement and negative psychological effects. Clinical gait analysis, a vital tool for early diagnosis and treatment, traditionally relies on expensive optical motion capture systems. Recent advances in computer vision and deep learning have made more accessible and cost-effective alternatives possible. This paper introduces a novel spatio-temporal transformer network to estimate critical gait parameters from RGB videos captured by a single-view camera. Empirical evaluations on a public dataset of cerebral palsy patients show that the proposed framework outperforms current state-of-the-art approaches and significantly improves the prediction of general gait parameters (including walking speed, Gait Deviation Index - GDI, and knee flexion angle at maximum extension), while using fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Musculoskeletal diseases and cognitive impairments in patients can make it difficult for them to move and may have negative psychological effects. Clinical gait analysis is an essential tool for early diagnosis and treatment, but traditional methods rely on expensive optical motion capture systems. Advances in computer vision and deep learning have made more affordable and accessible alternatives possible. This paper presents a new spatio-temporal transformer network to estimate critical gait parameters from RGB videos captured by a single-view camera. Empirical evaluations on a public dataset of cerebral palsy patients show that the proposed framework outperforms current state-of-the-art approaches and significantly improves the prediction of general gait parameters (including walking speed, Gait Deviation Index - GDI, and knee flexion angle at maximum extension), while using fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Musculoskeletal diseases and cognitive impairments in patients can make it difficult for them to move and may have negative psychological effects. Clinical gait analysis is an essential tool for early diagnosis and treatment, but traditional methods rely on expensive optical motion capture systems. Advances in computer vision and deep learning have made more affordable and accessible alternatives possible. This paper presents a new spatio-temporal transformer network to estimate critical gait parameters from RGB videos captured by a single-view camera. Empirical evaluations on a public dataset of cerebral palsy patients show that the proposed framework outperforms current state-of-the-art approaches and significantly improves the prediction of general gait parameters (including walking speed, Gait Deviation Index - GDI, and knee flexion angle at maximum extension), while using fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Musculoskeletal conditions and cognitive limitations can make it difficult for patients to move around, potentially leading to psychological distress. Clinical gait analysis is an essential diagnostic tool, but traditional methods often rely on costly optical motion capture systems. Fortunately, recent advancements in computer vision and deep learning have enabled more cost-effective and accessible alternatives. In this paper, we present a novel spatio-temporal transformer network that can estimate critical gait parameters from RGB videos captured by a single-view camera. Our framework has been empirically tested on a public dataset of cerebral palsy patients and has been shown to outperform current state-of-the-art approaches. In particular, the proposed framework significantly improves the prediction of general gait parameters, including walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Gait analysis is an essential diagnostic tool for musculoskeletal conditions and cognitive limitations, but traditional methods often rely on costly optical motion capture systems. Recent advancements in computer vision and deep learning have enabled more cost-effective and accessible alternatives. In this paper, we present a novel spatio-temporal transformer network that can estimate critical gait parameters from RGB videos captured by a single-view camera. Our framework has been empirically tested on a public dataset of cerebral palsy patients and has been shown to outperform current state-of-the-art approaches. In particular, the proposed framework significantly improves the prediction of general gait parameters, including walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Gait analysis is a crucial diagnostic tool for musculoskeletal conditions and cognitive limitations, but traditional methods often rely on expensive optical motion capture systems. Recent advancements in computer vision and deep learning have enabled more cost-effective and accessible alternatives. In this paper, we present a novel spatio-temporal transformer network that can estimate critical gait parameters from RGB videos captured by a single-view camera. Our framework has been empirically tested on a public dataset of cerebral palsy patients and has been shown to outperform current state-of-the-art approaches. In particular, the proposed framework significantly improves the prediction of general gait parameters, including walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Gait analysis is a crucial diagnostic tool for musculoskeletal conditions and cognitive limitations, but traditional methods often rely on expensive optical motion capture systems. Recent advancements in computer vision and deep learning have enabled more cost-effective and accessible alternatives. In this paper, we present a novel spatio-temporal transformer network that can estimate critical gait parameters from RGB videos captured by a single-view camera. Our framework has been empirically tested on a public dataset of cerebral palsy patients and has been shown to outperform current state-of-the-art approaches. In particular, the proposed framework significantly improves the prediction of general gait parameters, including walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Gait analysis is a key diagnostic tool for musculoskeletal conditions and cognitive limitations, but traditional methods often rely on costly optical motion capture systems. Advances in computer vision and deep learning have enabled more affordable and accessible alternatives. In this paper, we present a new spatio-temporal transformer network that can estimate important gait parameters from RGB videos captured by a single-view camera. Our framework has been tested on a public dataset of cerebral palsy patients and has been shown to outperform existing state-of-the-art approaches. In particular, the proposed framework significantly improves the prediction of general gait parameters, including walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Gait analysis is a crucial diagnostic tool for musculoskeletal conditions and cognitive limitations, but traditional methods often involve expensive optical motion capture systems. Recent developments in computer vision and deep learning have led to more cost-effective and accessible options. In this paper, we propose a new spatio-temporal transformer network that can estimate important gait parameters from RGB videos captured by a single-view camera. Our framework has been tested on a public dataset of cerebral palsy patients, and it has been shown to outperform existing state-of-the-art approaches. Specifically, the proposed framework significantly enhances the prediction of general gait parameters, such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension, while reducing the number of parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Gait analysis is an essential tool for diagnosing musculoskeletal conditions and cognitive limitations. However, traditional methods often require expensive optical motion capture systems. Fortunately, recent advances in computer vision and deep learning have made it possible to develop more cost-effective and accessible alternatives. In this paper, we present a new spatio-temporal transformer network that can estimate important gait parameters from RGB videos captured by a single-view camera. We tested our framework on a public dataset of cerebral palsy patients, and the results show that it outperforms existing state-of-the-art approaches. Specifically, our framework significantly improves the prediction of general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Moreover, our framework reduces the number of parameters and eliminates the need for manual feature extraction, making it a more efficient and practical solution."
        ],
        [
            "Gait analysis is an important tool for diagnosing musculoskeletal conditions and cognitive limitations. However, traditional methods often require expensive optical motion capture systems. Fortunately, recent advances in computer vision and deep learning have made it possible to develop more cost-effective and accessible alternatives. In this paper, we present a new spatio-temporal transformer network that can estimate important gait parameters from RGB videos captured by a single-view camera. We tested our framework on a public dataset of cerebral palsy patients, and the results show that it outperforms existing state-of-the-art approaches. Specifically, our framework significantly improves the prediction of general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Moreover, our framework reduces the number of parameters and eliminates the need for manual feature extraction, making it a more efficient and practical solution."
        ],
        [
            "Gait analysis is a crucial tool for diagnosing musculoskeletal conditions and cognitive limitations. However, traditional methods often require expensive optical motion capture systems. Thankfully, recent advances in computer vision and deep learning have made it possible to develop more cost-effective and accessible alternatives. In this paper, we present a new spatio-temporal transformer network that can estimate important gait parameters from RGB videos captured by a single-view camera. We tested our framework on a public dataset of cerebral palsy patients, and the results show that it outperforms existing state-of-the-art approaches. Specifically, our framework significantly improves the prediction of general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Moreover, our framework reduces the number of parameters and eliminates the need for manual feature extraction, making it a more efficient and practical solution."
        ],
        [
            "Gait analysis is an essential tool for diagnosing musculoskeletal conditions and cognitive limitations, but traditional methods often require expensive optical motion capture systems. Fortunately, recent advances in computer vision and deep learning have made it possible to develop more cost-effective and accessible alternatives. In this paper, we introduce a novel spatio-temporal transformer network that can estimate important gait parameters from RGB videos captured by a single-view camera. We evaluated our framework on a public dataset of cerebral palsy patients and found that it outperformed existing state-of-the-art approaches. Specifically, our framework significantly improved the prediction of general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Additionally, our framework reduced the number of parameters and eliminated the need for manual feature extraction, making it a more efficient and practical solution."
        ],
        [
            "Gait analysis is a valuable tool for diagnosing a wide range of musculoskeletal conditions and cognitive impairments. Traditionally, this analysis has been performed using expensive optical motion capture systems. However, recent advancements in computer vision and deep learning have made it possible to develop more cost-effective and accessible solutions. In this paper, we present a novel spatio-temporal transformer network that can estimate important gait parameters from RGB videos captured by a single-view camera. To evaluate the performance of our framework, we conducted experiments on a public dataset of cerebral palsy patients. The results showed that our approach outperformed existing state-of-the-art methods. Specifically, our framework demonstrated significant improvements in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Additionally, our framework reduced the number of parameters and eliminated the need for manual feature extraction, making it a more efficient and practical solution."
        ],
        [
            "Gait analysis is a valuable tool for diagnosing a wide range of musculoskeletal conditions and cognitive impairments. Traditionally, this analysis has been performed using expensive optical motion capture systems. However, recent advancements in computer vision and deep learning have made it possible to develop more cost-effective and accessible solutions. In this paper, we present a novel spatio-temporal transformer network that can estimate important gait parameters from RGB videos captured by a single-view camera. To evaluate the performance of our framework, we conducted experiments on a public dataset of cerebral palsy patients. The results showed that our approach outperformed existing state-of-the-art methods. Specifically, our framework demonstrated significant improvements in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Additionally, our framework reduced the number of parameters and eliminated the need for manual feature extraction, making it a more efficient and practical solution."
        ],
        [
            "Gait analysis is a valuable tool for diagnosing a wide range of musculoskeletal conditions and cognitive impairments. Traditionally, this analysis has been performed using expensive optical motion capture systems. However, recent advancements in computer vision and deep learning have made it possible to develop more cost-effective and accessible solutions. In this paper, we present a novel spatio-temporal transformer network that can estimate important gait parameters from RGB videos captured by a single-view camera. To evaluate the performance of our framework, we conducted experiments on a public dataset of cerebral palsy patients. The results showed that our approach outperformed existing state-of-the-art methods. Specifically, our framework demonstrated significant improvements in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Additionally, our framework reduced the number of parameters and eliminated the need for manual feature extraction, making it a more efficient and practical solution."
        ],
        [
            "Gait analysis is a valuable tool for diagnosing a wide range of musculoskeletal conditions and cognitive impairments. Traditionally, this analysis has been performed using expensive optical motion capture systems. However, recent advancements in computer vision and deep learning have made it possible to develop more cost-effective and accessible solutions. In this paper, we present a novel spatio-temporal transformer network that can estimate important gait parameters from RGB videos captured by a single-view camera. To evaluate the performance of our framework, we conducted experiments on a public dataset of cerebral palsy patients. The results showed that our approach outperformed existing state-of-the-art methods. Specifically, our framework demonstrated significant improvements in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Additionally, our framework reduced the number of parameters and eliminated the need for manual feature extraction, making it a more efficient and practical solution."
        ],
        [
            "Gait analysis is a valuable tool for diagnosing a wide range of musculoskeletal conditions and cognitive impairments. Traditionally, this analysis has been performed using expensive optical motion capture systems. However, recent advancements in computer vision and deep learning have made it possible to develop more cost-effective and accessible solutions. In this paper, we present a novel spatio-temporal transformer network that can estimate important gait parameters from RGB videos captured by a single-view camera. To evaluate the performance of our framework, we conducted experiments on a public dataset of cerebral palsy patients. The results showed that our approach outperformed existing state-of-the-art methods. Specifically, our framework demonstrated significant improvements in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Additionally, our framework reduced the number of parameters and eliminated the need for manual feature extraction, making it a more efficient and practical solution."
        ],
        [
            "Gait analysis is a valuable tool for diagnosing a wide range of musculoskeletal conditions and cognitive impairments. Traditionally, this analysis has been performed using expensive optical motion capture systems. However, recent advancements in computer vision and deep learning have made it possible to develop more cost-effective and accessible solutions. In this paper, we present a novel spatio-temporal transformer network that can estimate important gait parameters from RGB videos captured by a single-view camera. To evaluate the performance of our framework, we conducted experiments on a public dataset of cerebral palsy patients. The results showed that our approach outperformed existing state-of-the-art methods. Specifically, our framework demonstrated significant improvements in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Additionally, our framework reduced the number of parameters and eliminated the need for manual feature extraction, making it a more efficient and practical solution."
        ],
        [
            "Gait analysis is a valuable tool for diagnosing a wide range of musculoskeletal conditions and cognitive impairments. Traditionally, this analysis has been performed using expensive optical motion capture systems. However, recent advancements in computer vision and deep learning have made it possible to develop more cost-effective and accessible solutions. In this paper, we present a novel spatio-temporal transformer network that can estimate important gait parameters from RGB videos captured by a single-view camera. To evaluate the performance of our framework, we conducted experiments on a public dataset of cerebral palsy patients. The results showed that our approach outperformed existing state-of-the-art methods. Specifically, our framework demonstrated significant improvements in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Additionally, our framework reduced the number of parameters and eliminated the need for manual feature extraction, making it a more efficient and practical solution."
        ],
        [
            "Gait analysis is a valuable tool for diagnosing a wide range of musculoskeletal conditions and cognitive impairments. Traditionally, this analysis has been performed using expensive optical motion capture systems. However, recent advancements in computer vision and deep learning have made it possible to develop more cost-effective and accessible solutions. In this paper, we present a novel spatio-temporal transformer network that can estimate important gait parameters from RGB videos captured by a single-view camera. To evaluate the performance of our framework, we conducted experiments on a public dataset of cerebral palsy patients. The results showed that our approach outperformed existing state-of-the-art methods. Specifically, our framework demonstrated significant improvements in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Additionally, our framework reduced the number of parameters and eliminated the need for manual feature extraction, making it a more efficient and practical solution."
        ],
        [
            "Gait analysis is a valuable tool for diagnosing a wide range of musculoskeletal conditions and cognitive impairments. Traditionally, this analysis has been performed using expensive optical motion capture systems. However, recent advancements in computer vision and deep learning have made it possible to develop more cost-effective and accessible solutions. In this paper, we present a novel spatio-temporal transformer network that can estimate important gait parameters from RGB videos captured by a single-view camera. To evaluate the performance of our framework, we conducted experiments on a public dataset of cerebral palsy patients. The results showed that our approach outperformed existing state-of-the-art methods. Specifically, our framework demonstrated significant improvements in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Additionally, our framework reduced the number of parameters and eliminated the need for manual feature extraction, making it a more efficient and practical solution."
        ],
        [
            "Gait analysis is a valuable tool for diagnosing a wide range of musculoskeletal conditions and cognitive impairments. Traditionally, this analysis has been performed using expensive optical motion capture systems. However, recent advancements in computer vision and deep learning have made it possible to develop more cost-effective and accessible solutions. In this paper, we present a novel spatio-temporal transformer network that can estimate important gait parameters from RGB videos captured by a single-view camera. To evaluate the performance of our framework, we conducted experiments on a public dataset of cerebral palsy patients. The results showed that our approach outperformed existing state-of-the-art methods. Specifically, our framework demonstrated significant improvements in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Additionally, our framework reduced the number of parameters and eliminated the need for manual feature extraction, making it a more efficient and practical solution."
        ],
        [
            "Gait analysis is a valuable tool for diagnosing a wide range of musculoskeletal conditions and cognitive impairments. Traditionally, this analysis has been performed using expensive optical motion capture systems. However, recent advancements in computer vision and deep learning have made it possible to develop more cost-effective and accessible solutions. In this paper, we present a novel spatio-temporal transformer network that can estimate important gait parameters from RGB videos captured by a single-view camera. To evaluate the performance of our framework, we conducted experiments on a public dataset of cerebral palsy patients. The results showed that our approach outperformed existing state-of-the-art methods. Specifically, our framework demonstrated significant improvements in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Additionally, our framework reduced the number of parameters and eliminated the need for manual feature extraction, making it a more efficient and practical solution."
        ],
        [
            "Gait analysis has long been a valuable tool for diagnosing a range of musculoskeletal and cognitive impairments, but traditional methods using expensive optical motion capture systems have been inaccessible to many. However, recent advancements in computer vision and deep learning have made it possible to develop more cost-effective and accessible solutions. In this paper, we present a novel spatio-temporal transformer network that can estimate important gait parameters from RGB videos captured by a single-view camera. To evaluate the performance of our framework, we conducted experiments on a public dataset of cerebral palsy patients. The results showed that our approach outperformed existing state-of-the-art methods, demonstrating significant improvements in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Additionally, our framework reduced the number of parameters and eliminated the need for manual feature extraction, making it a more efficient and practical solution."
        ],
        [
            "Recent advances in computer vision and deep learning have made it possible to develop more cost-effective and accessible solutions for gait analysis. Gait analysis is a valuable tool for diagnosing musculoskeletal and cognitive impairments, but traditional methods using expensive optical motion capture systems have been inaccessible to many. In this paper, we present a novel spatio-temporal transformer network that can estimate important gait parameters from RGB videos captured by a single-view camera. To evaluate the performance of our framework, we conducted experiments on a public dataset of cerebral palsy patients. The results showed that our approach outperformed existing state-of-the-art methods, demonstrating significant improvements in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Additionally, our framework reduced the number of parameters and eliminated the need for manual feature extraction, making it a more efficient and practical solution."
        ],
        [
            "Advances in computer vision and deep learning have opened up new possibilities for cost-effective and accessible gait analysis solutions. Gait analysis is an essential tool for diagnosing musculoskeletal and cognitive impairments, but traditional methods using expensive optical motion capture systems have been out of reach for many. In this paper, we introduce a novel spatio-temporal transformer network that can estimate important gait parameters from RGB videos captured by a single-view camera. To evaluate the performance of our framework, we conducted experiments on a public dataset of cerebral palsy patients. The results demonstrated that our approach outperformed existing state-of-the-art methods, showing significant improvements in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Furthermore, our framework reduced the number of parameters and eliminated the need for manual feature extraction, making it a more efficient and practical solution."
        ],
        [
            "Recent developments in computer vision and deep learning have created new opportunities for cost-effective and accessible gait analysis tools. Gait analysis is crucial for diagnosing musculoskeletal and cognitive disorders, but traditional methods using expensive optical motion capture systems have been beyond the reach of many. In this paper, we present a novel spatio-temporal transformer network that can estimate key gait parameters from RGB videos captured by a single-view camera. To assess the performance of our framework, we carried out experiments on a public dataset of patients with cerebral palsy. Our results show that our approach outperforms existing state-of-the-art methods, with significant improvements in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Moreover, our framework reduces the number of parameters and eliminates the need for manual feature extraction, making it a more efficient and practical solution."
        ],
        [
            "Recent advancements in computer vision and deep learning have opened up new avenues for creating cost-effective and easily accessible gait analysis tools. Gait analysis is critical for diagnosing musculoskeletal and cognitive disorders, but conventional methods that use expensive optical motion capture systems have been out of reach for many. In this paper, we introduce a novel spatio-temporal transformer network that can estimate key gait parameters from RGB videos captured by a single-view camera. To evaluate the performance of our framework, we conducted experiments on a public dataset of patients with cerebral palsy. Our results demonstrate that our approach outperforms existing state-of-the-art methods, with significant improvements in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Additionally, our framework reduces the number of parameters and eliminates the need for manual feature extraction, making it a more efficient and practical solution."
        ],
        [
            "Recent advancements in computer vision and deep learning have opened up new avenues for creating cost-effective and easily accessible gait analysis tools. Gait analysis is critical for diagnosing musculoskeletal and cognitive disorders, but conventional methods that use expensive optical motion capture systems have been out of reach for many. In this paper, we introduce a novel spatio-temporal transformer network that can estimate key gait parameters from RGB videos captured by a single-view camera. To evaluate the performance of our framework, we conducted experiments on a public dataset of patients with cerebral palsy. Our results demonstrate that our approach outperforms existing state-of-the-art methods, with significant improvements in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Additionally, our framework reduces the number of parameters and eliminates the need for manual feature extraction, making it a more efficient and practical solution."
        ],
        [
            "Recent advancements in computer vision and deep learning have opened up new opportunities for creating cost-effective and easily accessible gait analysis tools. Gait analysis is critical for diagnosing musculoskeletal and cognitive disorders, but conventional methods that use expensive optical motion capture systems have been out of reach for many. In this paper, we introduce a novel spatio-temporal transformer network that can estimate key gait parameters from RGB videos captured by a single-view camera. To evaluate the performance of our framework, we conducted experiments on a public dataset of patients with cerebral palsy. Our results demonstrate that our approach outperforms existing state-of-the-art methods, with significant improvements in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Additionally, our framework reduces the number of parameters and eliminates the need for manual feature extraction, making it a more efficient and practical solution."
        ],
        [
            "Recent developments in computer vision and deep learning have opened up new possibilities for creating cost-effective and easily accessible gait analysis tools. Gait analysis is crucial for diagnosing musculoskeletal and cognitive disorders, but traditional methods that rely on expensive optical motion capture systems have been out of reach for many. In this paper, we present a novel spatio-temporal transformer network that can estimate key gait parameters from RGB videos captured by a single-view camera. To assess the performance of our framework, we conducted experiments on a public dataset of patients with cerebral palsy. Our results show that our approach outperforms existing state-of-the-art methods, with substantial improvements in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Moreover, our framework reduces the number of parameters and eliminates the need for manual feature extraction, making it a more efficient and practical solution."
        ],
        [
            "Recent developments in computer vision and deep learning have opened up new possibilities for creating cost-effective and easily accessible gait analysis tools. Gait analysis is crucial for diagnosing musculoskeletal and cognitive disorders, but traditional methods that rely on expensive optical motion capture systems have been out of reach for many. In this paper, we present a novel spatio-temporal transformer network that can estimate key gait parameters from RGB videos captured by a single-view camera. To assess the performance of our framework, we conducted experiments on a public dataset of patients with cerebral palsy. Our results show that our approach outperforms existing state-of-the-art methods, with substantial improvements in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Moreover, our framework reduces the number of parameters and eliminates the need for manual feature extraction, making it a more efficient and practical solution."
        ],
        [
            "Recent advances in computer vision and deep learning have opened up new opportunities for creating affordable and accessible gait analysis tools. Gait analysis is essential for diagnosing musculoskeletal and cognitive disorders, but traditional methods that rely on expensive optical motion capture systems have been out of reach for many. In this paper, we present a novel spatio-temporal transformer network that can estimate key gait parameters from RGB videos captured by a single-view camera. To assess the performance of our framework, we conducted experiments on a public dataset of patients with cerebral palsy. Our results show that our approach outperforms existing state-of-the-art methods, with significant improvements in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Moreover, our framework reduces the number of parameters and eliminates the need for manual feature extraction, making it a more efficient and practical solution."
        ],
        [
            "Recent advances in computer vision and deep learning have opened up new opportunities for creating affordable and accessible gait analysis tools. Gait analysis is essential for diagnosing musculoskeletal and cognitive disorders, but traditional methods that rely on expensive optical motion capture systems have been out of reach for many. In this paper, we present a novel spatio-temporal transformer network that can estimate key gait parameters from RGB videos captured by a single-view camera. To assess the performance of our framework, we conducted experiments on a public dataset of patients with cerebral palsy. Our results show that our approach outperforms existing state-of-the-art methods, with significant improvements in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Moreover, our framework reduces the number of parameters and eliminates the need for manual feature extraction, making it a more efficient and practical solution."
        ],
        [
            "Recent advances in computer vision and deep learning have opened up new possibilities for creating affordable and accessible gait analysis tools. Gait analysis is crucial for diagnosing musculoskeletal and cognitive disorders, but traditional methods that rely on expensive optical motion capture systems have been out of reach for many. In this paper, we introduce a novel spatio-temporal transformer network that can estimate key gait parameters from RGB videos captured by a single-view camera. To evaluate the performance of our framework, we conducted experiments on a public dataset of patients with cerebral palsy. Our results show that our approach outperforms existing state-of-the-art methods, with significant improvements in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Furthermore, our framework reduces the number of parameters and eliminates the need for manual feature extraction, making it a more efficient and practical solution."
        ],
        [
            "Gait analysis is important for identifying musculoskeletal and cognitive problems, but standard methods using costly optical motion capture systems have been inaccessible to many. However, recent developments in computer vision and deep learning have provided new opportunities for building cost-effective and accessible gait analysis tools. In this paper, we propose a new spatio-temporal transformer network that can estimate key gait parameters from RGB videos captured by a single-view camera. To evaluate our framework, we conducted experiments on a public dataset of patients with cerebral palsy. Our results demonstrate that our approach outperforms existing state-of-the-art methods, with significant improvements in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Additionally, our framework reduces the number of parameters and eliminates the need for manual feature extraction, making it more efficient and practical."
        ],
        [
            "Gait analysis is a critical tool for diagnosing musculoskeletal and cognitive disorders, but traditional methods using expensive optical motion capture systems have been out of reach for many. Recent advances in computer vision and deep learning have provided new opportunities for developing cost-effective and accessible gait analysis tools. In this paper, we present a new spatio-temporal transformer network that can estimate key gait parameters from RGB videos captured by a single-view camera. To evaluate our framework, we conducted experiments on a public dataset of patients with cerebral palsy. Our results demonstrate that our approach outperforms existing state-of-the-art methods, with significant improvements in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Furthermore, our framework reduces the number of parameters and eliminates the need for manual feature extraction, making it more efficient and practical."
        ],
        [
            "The use of gait analysis as a tool for diagnosing musculoskeletal and cognitive disorders has been limited due to the expense and complexity of traditional optical motion capture systems. However, recent advancements in computer vision and deep learning have created new opportunities for developing cost-effective and accessible gait analysis tools. In this paper, we present a novel spatio-temporal transformer network that can estimate key gait parameters from RGB videos captured by a single-view camera. To evaluate our framework, we conducted experiments on a public dataset of patients with cerebral palsy. Our results show that our approach outperforms existing state-of-the-art methods, with significant improvements in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Furthermore, our framework reduces the number of parameters and eliminates the need for manual feature extraction, making it more efficient and practical."
        ],
        [
            "Gait analysis can be used to diagnose musculoskeletal and cognitive disorders. However, traditional optical motion capture systems are expensive and complex. Recent advancements in computer vision and deep learning have created new opportunities for cost-effective and accessible gait analysis tools. In this paper, we present a novel spatio-temporal transformer network that can estimate key gait parameters from RGB videos captured by a single-view camera. To evaluate our framework, we conducted experiments on a public dataset of patients with cerebral palsy. Our results show that our approach outperforms existing state-of-the-art methods, with significant improvements in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Additionally, our framework reduces the number of parameters and eliminates the need for manual feature extraction, making it more efficient and practical."
        ],
        [
            "Gait analysis is an effective tool for diagnosing musculoskeletal and cognitive disorders. However, traditional optical motion capture systems are expensive and complex, making them inaccessible to many people. Recent advancements in computer vision and deep learning have opened up new possibilities for creating cost-effective and accessible gait analysis tools. In this paper, we propose a novel spatio-temporal transformer network that can estimate key gait parameters from RGB videos captured by a single-view camera. To evaluate our framework, we conducted experiments on a public dataset of patients with cerebral palsy. Our results demonstrate that our approach outperforms existing state-of-the-art methods, achieving significant improvements in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Furthermore, our framework requires fewer parameters and eliminates the need for manual feature extraction, making it more efficient and practical."
        ],
        [
            "Gait analysis has become a powerful tool for diagnosing musculoskeletal and cognitive disorders. Until recently, optical motion capture systems were expensive and complex, limiting their accessibility to many people. Thanks to recent developments in computer vision and deep learning, however, it is now possible to create cost-effective and accessible gait analysis tools. In this paper, we introduce a novel spatio-temporal transformer network that can estimate key gait parameters from RGB videos captured by a single-view camera. To assess our framework, we carried out experiments on a public dataset of patients with cerebral palsy. Our results show that our approach outperforms existing state-of-the-art methods, achieving significant improvements in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Furthermore, our framework requires fewer parameters and eliminates the need for manual feature extraction, making it more efficient and practical."
        ],
        [
            "Gait analysis is a powerful diagnostic tool used to identify musculoskeletal and cognitive disorders. Optical motion capture systems were previously expensive and complicated, limiting their availability. However, thanks to advances in computer vision and deep learning, cost-effective and accessible gait analysis tools can now be created. We introduce a new spatio-temporal transformer network capable of estimating key gait parameters from RGB videos captured by a single-view camera. We evaluated our framework using a public dataset of patients with cerebral palsy. Our results show that our approach outperforms existing state-of-the-art methods, significantly improving the prediction of general gait parameters like walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Additionally, our framework requires fewer parameters and eliminates manual feature extraction, making it more efficient and practical."
        ],
        [
            "Gait analysis is a diagnostic tool that can be used to identify musculoskeletal and cognitive disorders. Optical motion capture systems were previously expensive and complicated, limiting their availability. However, with advances in computer vision and deep learning, cost-effective and accessible gait analysis tools can now be created. We introduce a new spatio-temporal transformer network capable of estimating key gait parameters from RGB videos captured by a single-view camera. We evaluated our framework using a public dataset of patients with cerebral palsy. Our results show that our approach outperforms existing state-of-the-art methods, significantly improving the prediction of general gait parameters like walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Additionally, our framework requires fewer parameters and eliminates manual feature extraction, making it more efficient and practical."
        ],
        [
            "Gait analysis is a valuable diagnostic tool for identifying musculoskeletal and cognitive disorders. Until recently, optical motion capture systems were expensive and complex, limiting their accessibility. However, with the development of computer vision and deep learning techniques, cost-effective and accessible gait analysis tools are now possible. Our team has developed a new spatio-temporal transformer network that can estimate key gait parameters from RGB videos captured by a single-view camera. We tested our framework on a public dataset of patients with cerebral palsy, and the results demonstrate that our approach outperforms existing state-of-the-art methods in predicting general gait parameters, such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Our framework also requires fewer parameters and eliminates manual feature extraction, making it more efficient and practical for use in clinical settings."
        ],
        [
            "Gait analysis is a valuable diagnostic tool for identifying musculoskeletal and cognitive disorders. Until recently, optical motion capture systems were expensive and complex, limiting their accessibility. However, with the development of computer vision and deep learning techniques, cost-effective and accessible gait analysis tools are now possible. Our team has developed a new spatio-temporal transformer network that can estimate key gait parameters from RGB videos captured by a single-view camera. We tested our framework on a public dataset of patients with cerebral palsy, and the results demonstrate that our approach outperforms existing state-of-the-art methods in predicting general gait parameters, such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Our framework also requires fewer parameters and eliminates manual feature extraction, making it more efficient and practical for use in clinical settings."
        ],
        [
            "Gait analysis is a valuable tool for diagnosing musculoskeletal and cognitive disorders. Traditionally, optical motion capture systems were expensive and complicated, but recent advances in computer vision and deep learning have made cost-effective and accessible gait analysis tools possible. Our team has developed a new spatio-temporal transformer network that can estimate key gait parameters from RGB videos captured by a single-view camera. We tested our framework on a public dataset of patients with cerebral palsy and found that it outperformed existing state-of-the-art methods in predicting general gait parameters such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Our framework also requires fewer parameters and eliminates manual feature extraction, making it more efficient and practical for use in clinical settings."
        ],
        [
            "Gait analysis is a useful diagnostic tool for detecting both musculoskeletal and cognitive problems. In the past, optical motion capture systems were costly and difficult to use, but advances in computer vision and deep learning have made inexpensive and easy-to-use gait analysis tools available. Our team has created a new spatio-temporal transformer network that can calculate critical gait parameters from RGB video clips taken with a single camera. We evaluated our platform using a publicly available dataset of cerebral palsy patients and discovered that it outperformed current state-of-the-art methods in predicting general gait metrics such as walking speed, Gait Deviation Index (GDI), and knee flexion angle at maximum extension. Our method needs less parameters and eliminates manual feature extraction, making it more effective and practical for use in clinical settings."
        ]
    ]
}