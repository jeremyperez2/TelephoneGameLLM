{
    "adjacency_matrix": [
        [
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0
        ]
    ],
    "prompt_init": [
        "You will receive a text. Your task is to create a new original text by taking inspiration from this text. Just output your new text, nothing else. Here is the text:"
    ],
    "prompt_update": [
        "You will receive a text. Your task is to create a new original text by taking inspiration from this text. Just output your new text, nothing else. Here is the text:"
    ],
    "personality_list": [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        ""
    ],
    "format_prompt": [
        ""
    ],
    "initial_story": "having the potential for high speed, high throughput, and low energy cost,optical neural networks (onns) have emerged as a promising candidate foraccelerating deep learning tasks. in conventional onns, light amplitudes aremodulated at the input and detected at the output. however, the light phasesare still ignored in conventional structures, although they can also carryinformation for computing. to address this issue, in this paper, we propose aframework called oplixnet to compress the areas of onns by modulating inputimage data into the amplitudes and phase parts of light signals. the input andoutput parts of the onns are redesigned to make full use of both amplitude andphase information. moreover, mutual learning across different onn structures isintroduced to maintain the accuracy. experimental results demonstrate that theproposed framework significantly reduces the areas of onns with the accuracywithin an acceptable range. for instance, 75.03% area is reduced with a 0.33%accuracy decrease on fully connected neural network (fcnn) and 74.88% area isreduced with a 2.38% accuracy decrease on resnet-32. ",
    "stories": [
        [
            "Optical neural networks (ONNs) are emerging as a promising candidate foraccelerating deep learning tasks due to their potential for high speed, highthroughput, and low energy cost. Conventional ONNs modulate the amplitudes oflight signals at the input and detect them at the output. However, the phases ofthe light signals are still ignored, even though they can also carryinformation for computing. To address this issue, we propose a frameworkcalled OPLIXNET to compress the areas of ONNs by modulating input image datainto the amplitudes and phase parts of light signals. The input and outputparts of the ONNs are redesigned to make full use of both amplitude and phaseinformation. Moreover, mutual learning across different ONN structures isintroduced to maintain the accuracy. Experimental results demonstrate that theproposed framework significantly reduces the areas of ONNs with the accuracywithin an acceptable range. For instance, 75.03% area is reduced with a 0.33%accuracy decrease on fully connected neural network (FCNN) and 74.88% area isreduced with a 2.38% accuracy decrease on ResNet-32."
        ],
        [
            "Optical neural networks (ONNs) are emerging as a promising candidate foraccelerating deep learning tasks due to their potential for high speed, highthroughput, and low energy cost. Conventional ONNs modulate the amplitudes oflight signals at the input and detect them at the output. However, the phases ofthe light signals are still ignored, even though they can also carryinformation for computing. To address this issue, we propose a frameworkcalled OPLIXNET to compress the areas of ONNs by modulating input image datainto the amplitudes and phase parts of light signals. The input and outputparts of the ONNs are redesigned to make full use of both amplitude and phaseinformation. Moreover, mutual learning across different ONN structures isintroduced to maintain the accuracy. Experimental results demonstrate that theproposed framework significantly reduces the areas of ONNs with the accuracywithin an acceptable range. For instance, 75.03% area is reduced with a 0.33%accuracy decrease on fully connected neural network (FCNN) and 74.88% area isreduced with a 2.38% accuracy decrease on ResNet-32."
        ],
        [
            "Optical Neural Networks (ONNs) are emerging as a promising candidate foraccelerating deep learning tasks due to their potential for high speed, highthroughput, and low energy cost. Conventional ONNs modulate the amplitudes oflight signals at the input and detect them at the output. However, the phases ofthe light signals are still ignored, even though they can also carryinformation for computing. To address this issue, we propose a frameworkcalled OPLIXNET to compress the areas of ONNs by modulating input image datainto the amplitudes and phase parts of light signals. The input and outputparts of the ONNs are redesigned to make full use of both amplitude and phaseinformation. Moreover, mutual learning across different ONN structures isintroduced to maintain the accuracy. Experimental results demonstrate that theproposed framework significantly reduces the areas of ONNs with the accuracywithin an acceptable range. For instance, 75.03% area is reduced with a 0.33%accuracy decrease on fully connected neural network (FCNN) and 74.88% area isreduced with a 2.38% accuracy decrease on ResNet-32."
        ],
        [
            "Optical Neural Networks (ONNs) are emerging as a promising candidate foraccelerating deep learning tasks due to their potential for high speed, highthroughput, and low energy cost. Conventional ONNs modulate the amplitudes oflight signals at the input and detect them at the output. However, the phases ofthe light signals are still ignored, even though they can also carryinformation for computing. To address this issue, we propose a frameworkcalled OPLIXNET to compress the areas of ONNs by modulating input image datainto the amplitudes and phase parts of light signals. The input and outputparts of the ONNs are redesigned to make full use of both amplitude and phaseinformation. Moreover, mutual learning across different ONN structures isintroduced to maintain the accuracy. Experimental results demonstrate that theproposed framework significantly reduces the areas of ONNs with the accuracywithin an acceptable range. For instance, 75.03% area is reduced with a 0.33%accuracy decrease on fully connected neural network (FCNN) and 74.88% area isreduced with a 2.38% accuracy decrease on ResNet-32."
        ],
        [
            "Optical Neural Networks (ONNs) are emerging as a promising candidate foraccelerating deep learning tasks due to their potential for high speed, highthroughput, and low energy cost. Conventional ONNs modulate the amplitudes oflight signals at the input and detect them at the output. However, the phases ofthe light signals are still ignored, even though they can also carryinformation for computing. To address this issue, we propose a frameworkcalled OPLIXNET to compress the areas of ONNs by modulating input image datainto the amplitudes and phase parts of light signals. The input and outputparts of the ONNs are redesigned to make full use of both amplitude and phaseinformation. Moreover, mutual learning across different ONN structures isintroduced to maintain the accuracy. Experimental results demonstrate that theproposed framework significantly reduces the areas of ONNs with the accuracywithin an acceptable range. For instance, 75.03% area is reduced with a 0.33%accuracy decrease on fully connected neural network (FCNN) and 74.88% area isreduced with a 2.38% accuracy decrease on ResNet-32."
        ],
        [
            "Optical Neural Networks (ONNs) are emerging as a promising candidate for accelerating deep learning tasks due to their potential for high speed, high throughput, and low energy cost. Conventional ONNs modulate the amplitudes of light signals at the input and detect them at the output. However, the phases of the light signals are still ignored, even though they can also carry information for computing. To address this issue, we propose a framework called OPLIXNET to compress the areas of ONNs by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Moreover, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32."
        ],
        [
            "Optical Neural Networks (ONNs) are emerging as a promising candidate for accelerating deep learning tasks due to their potential for high speed, high throughput, and low energy cost. Conventional ONNs modulate the amplitudes of light signals at the input and detect them at the output. However, the phases of the light signals are still ignored, even though they can also carry information for computing. To address this issue, we propose a framework called OPLIXNET to compress the areas of ONNs by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Moreover, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32."
        ],
        [
            "Optical Neural Networks (ONNs) are emerging as a promising candidate for accelerating deep learning tasks due to their potential for high speed, high throughput, and low energy cost. Conventional ONNs modulate the amplitudes of light signals at the input and detect them at the output. However, the phases of the light signals are still ignored, even though they can also carry information for computing. To address this issue, we propose a framework called OPLIXNET to compress the areas of ONNs by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Moreover, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32."
        ],
        [
            "A new framework called OPLIXNET is proposed to compress the areas of Optical Neural Networks (ONNs) by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Moreover, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32."
        ],
        [
            "A new framework called OPLIXNET is proposed to compress the areas of Optical Neural Networks (ONNs) by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Moreover, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32."
        ],
        [
            "A novel framework, called OPLIXNET, is proposed to compress the areas of Optical Neural Networks (ONNs) by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32."
        ],
        [
            "A novel framework, called OPLIXNET, is proposed to compress the areas of Optical Neural Networks (ONNs) by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the"
        ],
        [
            "A novel framework, called OPLIXNET, is proposed to compress the areas of Optical Neural Networks (ONNs) by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the"
        ],
        [
            "A novel framework, called OPLIXNET, is proposed to compress the areas of Optical Neural Networks (ONNs) by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the"
        ],
        [
            "A novel framework, called OPLIXNET, is proposed to compress the areas of Optical Neural Networks (ONNs) by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the"
        ],
        [
            "A novel framework, called OPLIXNET, is proposed to compress the areas of Optical Neural Networks (ONNs) by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the"
        ],
        [
            "A novel framework, called OPLIXNET, is proposed to compress the areas of Optical Neural Networks (ONNs) by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the"
        ],
        [
            "A novel framework, called OPLIXNET, is proposed to compress the areas of Optical Neural Networks (ONNs) by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the"
        ],
        [
            "A novel framework, called OPLIXNET, is proposed to compress the areas of Optical Neural Networks (ONNs) by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the"
        ],
        [
            "A novel framework, called OPLIXNET, is proposed to compress the areas of Optical Neural Networks (ONNs) by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the"
        ],
        [
            "A novel framework, called OPLIXNET, is proposed to compress the areas of Optical Neural Networks (ONNs) by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the"
        ],
        [
            "A novel framework, called OPLIXNET, is proposed to compress the areas of Optical Neural Networks (ONNs) by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the"
        ],
        [
            "A novel framework, called OPLIXNET, is proposed to compress the areas of Optical Neural Networks (ONNs) by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the"
        ],
        [
            "A novel framework, called OPLIXNET, is proposed to compress the areas of Optical Neural Networks (ONNs) by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the"
        ],
        [
            "A novel framework, called OPLIXNET, is proposed to compress the areas of Optical Neural Networks (ONNs) by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the"
        ],
        [
            "A novel framework, called OPLIXNET, is proposed to compress the areas of Optical Neural Networks (ONNs) by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the"
        ],
        [
            "A novel framework, called OPLIXNET, is proposed to compress the areas of Optical Neural Networks (ONNs) by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the"
        ],
        [
            "A novel framework, called OPLIXNET, is proposed to compress the areas of Optical Neural Networks (ONNs) by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the"
        ],
        [
            "A novel framework, called OPLIXNET, is proposed to compress the areas of Optical Neural Networks (ONNs) by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the"
        ],
        [
            "A novel framework, called OPLIXNET, is proposed to compress the areas of Optical Neural Networks (ONNs) by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the"
        ],
        [
            "A novel framework, called OPLIXNET, is proposed to compress the areas of Optical Neural Networks (ONNs) by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the"
        ],
        [
            "A novel framework, called OPLIXNET, is proposed to compress the areas of Optical Neural Networks (ONNs) by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the"
        ],
        [
            "A novel framework, called OPLIXNET, is proposed to compress the areas of Optical Neural Networks (ONNs) by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the"
        ],
        [
            "A novel framework, called OPLIXNET, is proposed to compress the areas of Optical Neural Networks (ONNs) by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the"
        ],
        [
            "A novel framework, called OPLIXNET, is proposed to compress the areas of Optical Neural Networks (ONNs) by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the"
        ],
        [
            "A novel framework, called OPLIXNET, is proposed to compress the areas of Optical Neural Networks (ONNs) by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the"
        ],
        [
            "A novel framework, called OPLIXNET, is proposed to compress the areas of Optical Neural Networks (ONNs) by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the"
        ],
        [
            "A novel framework, called OPLIXNET, is proposed to compress the areas of Optical Neural Networks (ONNs) by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the"
        ],
        [
            "The proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with"
        ],
        [
            "The proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with"
        ],
        [
            "The proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with"
        ],
        [
            "The proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with"
        ],
        [
            "The proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with"
        ],
        [
            "The proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with"
        ],
        [
            "The proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with"
        ],
        [
            "The proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with"
        ],
        [
            "The proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with"
        ],
        [
            "The proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with"
        ],
        [
            "The proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with"
        ],
        [
            "The proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32.\n\nThe proposed framework is based on the OPLIXNET framework [1], which uses a combination of amplitude and phase modulation to compress the areas of ONNs. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Furthermore, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with"
        ]
    ]
}