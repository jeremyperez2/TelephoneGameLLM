{
    "adjacency_matrix": [
        [
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0
        ]
    ],
    "prompt_init": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "prompt_update": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "personality_list": [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        ""
    ],
    "format_prompt": [
        ""
    ],
    "initial_story": "having the potential for high speed, high throughput, and low energy cost,optical neural networks (onns) have emerged as a promising candidate foraccelerating deep learning tasks. in conventional onns, light amplitudes aremodulated at the input and detected at the output. however, the light phasesare still ignored in conventional structures, although they can also carryinformation for computing. to address this issue, in this paper, we propose aframework called oplixnet to compress the areas of onns by modulating inputimage data into the amplitudes and phase parts of light signals. the input andoutput parts of the onns are redesigned to make full use of both amplitude andphase information. moreover, mutual learning across different onn structures isintroduced to maintain the accuracy. experimental results demonstrate that theproposed framework significantly reduces the areas of onns with the accuracywithin an acceptable range. for instance, 75.03% area is reduced with a 0.33%accuracy decrease on fully connected neural network (fcnn) and 74.88% area isreduced with a 2.38% accuracy decrease on resnet-32. ",
    "stories": [
        [
            "Optical neural networks (ONNs) have gained attention as a potential technology for accelerating deep learning tasks due to their high speed, high throughput, and low energy consumption. In traditional ONNs, only the amplitudes of light are modulated at the input and detected at the output, while the phase of light is disregarded despite its potential for carrying information. To tackle this issue, the authors propose a framework called Oplixnet, which modulates input image data into both the amplitude and phase parts of light signals, thereby reducing the area of ONNs while maintaining accuracy. The input and output parts of ONNs are redesigned to utilize both amplitude and phase information. Additionally, mutual learning across different ONN structures is implemented to preserve accuracy. The experimental results show that the proposed framework significantly decreases the area of ONNs while keeping the accuracy within an acceptable range. For example, a 75.03% reduction in area was achieved with a 0.33% accuracy drop in a fully connected neural network (FCNN), and a 74.88% reduction in area was obtained with a 2.38% accuracy drop in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently gained interest as a method for increasing the speed and efficiency of deep learning processes, thanks to their high speed, high capacity, and low energy consumption. Conventional ONNs only alter the amplitude of light at the input and output, while neglecting the potential of the light's phase to convey information. In order to address this, the authors introduce a framework called Oplixnet, which encodes image data into both the amplitude and phase components of light signals. This results in a smaller ONN size without sacrificing accuracy, as the input and output components of ONNs are updated to utilize both amplitude and phase data. Furthermore, the framework includes a mechanism for mutual learning between different ONN structures to maintain accuracy. The experimental results demonstrate that Oplixnet significantly reduces the size of ONNs while maintaining acceptable accuracy levels. For instance, there was a 75.03% decrease in area with only a 0.33% decrease in accuracy in a fully connected neural network (FCNN), and a 74.88% reduction in area with a 2.38% decrease in accuracy in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently attracted attention as a means to enhance the speed and energy efficiency of deep learning by taking advantage of their high speed, large capacity, and low energy consumption. Traditional ONNs only adjust the light's amplitude at the input and output, while disregarding the potential of the light's phase to transmit information. To tackle this issue, the authors propose a framework named Oplixnet, which encodes image data into both the amplitude and phase of light signals. This results in a more compact ONN size without compromising accuracy, as the input and output parts of ONNs are modified to utilize both amplitude and phase information. Additionally, Oplixnet includes a mutual learning mechanism between various ONN structures to ensure accuracy. The experimental results indicate that Oplixnet significantly decreases the size of ONNs while maintaining acceptable accuracy levels. For example, there was a 75.03% decrease in area with only a 0.33% decrease in accuracy in a fully connected neural network (FCNN), and a 74.88% reduction in area with a 2.38% decrease in accuracy in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently gained interest for improving the speed and energy efficiency of deep learning by utilizing their high speed, large capacity, and low energy usage. Existing ONNs only adjust the light's amplitude at the input and output, neglecting the possibility of using the light's phase to transmit information. To address this, researchers have introduced a framework called Oplixnet, which encodes image data into both the amplitude and phase of light signals. This results in a more space-efficient ONN without sacrificing accuracy, as the input and output components of ONNs are adapted to use both amplitude and phase information. Furthermore, Oplixnet includes a mutual learning mechanism between different ONN structures to ensure accuracy. The experimental results demonstrate that Oplixnet significantly reduces the size of ONNs while maintaining acceptable accuracy levels. For instance, there was a 75.03% reduction in area with a 0.33% decrease in accuracy in a fully connected neural network (FCNN), and a 74.88% decrease in area with a 2.38% decrease in accuracy in Resnet-32."
        ],
        [
            "Recently, optical neural networks (ONNs) have become popular due to their ability to enhance the speed and energy efficiency of deep learning by leveraging high-speed, high-capacity, and low-energy consumption features. However, existing ONNs only adjust the light's amplitude at the input and output, overlooking the potential of using the light's phase to transmit information. To tackle this issue, researchers have developed a framework named Oplixnet, which converts image data into both the amplitude and phase of light signals. This approach results in a more space-efficient ONN, without compromising accuracy, as the input and output components of ONNs are modified to utilize both amplitude and phase information. Additionally, Oplixnet incorporates a mutual learning mechanism between various ONN structures to ensure accuracy. The experimental results reveal that Oplixnet significantly decreases the size of ONNs while preserving acceptable accuracy levels. For example, there was a 75.03% reduction in area with a 0.33% drop in accuracy in a fully connected neural network (FCNN), and a 74.88% reduction in area with a 2.38% decrease in accuracy in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have gained popularity recently because of their capacity to improve the speed and energy efficiency of deep learning by taking advantage of high-speed, high-capacity, and low-energy consumption properties. Nevertheless, existing ONNs only adjust the light's amplitude at the input and output, neglecting the possibility of utilizing the light's phase to convey information. A solution has been proposed in the form of a framework named Oplixnet, which transforms image data into both the amplitude and phase of light signals. This method results in a more compact ONN, without losing accuracy, as the input and output components of ONNs are adjusted to utilize both amplitude and phase information. Furthermore, Oplixnet includes a mutual learning mechanism between various ONN structures to maintain accuracy. The experimental results indicate that Oplixnet significantly reduces the size of ONNs while maintaining acceptable accuracy levels. For instance, a 75.03% reduction in area was observed with a 0.33% decrease in accuracy in a fully connected neural network (FCNN), and a 74.88% reduction in area was seen with a 2.38% drop in accuracy in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently become prominent due to their ability to enhance the speed and energy efficiency of deep learning, as they leverage the high-speed, high-capacity, and low-energy consumption properties of light. However, current ONNs only adjust the light's amplitude at the input and output, overlooking the potential of utilizing the light's phase to transmit information. A newly proposed framework called Oplixnet addresses this issue by converting image data into both the amplitude and phase of light signals, leading to a more space-efficient ONN without compromising accuracy, as the input and output elements of ONNs are adapted to handle both amplitude and phase information. Additionally, Oplixnet incorporates a mutual learning system among various ONN structures to preserve accuracy. Experimental findings suggest that Oplixnet considerably decreases the size of ONNs while preserving acceptable accuracy levels. For example, a 75.03% reduction in area was noted with a 0.33% decrease in accuracy in a fully connected neural network (FCNN), and a 74.88% reduction in area was observed with a 2.38% accuracy decline in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have gained popularity recently because of their potential to increase the speed and energy efficiency of deep learning, as they take advantage of the high-speed, high-capacity, and low-energy usage of light. Nevertheless, current ONNs only adjust the amplitude of light at the input and output, neglecting the possibility of using the light's phase to transmit information. A new proposed framework called Oplixnet tackles this problem by converting image data into both the amplitude and phase of light signals, resulting in a more space-efficient ONN that does not sacrifice accuracy. This is achieved by modifying the input and output elements of ONNs to manage both amplitude and phase information. Furthermore, Oplixnet includes a mutual learning system among various ONN structures to maintain accuracy. Experimental results indicate that Oplixnet significantly reduces the size of ONNs while maintaining acceptable accuracy levels. For instance, a 75.03% reduction in area was observed with a 0.33% decrease in accuracy in a fully connected neural network (FCNN), and a 74.88% reduction in area was noted with a 2.38% accuracy decline in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently gained significance due to their ability to enhance the speed and energy efficiency of deep learning by utilizing the high-speed, high-capacity, and low-energy properties of light. However, current ONNs only adjust the light's amplitude at the input and output, disregarding the use of light's phase to transmit information. A new proposed framework, Oplixnet, addresses this issue by converting image data into both the amplitude and phase of light signals, resulting in a more space-efficient ONN that does not compromise accuracy. This is achieved by altering the input and output components of ONNs to handle both amplitude and phase information. Additionally, Oplixnet includes a mutual learning system among various ONN structures to maintain accuracy. Experimental results suggest that Oplixnet substantially decreases the size of ONNs while maintaining acceptable accuracy levels. For example, a 75.03% reduction in area was observed with a 0.33% decrease in accuracy in a fully connected neural network (FCNN), and a 74.88% reduction in area was noted with a 2.38% accuracy decline in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently become important as they can improve the speed and energy efficiency of deep learning by taking advantage of the high-speed, high-capacity, and low-energy features of light. Nevertheless, current ONNs only adjust the light's amplitude at the input and output, neglecting the use of light's phase to convey information. A new suggested framework, called Oplixnet, tackles this problem by transforming image data into both the amplitude and phase of light signals. This results in a more space-saving ONN that does not sacrifice accuracy by changing the input and output components of ONNs to manage both amplitude and phase information. Moreover, Oplixnet includes a mutual learning system among different ONN structures to maintain accuracy. Experimental results indicate that Oplixnet significantly reduces the size of ONNs while preserving acceptable accuracy levels. For instance, a reduction of 75.03% in area was observed with a slight decrease in accuracy of 0.33% in a fully connected neural network (FCNN), and a 74.88% reduction in area was noted with a 2.38% accuracy decline in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have gained significance recently due to their ability to enhance the speed and energy efficiency of deep learning by utilizing the high-speed, high-capacity, and low-energy properties of light. However, current ONNs only adjust the light's amplitude at the input and output, overlooking the use of light's phase to transmit information. A proposed framework, named Oplixnet, addresses this issue by converting image data into both the amplitude and phase of light signals. This results in a more space-efficient ONN without compromising accuracy by altering the input and output components of ONNs to handle both amplitude and phase information. Furthermore, Oplixnet incorporates a mutual learning system among various ONN structures to maintain accuracy. Experimental findings suggest that Oplixnet significantly decreases the size of ONNs while maintaining acceptable accuracy levels. For example, a reduction of 75.03% in area was observed with a slight accuracy decrease of 0.33% in a fully connected neural network (FCNN), and a 74.88% reduction in area was noted with a 2.38% accuracy drop in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have become important recently because they can improve the speed and energy efficiency of deep learning by using the high-speed, high-capacity, and low-energy benefits of light. But, current ONNs only change the light's amplitude at the start and end, while not using the light's phase to transmit information. The proposed framework, called Oplixnet, tackles this problem by turning image data into both the amplitude and phase of light signals. This leads to an ONN that is more space-efficient without losing accuracy, by changing how the input and output parts of ONNs manage both amplitude and phase information. Also, Oplixnet has a system for mutual learning among different ONN structures to keep the accuracy. Test results show that Oplixnet greatly lowers the size of ONNs while still keeping acceptable accuracy levels. For example, there was a reduction of 75.03% in area with a slight accuracy decrease of 0.33% in a fully connected neural network (FCNN), and a 74.88% reduction in area with a 2.38% accuracy drop in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have gained significance recently due to their ability to enhance the speed and energy efficiency of deep learning through the use of light's high-speed, high-capacity, and low-energy advantages. However, current ONNs only adjust the light's amplitude at the beginning and end, neglecting the use of light's phase to convey information. The novel framework, referred to as Oplixnet, addresses this issue by converting image data into both the amplitude and phase of light signals. This results in a more space-efficient ONN, without sacrificing accuracy, by modifying how the input and output components of ONNs handle both amplitude and phase data. Additionally, Oplixnet includes a mutual learning system among various ONN structures to maintain accuracy. Test outcomes indicate that Oplixnet considerably decreases the size of ONNs while preserving acceptable accuracy levels. For instance, a 75.03% decrease in area was observed in a fully connected neural network (FCNN) with a minor accuracy decline of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy drop in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have become important recently because they can improve the speed and energy efficiency of deep learning by utilizing light's high speed, high capacity, and low energy. But, current ONNs only adjust the light's amplitude at the start and end, ignoring the use of light's phase to transmit information. A new framework, called Oplixnet, tackles this problem by changing image data into both the amplitude and phase of light signals. This leads to a more space-efficient ONN, with no loss in accuracy, by altering how the input and output parts of ONNs manage both amplitude and phase data. Furthermore, Oplixnet includes a learning system where various ONN structures teach each other to maintain accuracy. The results show that Oplixnet significantly reduces the size of ONNs while keeping acceptable accuracy levels. For example, a 75.03% decrease in area was seen in a fully connected neural network (FCNN) with a small accuracy drop of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy decrease in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have gained significance recently due to their ability to enhance the speed and energy efficiency of deep learning through the use of light's high speed, large capacity, and low energy consumption. However, current ONNs only adjust the amplitude of light at the beginning and end, neglecting the potential of utilizing light's phase to transmit information. A novel framework named Oplixnet addresses this issue by converting image data into both the amplitude and phase of light signals. This results in a more space-efficient ONN, with no loss of accuracy, by modifying how the input and output components of ONNs handle both amplitude and phase data. Moreover, Oplixnet includes a learning system where various ONN structures educate each other to maintain accuracy. The findings indicate that Oplixnet substantially reduces the size of ONNs while maintaining acceptable accuracy levels. For instance, a 75.03% reduction in area was observed in a fully connected neural network (FCNN) with a minor accuracy drop of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy decrease in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently become important as they can increase the speed and energy efficiency of deep learning by utilizing light's high speed, large capacity, and low energy consumption. But, current ONNs only change the amplitude of light at the start and end, ignoring the possibility of using light's phase to carry information. A new framework called Oplixnet has been developed to tackle this problem by changing image data into both the amplitude and phase of light signals. This results in a more space-saving ONN, with no loss of accuracy, by altering how the input and output parts of ONNs manage both amplitude and phase data. Additionally, Oplixnet includes a learning system where various ONN structures teach each other to maintain accuracy. The results show that Oplixnet significantly decreases the size of ONNs while keeping acceptable accuracy levels. For example, there was a 75.03% reduction in area in a fully connected neural network (FCNN) with a minor accuracy drop of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy decrease in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have gained significance recently due to their ability to enhance the speed and energy efficiency of deep learning by leveraging light's high speed, large capacity, and low energy usage. However, current ONNs only adjust the light's amplitude at the beginning and end, neglecting the potential of utilizing light's phase to transmit information. To address this, a new framework named Oplixnet has been created, which converts image data into both the amplitude and phase of light signals. This results in a more compact ONN, with no compromise in accuracy, by modifying how the input and output components of ONNs handle both amplitude and phase data. Furthermore, Oplixnet incorporates a learning system where various ONN structures educate one another to preserve accuracy. The findings indicate that Oplixnet substantially reduces the size of ONNs while maintaining acceptable accuracy levels. For instance, a 75.03% decrease in area was observed in a fully connected neural network (FCNN) with a minor accuracy drop of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy decline in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have become important recently because they can improve the speed and energy efficiency of deep learning by utilizing light's high speed, large capacity, and low energy use. But, current ONNs only change the light's amplitude at the start and end, while ignoring the possibility of using light's phase to transmit information. To solve this problem, a new framework called Oplixnet has been developed, which changes image data into both the amplitude and phase of light signals. This leads to a more space-efficient ONN, with no loss in accuracy, by altering how the input and output parts of ONNs manage both amplitude and phase data. Additionally, Oplixnet includes a learning system where various ONN structures teach each other to maintain accuracy. The results show that Oplixnet significantly decreases the size of ONNs while still keeping acceptable accuracy levels. For example, a 75.03% reduction in area was seen in a fully connected neural network (FCNN) with a small accuracy drop of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy decrease in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have gained significance recently due to their ability to enhance the speed and energy efficiency of deep learning by taking advantage of light's high speed, large capacity, and low energy consumption. However, existing ONNs only adjust the light's amplitude at the beginning and end, neglecting the use of light's phase to convey information. To address this, a new framework named Oplixnet has been proposed, which converts image data into both the amplitude and phase of light signals. This results in a more space-saving ONN, with no compromise in accuracy, by modifying how the input and output components of ONNs handle both amplitude and phase data. Moreover, Oplixnet incorporates a learning system where different ONN structures educate one another to preserve accuracy. The findings indicate that Oplixnet considerably reduces the size of ONNs while maintaining acceptable accuracy levels. For instance, a 75.03% reduction in area was observed in a fully connected neural network (FCNN) with a minor accuracy drop of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy decline in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have become increasingly important recently because they can improve the speed and energy efficiency of deep learning by utilizing light's high speed, large capacity, and low energy usage. Nevertheless, existing ONNs only adjust the light's amplitude at the start and end, ignoring the potential of using light's phase to transmit information. To tackle this issue, a new framework called Oplixnet has been introduced. This framework converts image data into both the amplitude and phase of light signals, leading to a more space-efficient ONN without sacrificing accuracy. Oplixnet modifies how the input and output components of ONNs manage both amplitude and phase data. Furthermore, Oplixnet includes a learning system where various ONN structures teach each other to maintain accuracy. The results demonstrate that Oplixnet significantly decreases the size of ONNs while preserving acceptable accuracy levels. For example, a 75.03% reduction in area was observed in a fully connected neural network (FCNN) with a slight accuracy drop of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy decline in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have gained significant attention recently due to their ability to enhance the speed and energy efficiency of deep learning by leveraging light's high speed, large capacity, and low energy consumption. However, existing ONNs only adjust the light's amplitude at the beginning and end, neglecting the use of light's phase for information transmission. A novel framework, referred to as Oplixnet, addresses this limitation by converting image data into both the amplitude and phase of light signals. This approach results in a more space-efficient ONN that does not compromise accuracy. Oplixnet modifies how input and output components in ONNs handle amplitude and phase data while incorporating a learning system where various ONN structures educate one another to maintain accuracy. The findings indicate that Oplixnet substantially reduces the size of ONNs while maintaining acceptable accuracy levels. For instance, a 75.03% reduction in area was observed in a fully connected neural network (FCNN) with a minor accuracy decrease of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy drop in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently received much interest because they can increase the speed and energy efficiency of deep learning by utilizing light's fast speed, large capacity, and low energy usage. Nevertheless, current ONNs only adjust the light's amplitude at the start and end, overlooking the use of light's phase for data transmission. A new framework, called Oplixnet, tackles this issue by transforming image data into both the amplitude and phase of light signals, resulting in a more space-saving ONN without sacrificing accuracy. Oplixnet changes how input and output components in ONNs manage amplitude and phase data and includes a learning system where various ONN structures teach each other to maintain accuracy. The results show that Oplixnet significantly decreases the size of ONNs while preserving acceptable accuracy levels. For example, a 75.03% reduction in area was seen in a fully connected neural network (FCNN) with a minor accuracy decrease of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy drop in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have gained significant attention recently due to their ability to enhance the speed and energy efficiency of deep learning by leveraging light's high speed, extensive capacity, and low energy consumption. However, current ONNs only adjust the light's amplitude at the beginning and end, neglecting the use of light's phase for data transmission. A novel framework, named Oplixnet, addresses this problem by converting image data into both the amplitude and phase of light signals, leading to a more compact ONN without compromising accuracy. Oplixnet modifies how input and output components in ONNs handle amplitude and phase data and incorporates a learning system where various ONN structures teach each other to maintain accuracy. The findings indicate that Oplixnet substantially reduces the size of ONNs while maintaining acceptable accuracy levels. For instance, a 75.03% reduction in area was observed in a fully connected neural network (FCNN) with a minor accuracy decline of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy drop in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently received much interest because of their potential to improve the speed and energy efficiency of deep learning through the use of light's high speed, large capacity, and low energy consumption. One limitation of current ONNs is that they only adjust the light's amplitude at the start and end, without utilizing the light's phase for data transmission. A new framework, called Oplixnet, aims to overcome this issue by transforming image data into both the amplitude and phase of light signals, resulting in a more space-efficient ONN without sacrificing accuracy. Oplixnet changes how input and output components in ONNs manage amplitude and phase data and includes a learning system where various ONN structures teach one another to maintain accuracy. The results show that Oplixnet significantly decreases the size of ONNs while still maintaining acceptable accuracy levels. For example, a 75.03% reduction in area was seen in a fully connected neural network (FCNN) with a slight accuracy decrease of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy drop in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have gained considerable attention recently due to their ability to enhance the speed and energy efficiency of deep learning by utilizing light's high speed, large capacity, and low energy consumption. However, a limitation of current ONNs is that they only adjust the light's amplitude at the beginning and end, without taking advantage of the light's phase for data transmission. A new framework, referred to as Oplixnet, aims to address this issue by converting image data into both the amplitude and phase of light signals. This approach results in a more space-efficient ONN without compromising accuracy. Oplixnet modifies how input and output components in ONNs handle amplitude and phase data and includes a learning system where various ONN structures can teach each other to maintain accuracy. The results indicate that Oplixnet significantly reduces the size of ONNs while still maintaining acceptable accuracy levels. For instance, a 75.03% reduction in area was observed in a fully connected neural network (FCNN) with a slight accuracy decrease of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy drop in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently received much interest because of their potential to improve the speed and energy efficiency of deep learning by leveraging light's fast speed, large capacity, and low energy use. One current limitation of ONNs is that they only adjust the light's amplitude at the start and end, without considering the light's phase for data transmission. A new framework, called Oplixnet, seeks to overcome this issue by transforming image data into both the amplitude and phase of light signals. This method allows for a more space-efficient ONN without sacrificing accuracy. Oplixnet changes how input and output components in ONNs manage amplitude and phase data and includes a learning system where various ONN structures can share knowledge to maintain accuracy. The results show that Oplixnet significantly decreases the size of ONNs while still achieving acceptable accuracy levels. For example, there was a 75.03% reduction in area in a fully connected neural network (FCNN) with a minor accuracy decrease of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy drop in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have gained significant attention recently due to their ability to enhance the speed and energy efficiency of deep learning by utilizing the high speed, large capacity, and low energy consumption of light. However, a challenge with ONNs is that they only adjust the amplitude of light at the beginning and end of the transmission process, without taking into account the phase of the light. A new framework, referred to as Oplixnet, aims to address this issue by converting image data into both the amplitude and phase of light signals. This approach enables a more space-efficient ONN without compromising accuracy. Oplixnet modifies how input and output components in ONNs handle amplitude and phase data and incorporates a learning system that allows different ONN structures to exchange knowledge and maintain accuracy. The results indicate that Oplixnet considerably reduces the size of ONNs while still achieving acceptable accuracy levels. For instance, there was a 75.03% reduction in area in a fully connected neural network (FCNN) with a minor accuracy decrease of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy drop in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently gained considerable interest because of their potential to increase the speed and energy efficiency of deep learning through the high speed, large capacity, and low energy consumption of light. One challenge with ONNs is that they only adjust the light's amplitude at the start and end of transmission, neglecting the light's phase. A new framework, called Oplixnet, attempts to tackle this problem by transforming image data into both the amplitude and phase of light signals. This method allows for a more space-efficient ONN while maintaining accuracy. Oplixnet changes how input and output components in ONNs manage amplitude and phase data and includes a learning system for different ONN structures to share knowledge and preserve accuracy. The results show that Oplixnet significantly decreases the size of ONNs while still maintaining acceptable accuracy levels. For example, there was a 75.03% reduction in area in a fully connected neural network (FCNN) with a minor accuracy decrease of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy drop in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently attracted significant attention due to their ability to enhance the speed and energy efficiency of deep learning by utilizing the high speed, large capacity, and low energy consumption of light. However, ONNs only adjust the amplitude of light at the beginning and end of transmission, overlooking the light's phase. A new framework, named Oplixnet, aims to address this issue by converting image data into both the amplitude and phase of light signals. This approach enables a more space-efficient ONN while maintaining accuracy. Oplixnet modifies how input and output components in ONNs handle amplitude and phase data and incorporates a learning system for different ONN structures to exchange knowledge and maintain accuracy. The results indicate that Oplixnet substantially reduces the size of ONNs while still preserving acceptable accuracy levels. For instance, a 75.03% reduction in area was observed in a fully connected neural network (FCNN) with a slight accuracy decrease of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy drop in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently gained considerable interest because of their potential to increase the speed and energy efficiency of deep learning through the high speed, large capacity, and low energy consumption of light. Yet, ONNs only adjust the light's amplitude at the start and end of transmission, neglecting the light's phase. A novel framework, Oplixnet, aims to tackle this problem by transforming image data into both the amplitude and phase of light signals, thereby allowing for a more space-efficient ONN while maintaining accuracy. Oplixnet changes how input and output components in ONNs manage amplitude and phase data and includes a learning system for different ONN structures to share knowledge and maintain accuracy. The results show that Oplixnet significantly decreases the size of ONNs while still preserving acceptable accuracy levels. For example, a 75.03% reduction in area was seen in a fully connected neural network (FCNN) with a slight accuracy decline of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy drop in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently received a lot of attention due to their ability to enhance the speed and energy efficiency of deep learning by utilizing the high speed, large capacity, and low energy consumption of light. However, ONNs only adjust the amplitude of light at the beginning and end of transmission, ignoring the light's phase. A new framework, called Oplixnet, aims to address this issue by converting image data into both the amplitude and phase of light signals, allowing for a more space-efficient ONN while maintaining accuracy. Oplixnet modifies how input and output components in ONNs handle amplitude and phase data and includes a learning system for different ONN structures to exchange knowledge and maintain accuracy. The results indicate that Oplixnet significantly reduces the size of ONNs while still preserving acceptable accuracy levels. For instance, a 75.03% reduction in area was observed in a fully connected neural network (FCNN) with a slight accuracy decrease of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy drop in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have gained significant interest recently because of their potential to improve the speed and energy efficiency of deep learning through the high-speed, large-capacity, and low-energy-consumption properties of light. Nevertheless, ONNs only adjust the light's amplitude at the beginning and end of transmission, disregarding the light's phase. A novel framework, named Oplixnet, has been proposed to tackle this problem. Oplixnet transforms image data into both the amplitude and phase of light signals, enabling a more space-efficient ONN while preserving accuracy. The framework adjusts how input and output components in ONNs manage amplitude and phase data and incorporates a learning system for various ONN structures to share knowledge and maintain accuracy. The findings suggest that Oplixnet considerably decreases the size of ONNs while still preserving acceptable accuracy levels. For example, a 75.03% reduction in area was noted in a fully connected neural network (FCNN) with a minor accuracy decline of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy decrease in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently attracted considerable attention due to their ability to enhance the speed and energy efficiency of deep learning by utilizing light's high-speed, large-capacity, and low-energy-consumption properties. However, ONNs only adjust the light's amplitude at the start and end of transmission, neglecting the light's phase. To address this issue, a new framework called Oplixnet has been introduced. Oplixnet converts image data into both the amplitude and phase of light signals, allowing for a more space-efficient ONN while maintaining accuracy. The framework modifies how input and output components in ONNs handle amplitude and phase data and includes a learning system for various ONN structures to exchange knowledge and maintain accuracy. The results indicate that Oplixnet significantly reduces the size of ONNs while still preserving acceptable accuracy levels. For instance, a 75.03% reduction in area was observed in a fully connected neural network (FCNN) with a minor accuracy drop of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy decrease in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently gained significant interest due to their potential to improve the speed and energy efficiency of deep learning by taking advantage of light's fast speed, large capacity, and low energy consumption. One limitation of ONNs is that they only adjust the light's amplitude at the beginning and end of transmission, ignoring the light's phase. To overcome this issue, the Oplixnet framework has been developed. Oplixnet transforms image data into both the amplitude and phase of light signals, enabling a more space-efficient ONN while maintaining accuracy. The framework changes how input and output components in ONNs manage amplitude and phase data and includes a learning system for various ONN structures to share knowledge and maintain accuracy. The results show that Oplixnet substantially decreases the size of ONNs while still preserving acceptable accuracy levels. For example, a 75.03% reduction in area was seen in a fully connected neural network (FCNN) with a minor accuracy decrease of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy drop in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently received a lot of attention for their ability to enhance the speed and energy efficiency of deep learning by utilizing the high speed, large capacity, and low energy consumption of light. However, ONNs only adjust the amplitude of light at the start and end of transmission, neglecting the phase of light. The Oplixnet framework was created to address this limitation by converting image data into both the amplitude and phase of light signals, allowing for a more space-efficient ONN while maintaining accuracy. Oplixnet modifies how input and output components in ONNs handle amplitude and phase data and includes a learning system for different ONN structures to exchange knowledge and maintain accuracy. The results indicate that Oplixnet significantly reduces the size of ONNs while still maintaining acceptable accuracy levels. For instance, a 75.03% reduction in area was observed in a fully connected neural network (FCNN) with a minor accuracy decrease of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy drop in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently gained significant interest due to their potential to increase the speed and energy efficiency of deep learning through the use of light's high speed, large capacity, and low energy consumption. One limitation of ONNs is that they only adjust the light's amplitude at the beginning and end of transmission, ignoring the light's phase. The Oplixnet framework was developed to tackle this issue by transforming image data into both the amplitude and phase of light signals, resulting in a more space-efficient ONN that maintains accuracy. Oplixnet modifies how input and output components in ONNs manage amplitude and phase data and includes a knowledge-sharing learning system for different ONN structures to ensure accuracy. The findings suggest that Oplixnet substantially decreases the size of ONNs while still maintaining acceptable accuracy levels. For example, a 75.03% reduction in area was observed in a fully connected neural network (FCNN) with a minor accuracy decrease of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy drop in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently received a lot of attention due to their ability to enhance the speed and energy efficiency of deep learning by utilizing light's high speed, large capacity, and low energy consumption. However, a limitation of ONNs is that they only adjust the amplitude of light at the start and end of transmission, neglecting the light's phase. To address this issue, the Oplixnet framework was developed, which converts image data into both the amplitude and phase of light signals, resulting in a more space-efficient ONN that maintains accuracy. Oplixnet modifies how input and output components in ONNs handle amplitude and phase data and includes a learning system that shares knowledge between different ONN structures to ensure accuracy. The results indicate that Oplixnet significantly reduces the size of ONNs while still maintaining acceptable accuracy levels. For instance, a 75.03% reduction in area was observed in a fully connected neural network (FCNN) with a minor accuracy decrease of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy drop in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently gained significant interest due to their potential to improve the speed and energy efficiency of deep learning by taking advantage of light's high speed, large capacity, and low energy usage. One limitation of ONNs is that they only adjust the light's intensity at the beginning and end of transmission, while ignoring the light's phase. To tackle this problem, the Oplixnet framework was developed, which transforms image data into both the intensity and phase of light signals, leading to a more space-efficient ONN that maintains accuracy. Oplixnet changes how input and output components in ONNs manage amplitude and phase data and includes a learning system that exchanges knowledge between various ONN structures to ensure accuracy. The findings suggest that Oplixnet substantially decreases the size of ONNs while still maintaining acceptable accuracy levels. For example, a 75.03% reduction in area was seen in a fully connected neural network (FCNN) with a slight accuracy drop of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy decline in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently seen a surge in popularity because of their ability to enhance the speed and energy efficiency of deep learning, as they utilize light's rapid speed, large capacity, and low energy consumption. However, ONNs only adjust the intensity of light at the start and end of transmission, neglecting the light's phase. To address this, the Oplixnet framework was created, which converts image data into both the intensity and phase of light signals, resulting in a more space-efficient ONN that maintains accuracy. Oplixnet modifies how input and output components in ONNs handle amplitude and phase data and includes a learning system that shares knowledge among various ONN structures to ensure accuracy. The results indicate that Oplixnet significantly reduces the size of ONNs while still maintaining acceptable accuracy levels. For instance, a 75.03% reduction in area was observed in a fully connected neural network (FCNN) with a minor accuracy drop of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy decline in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently gained significant attention due to their potential to improve the speed and energy efficiency of deep learning by leveraging light's high speed, large capacity, and low energy consumption. Nevertheless, ONNs currently only adjust the intensity of light at the beginning and end of transmission, ignoring the light's phase. To tackle this issue, the Oplixnet framework was developed, which transforms image data into both the intensity and phase of light signals, creating a more space-efficient ONN that maintains accuracy. Oplixnet modifies how input and output components in ONNs manage amplitude and phase data and incorporates a learning system that distributes knowledge across various ONN structures to ensure accuracy. The findings suggest that Oplixnet substantially decreases the size of ONNs while still preserving acceptable accuracy levels. For example, a 75.03% reduction in area was noted in a fully connected neural network (FCNN) with a slight accuracy decrease of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy decline in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently received much interest for their ability to increase the speed and energy efficiency of deep learning by utilizing light's high speed, large capacity, and low energy consumption. However, ONNs currently only adjust the light's intensity at the start and end of transmission, neglecting the light's phase. To address this, the Oplixnet framework was created, which converts image data into both the intensity and phase of light signals, resulting in a more space-efficient ONN with maintained accuracy. Oplixnet changes how input and output components in ONNs handle amplitude and phase data and includes a learning system that distributes knowledge throughout different ONN structures to ensure accuracy. The results indicate that Oplixnet significantly reduces the size of ONNs while still preserving acceptable accuracy levels. For instance, a 75.03% reduction in area was observed in a fully connected neural network (FCNN) with a slight accuracy drop of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy decline in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently gained significant attention due to their potential to enhance the speed and energy efficiency of deep learning by leveraging light's high speed, large capacity, and low energy usage. Nevertheless, ONNs currently only adjust the light's intensity at the beginning and end of transmission, overlooking the light's phase. To tackle this issue, the Oplixnet framework was developed, which transforms image data into both the intensity and phase of light signals, leading to a more space-efficient ONN with unchanged accuracy. Oplixnet modifies how input and output components in ONNs manage amplitude and phase data and incorporates a learning system that distributes knowledge across various ONN structures to maintain accuracy. The findings suggest that Oplixnet substantially decreases the size of ONNs while still preserving acceptable accuracy levels. For example, a 75.03% reduction in area was noted in a fully connected neural network (FCNN) with a minor accuracy drop of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy decrease in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently received much interest due to their ability to increase the speed and energy efficiency of deep learning by utilizing light's fast speed, large capacity, and low energy consumption. However, ONNs currently only adjust the light's intensity at the start and end of transmission, neglecting the light's phase. To address this problem, the Oplixnet framework was developed, which converts image data into both the intensity and phase of light signals, resulting in a more space-efficient ONN with the same level of accuracy. Oplixnet changes how input and output components in ONNs handle amplitude and phase data and includes a learning system that distributes knowledge across various ONN structures to maintain accuracy. The results indicate that Oplixnet significantly reduces the size of ONNs while still maintaining acceptable accuracy levels. For instance, a 75.03% reduction in area was observed in a fully connected neural network (FCNN) with a minor accuracy drop of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy decrease in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have gained significant attention recently because of their potential to enhance the speed and energy efficiency of deep learning through the use of light's high speed, large capacity, and low energy consumption. One limitation of current ONNs is that they only adjust the light's intensity at the beginning and end of transmission, ignoring the light's phase. The Oplixnet framework was introduced to tackle this issue by converting image data into both the intensity and phase of light signals, leading to a more space-efficient ONN with comparable accuracy. Oplixnet modifies how input and output components in ONNs manage amplitude and phase data and includes a learning system that distributes knowledge throughout various ONN structures to maintain accuracy. The findings suggest that Oplixnet considerably decreases the size of ONNs while still preserving acceptable accuracy levels. For example, there was a 75.03% reduction in area in a fully connected neural network (FCNN) with a slight accuracy decline of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy decrease in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently received much interest due to their ability to increase the speed and energy efficiency of deep learning by utilizing light's high speed, large capacity, and low energy consumption. However, a current limitation of ONNs is that they only adjust the light's intensity at the start and end of transmission, neglecting the light's phase. The Oplixnet framework was developed to address this issue by transforming image data into both the intensity and phase of light signals, resulting in a more space-efficient ONN with comparable accuracy. Oplixnet changes how input and output components in ONNs handle amplitude and phase data and includes a learning system that distributes knowledge across various ONN structures to maintain accuracy. The results indicate that Oplixnet significantly reduces the size of ONNs while still maintaining acceptable accuracy levels. For instance, a 75.03% reduction in area was observed in a fully connected neural network (FCNN) with a minor accuracy decrease of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy decline in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have gained significant attention recently because of their potential to enhance the speed and energy efficiency of deep learning through the use of light's high speed, large capacity, and low energy consumption. One current limitation of ONNs is that they only adjust the intensity of light at the beginning and end of transmission, without considering the light's phase. To address this, the Oplixnet framework was created to convert image data into both the intensity and phase of light signals, resulting in a more space-efficient ONN with comparable accuracy. Oplixnet modifies how input and output components in ONNs manage amplitude and phase data, and includes a learning system that distributes knowledge across various ONN structures to maintain accuracy. The findings suggest that Oplixnet substantially decreases the size of ONNs while still maintaining acceptable accuracy levels. For example, a 75.03% reduction in area was seen in a fully connected neural network (FCNN) with a minor accuracy decrease of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy decline in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently gained considerable interest due to their ability to increase the speed and energy efficiency of deep learning by utilizing light's high speed, large capacity, and low energy consumption. However, a current challenge is that ONNs only adjust the intensity of light at the start and end of transmission, without taking into account the light's phase. To overcome this, the Oplixnet framework was developed to transform image data into both the intensity and phase of light signals, creating a more space-efficient ONN with similar accuracy. Oplixnet changes how input and output components in ONNs handle amplitude and phase data, and includes a learning system that distributes knowledge across various ONN structures to maintain accuracy. The results indicate that Oplixnet significantly reduces the size of ONNs while still maintaining acceptable accuracy levels. For instance, a 75.03% reduction in area was observed in a fully connected neural network (FCNN) with a minor accuracy decrease of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy decline in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently received significant attention because of their potential to enhance the speed and energy efficiency of deep learning through the use of light's high speed, large capacity, and low energy consumption. One challenge faced by ONNs is that they only adjust the intensity of light at the beginning and end of transmission, without considering the light's phase. To address this issue, the Oplixnet framework was developed, which converts image data into both the intensity and phase of light signals, resulting in a more space-efficient ONN with comparable accuracy. Oplixnet modifies how input and output components in ONNs manage amplitude and phase data, and includes a learning system that distributes knowledge across various ONN structures to maintain accuracy. The findings suggest that Oplixnet substantially decreases the size of ONNs while still maintaining acceptable accuracy levels. For example, a 75.03% reduction in area was observed in a fully connected neural network (FCNN) with a minor accuracy decrease of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy decline in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently gained considerable interest due to their ability to improve the speed and energy efficiency of deep learning by utilizing light's high speed, large capacity, and low energy consumption. However, ONNs only adjust the light's intensity at the beginning and end of transmission, neglecting the light's phase. To tackle this problem, the Oplixnet framework was created, which transforms image data into both the intensity and phase of light signals, leading to a more space-efficient ONN with comparable accuracy. Oplixnet changes how input and output components in ONNs handle amplitude and phase data, and incorporates a learning system that distributes knowledge throughout various ONN structures to maintain accuracy. The results indicate that Oplixnet significantly reduces the size of ONNs while still preserving acceptable accuracy levels. For instance, a 75.03% reduction in area was seen in a fully connected neural network (FCNN) with a slight accuracy drop of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy decrease in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently received a lot of attention for their potential to enhance the speed and energy efficiency of deep learning by leveraging light's high speed, large capacity, and low energy usage. Nevertheless, ONNs currently only adjust the light's intensity at the start and end of transmission, overlooking the light's phase. The Oplixnet framework was developed to address this issue, by converting image data into both the intensity and phase of light signals, resulting in a more space-efficient ONN with comparable accuracy. Oplixnet modifies how input and output components in ONNs manage amplitude and phase data, and includes a learning system that distributes knowledge across various ONN structures to maintain accuracy. The findings suggest that Oplixnet significantly decreases the size of ONNs while still maintaining acceptable accuracy levels. For example, a 75.03% reduction in area was observed in a fully connected neural network (FCNN) with a minor accuracy decline of 0.33%, and a 74.88% reduction in area with a 2.38% accuracy drop in Resnet-32."
        ]
    ]
}