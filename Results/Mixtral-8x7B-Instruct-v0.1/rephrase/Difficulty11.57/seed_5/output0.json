{
    "adjacency_matrix": [
        [
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0
        ]
    ],
    "prompt_init": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "prompt_update": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "personality_list": [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        ""
    ],
    "format_prompt": [
        ""
    ],
    "initial_story": "having the potential for high speed, high throughput, and low energy cost,optical neural networks (onns) have emerged as a promising candidate foraccelerating deep learning tasks. in conventional onns, light amplitudes aremodulated at the input and detected at the output. however, the light phasesare still ignored in conventional structures, although they can also carryinformation for computing. to address this issue, in this paper, we propose aframework called oplixnet to compress the areas of onns by modulating inputimage data into the amplitudes and phase parts of light signals. the input andoutput parts of the onns are redesigned to make full use of both amplitude andphase information. moreover, mutual learning across different onn structures isintroduced to maintain the accuracy. experimental results demonstrate that theproposed framework significantly reduces the areas of onns with the accuracywithin an acceptable range. for instance, 75.03% area is reduced with a 0.33%accuracy decrease on fully connected neural network (fcnn) and 74.88% area isreduced with a 2.38% accuracy decrease on resnet-32. ",
    "stories": [
        [
            "Optical neural networks (ONNs) have gained popularity as a potential solution for accelerating deep learning tasks due to their high speed, high throughput, and low energy consumption. In traditional ONNs, only the light amplitudes are modulated at the input and detected at the output, while the light phases are disregarded despite their ability to carry information for computing. This paper introduces a framework called Oplixnet, which modulates input image data into both the amplitude and phase parts of light signals to compress the ONNs area. The input and output parts of the ONNs are redesigned to utilize both amplitude and phase information. Additionally, mutual learning is implemented across different ONN structures to maintain accuracy. The experimental results show that the proposed framework significantly decreases the ONNs area while keeping the accuracy within an acceptable range. For example, a 75.03% reduction in area was observed with a 0.33% accuracy decrease in a fully connected neural network (FCNN), and a 74.88% reduction in area was seen with a 2.38% accuracy decrease in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently gained significant attention as a promising approach to hasten deep learning processes, thanks to their high speed, high data-processing capacity, and low energy consumption. Conventional ONNs only adjust the light amplitudes at the input and output, neglecting the light phases, even though they can also transmit information for computing. This paper presents Oplixnet, a framework that manipulates input image data into both the amplitude and phase components of light signals, thereby reducing the ONNs' surface area. The input and output sections of ONNs are reconfigured to utilize both amplitude and phase details. Furthermore, a mutual learning system is implemented across various ONN structures to preserve accuracy. The experimental findings reveal that the proposed framework considerably reduces the ONNs' surface area while maintaining acceptable accuracy levels. For instance, a 75.03% decrease in area was noted along with a 0.33% accuracy drop in a fully connected neural network (FCNN), and a 74.88% area reduction was observed with a 2.38% accuracy decrease in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently received much interest as they have the potential to accelerate deep learning procedures, owing to their fast speed, large data-processing capability, and low energy usage. Traditional ONNs only adjust the light intensity at the input and output, ignoring the light phases, even though they can carry information for computation. This paper introduces Oplixnet, a framework that transforms input image data into both the amplitude and phase elements of light signals, thereby minimizing the ONNs' surface area. The input and output components of ONNs are redesigned to utilize both amplitude and phase details. Additionally, a mutual learning system is incorporated across multiple ONN structures to maintain accuracy. The results of the experiment indicate that the proposed framework substantially decreases the ONNs' surface area while preserving acceptable accuracy levels. For example, there was a 75.03% decrease in area with a 0.33% accuracy drop in a fully connected neural network (FCNN), and a 74.88% reduction in area with a 2.38% accuracy decline in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently gained significant attention due to their ability to enhance deep learning processes, as they offer quick speeds, large data handling capacity, and low energy consumption. Conventional ONNs only adjust the light intensity at the input and output, neglecting the light phases, even though they can also contain information for computation. This paper presents Oplixnet, a framework that converts input image data into both the intensity and phase components of light signals, thereby minimizing the ONNs' surface area. The input and output sections of ONNs are restructured to take advantage of both intensity and phase details. Furthermore, a mutual learning system is integrated across multiple ONN structures to maintain accuracy. The experimental results suggest that the proposed framework considerably reduces the ONNs' surface area while maintaining acceptable accuracy levels. For instance, there was a 75.03% decrease in area with a 0.33% accuracy drop in a fully connected neural network (FCNN), and a 74.88% reduction in area with a 2.38% accuracy decline in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently received much interest because of their potential to improve deep learning systems, offering fast speeds, large data capacity, and low energy usage due to adjusting only the light intensity at the input and output while disregarding the light phases, which can also contain computational information. This paper introduces Oplixnet, a framework that transforms input image data into both intensity and phase components of light signals, thereby minimizing the ONNs' surface area by restructuring the input and output sections to utilize both intensity and phase details. Additionally, a mutual learning system is integrated across multiple ONN structures to maintain accuracy. The experimental results demonstrate that Oplixnet significantly reduces the ONNs' surface area while maintaining acceptable accuracy levels, such as a 75.03% decrease in area with a 0.33% accuracy drop in a FCNN, and a 74.88% reduction in area with a 2.38% accuracy decline in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have gained significant attention recently for their ability to enhance deep learning systems, as they offer fast speeds, large data capacity, and low energy consumption. This is achieved by adjusting only the light intensity at the input and output, while not taking into account the light phases, which can also contain computational data. A new framework called Oplixnet is introduced in this paper, which converts input image data into both intensity and phase components of light signals. This results in a reduced surface area for ONNs, as the input and output sections are redesigned to utilize both intensity and phase information. Furthermore, a mutual learning system is incorporated across multiple ONN structures to maintain accuracy. The experimental results show that Oplixnet significantly decreases the surface area of ONNs while still maintaining acceptable accuracy levels. For instance, there is a 75.03% reduction in area with a 0.33% decrease in accuracy in a FCNN, and a 74.88% reduction in area with a 2.38% decline in accuracy in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently received much interest due to their potential to improve deep learning systems, offering fast speeds, large data capacity, and low energy consumption. This is made possible by adjusting only the light intensity at the input and output, without considering the light phases which can also store computational data. In this paper, a new framework named Oplixnet is presented, which transforms input image data into both intensity and phase components of light signals. This modification results in a smaller surface area for ONNs, as the input and output sections are now designed to utilize both intensity and phase information. Additionally, a mutual learning system is integrated between multiple ONN structures to preserve accuracy. The experimental results demonstrate that Oplixnet significantly reduces the surface area of ONNs while maintaining acceptable accuracy levels. For example, there is a 75.03% reduction in area with a 0.33% decrease in accuracy in a FCNN, and a 74.88% reduction in area with a 2.38% drop in accuracy in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently gained significant attention because of their ability to enhance deep learning systems, providing high speeds, extensive data capabilities, and low energy usage. This is achieved by varying only the light intensity at the input and output, without taking into account the light phases that can also hold computational data. In this paper, a new framework named Oplixnet is introduced, which converts input image data into both intensity and phase aspects of light signals. This change results in a decreased surface area for ONNs, as the input and output components are now built to utilize both intensity and phase details. Furthermore, a mutual learning system is incorporated between multiple ONN structures to maintain accuracy. The experimental results indicate that Oplixnet substantially reduces the surface area of ONNs while preserving acceptable accuracy levels. For instance, there is a 75.03% reduction in area with a 0.33% decrease in accuracy in a FCNN, and a 74.88% reduction in area with a 2.38% decline in accuracy in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently received much interest due to their potential to improve deep learning systems, offering high speeds, large data capacities, and low energy consumption. ONNs achieve this by varying only the light intensity at the input and output, without considering the light phases that could also store computational data. This paper introduces a new framework called Oplixnet, which converts input image data into both intensity and phase features of light signals. This modification allows for a smaller surface area for ONNs, as the input and output components now utilize both intensity and phase information. Additionally, a mutual learning system is integrated between multiple ONN structures to maintain accuracy. The experimental results suggest that Oplixnet significantly decreases the surface area of ONNs while maintaining acceptable accuracy levels. For example, there is a 75.03% reduction in area with a 0.33% drop in accuracy in a FCNN, and a 74.88% reduction in area with a 2.38% decrease in accuracy in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently gained significant attention because of their ability to enhance deep learning systems with high-speed processing, large data capacities, and low energy usage. ONNs function by varying only the light intensity at the input and output, without taking into account the light phases that could potentially hold computational data. This paper presents a novel framework named Oplixnet, which transforms input image data into both intensity and phase characteristics of light signals. This adjustment enables a smaller surface area for ONNs, as input and output components now utilize both intensity and phase details. Furthermore, a mutual learning system is incorporated among multiple ONN structures to preserve accuracy. The experimental findings indicate that Oplixnet substantially reduces the surface area of ONNs while maintaining acceptable accuracy levels. For instance, there is a 75.03% reduction in area with a 0.33% decrease in accuracy in a FCNN, and a 74.88% reduction in area with a 2.38% drop in accuracy in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently received much interest due to their potential to improve deep learning systems with fast processing, large data capabilities, and low energy consumption. ONNs work by changing only the light intensity at the input and output, without considering the light phases that could contain computational information. This paper introduces a new framework called Oplixnet, which converts input image data into both intensity and phase properties of light signals. This modification allows for a smaller surface area for ONNs, as input and output components now use both intensity and phase information. Additionally, a mutual learning system is implemented among multiple ONN structures to maintain accuracy. The experimental results show that Oplixnet significantly decreases the surface area of ONNs while maintaining acceptable accuracy levels. For example, there is a 75.03% reduction in area with a 0.33% decrease in accuracy in a FCNN, and a 74.88% reduction in area with a 2.38% decrease in accuracy in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have gained significant attention recently for their ability to enhance deep learning systems with quick processing, extensive data handling, and low energy usage. ONNs function by altering only the light intensity at the input and output, disregarding the light phases that might hold computational data. This paper presents a new framework named Oplixnet, which transforms input image data into both intensity and phase attributes of light signals. This alteration enables a smaller surface area for ONNs, since input and output components now utilize both intensity and phase details. Furthermore, a mutual learning system is established among several ONN structures to preserve accuracy. The experimental results indicate that Oplixnet substantially reduces the surface area of ONNs while keeping acceptable accuracy levels. For instance, a 75.03% reduction in area is observed with a 0.33% decrease in accuracy in a FCNN, and a 74.88% reduction in area is seen with a 2.38% decrease in accuracy in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently received much interest due to their capacity to improve deep learning systems with fast processing, large data handling, and low energy consumption. ONNs work by changing only the light intensity at the input and output, ignoring the light phases that could contain computational information. This paper introduces a new framework called Oplixnet, which converts input image data into both intensity and phase properties of light signals. This modification allows for a smaller surface area for ONNs, as input and output components now utilize both intensity and phase information. Additionally, a collaborative learning system is set up among multiple ONN structures to maintain accuracy. The experimental results show that Oplixnet significantly decreases the surface area of ONNs while maintaining acceptable accuracy levels. For example, a reduction of 75.03% in area is observed with a slight accuracy decrease of 0.33% in a FCNN, and a 74.88% reduction in area is seen with a 2.38% accuracy decrease in Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently gained significant attention due to their ability to enhance deep learning systems with rapid processing, large data handling, and reduced energy consumption. The unique functioning of ONNs involves altering only the light intensity at the input and output, disregarding the light phases that might carry computational data. A new framework named Oplixnet is presented in this paper, which transforms input image data into both intensity and phase attributes of light signals. This adjustment enables a smaller surface area for ONNs, as input and output elements now utilize both intensity and phase details. Furthermore, a collaborative learning system is established among multiple ONNs to preserve accuracy. The experimental results indicate that Oplixnet substantially decreases the surface area of ONNs while maintaining acceptable accuracy levels. For instance, a FCNN exhibits a 75.03% reduction in area with a slight accuracy drop of 0.33%, and Resnet-32 shows a 74.88% reduction in area with a 2.38% accuracy decrease."
        ],
        [
            "Optical neural networks (ONNs) have recently received much interest because they can improve deep learning systems by processing data quickly, handling large amounts of data, and reducing energy consumption. ONNs work by changing only the light's intensity at the input and output, ignoring the light's phases that could contain computational data. This paper introduces a new framework called Oplixnet, which converts image data into both intensity and phase attributes of light signals. This change allows ONNs to have a smaller surface area, as input and output elements now use both intensity and phase information. Additionally, a collaborative learning system is set up among multiple ONNs to maintain accuracy. The experimental results show that Oplixnet significantly decreases the surface area of ONNs while keeping acceptable accuracy levels. For example, a FCNN shows a 75.03% reduction in area with a slight accuracy decrease of 0.33%, and Resnet-32 has a 74.88% reduction in area with a 2.38% accuracy drop."
        ],
        [
            "Optical neural networks (ONNs) have gained significant attention recently due to their ability to enhance deep learning systems by rapidly processing large quantities of data and reducing energy usage. ONNs function by only altering the light's intensity at the input and output, disregarding the light's phases which could potentially contain computational data. This paper presents a new framework named Oplixnet, which transforms image data into both intensity and phase properties of light signals. This modification enables ONNs to have a smaller surface area, as input and output elements now utilize both intensity and phase details. Furthermore, a collaborative learning system is established among multiple ONNs to maintain accuracy. The experimental results indicate that Oplixnet considerably lowers the surface area of ONNs while preserving acceptable accuracy levels. For instance, a FCNN exhibits a 75.03% reduction in area with a minor accuracy decline of 0.33%, and Resnet-32 has a 74.88% reduction in area with a 2.38% accuracy drop."
        ],
        [
            "Optical neural networks (ONNs) have recently received much interest because of their capacity to improve deep learning systems by quickly handling large amounts of data and reducing energy consumption. ONNs work by only adjusting the light's intensity at the input and output, ignoring the light's phases, which might contain additional computational information. This paper introduces a new framework called Oplixnet, which converts image data into both intensity and phase attributes of light signals. This adjustment allows ONNs to have a smaller surface area, as input and output components can now utilize both intensity and phase data. Additionally, a collaborative learning system is set up among several ONNs to maintain accuracy. The experimental results show that Oplixnet significantly decreases the surface area of ONNs while maintaining acceptable accuracy levels. For example, a FCNN shows a 75.03% reduction in area with a slight accuracy decrease of 0.33%, and Resnet-32 has a 74.88% reduction in area with a 2.38% accuracy drop."
        ],
        [
            "Optical neural networks (ONNs) have gained significant attention recently due to their ability to enhance deep learning systems by rapidly processing extensive data and lowering energy usage, primarily by adjusting the light's intensity at the input and output while disregarding the light's phases, which could potentially hold additional computational value. This paper presents a new framework, Oplixnet, which transforms image data into both intensity and phase characteristics of light signals. By doing so, ONNs can minimize their surface area as input and output elements can now benefit from both intensity and phase data. Furthermore, a collaborative learning system is established among multiple ONNs to ensure accuracy. The experimental results indicate that Oplixnet leads to a substantial reduction in ONNs' surface area without compromising acceptable accuracy levels. For instance, a FCNN exhibits a 75.03% decrease in area alongside a minor accuracy drop of 0.33%, and Resnet-32 demonstrates a 74.88% reduction in area with a 2.38% decrease in accuracy."
        ],
        [
            "Optical neural networks (ONNs) have recently received much interest because of their capacity to improve deep learning systems through quick processing of large data and reduced energy consumption, mainly by modifying the light's intensity at the input and output while not considering the light's phases, which might still contain computational worth. This paper introduces a new framework, Oplixnet, that converts image data into both intensity and phase properties of light signals. This approach allows ONNs to minimize their input and output surface area since the elements can now utilize both intensity and phase data. Additionally, a learning system that involves multiple ONNs working together is set up to ensure precision. The experimental results suggest that Oplixnet significantly decreases the surface area of ONNs without sacrificing acceptable accuracy levels. For example, a FCNN shows a 75.03% decrease in area with a 0.33% drop in accuracy, and Resnet-32 exhibits a 74.88% reduction in area with a 2.38% decrease in accuracy."
        ],
        [
            "Optical neural networks (ONNs) have recently gained significant attention due to their ability to enhance deep learning systems with fast processing of large data and lower energy consumption, primarily by adjusting the light's intensity at the input and output while disregarding the light's phases, which could still hold computational value. This paper introduces a new framework, Oplixnet, that transforms image data into both intensity and phase attributes of light signals. By doing so, ONNs can minimize their input and output surface area as their elements can now process both intensity and phase data. Furthermore, a multi-ONN learning system is established to ensure precision. The experimental results indicate that Oplixnet considerably reduces the surface area of ONNs without compromising acceptable accuracy levels. For instance, a FCNN shows a 75.03% decrease in area with a 0.33% drop in accuracy, and Resnet-32 exhibits a 74.88% reduction in area with a 2.38% decrease in accuracy."
        ],
        [
            "Optical neural networks (ONNs) have recently received much interest for improving deep learning systems by rapidly processing large data with lower energy consumption. This is achieved by adjusting the light's intensity at the input and output, although the light's phases, which could also have computational value, are ignored. This paper presents a new framework, Oplixnet, which converts image data into both intensity and phase attributes of light signals, allowing ONNs to minimize their input and output processing area. This is because their elements can now handle both intensity and phase data. Additionally, a multi-ONN learning system is set up to ensure precision. The experimental results demonstrate that Oplixnet significantly decreases the processing area of ONNs without negatively impacting acceptable accuracy levels. For example, a FCNN shows a 75.03% reduction in area with a 0.33% decrease in accuracy, and Resnet-32 exhibits a 74.88% decrease in area with a 2.38% decrease in accuracy."
        ],
        [
            "Optical neural networks (ONNs) have recently gained significant attention due to their ability to enhance deep learning systems by rapidly processing large amounts of data while using less energy. This is accomplished by adjusting the light's intensity at the input and output, although the light's phases, which could potentially hold computational value, are currently disregarded. This paper introduces a new framework, Oplixnet, which converts image data into both intensity and phase properties of light signals, thereby enabling ONNs to minimize the area required for input and output processing. This is possible because the ONN elements can now manage both intensity and phase data. Furthermore, a multi-ONN learning system is established to ensure precision. The experimental results indicate that Oplixnet substantially reduces the processing area of ONNs without negatively affecting acceptable accuracy levels. For instance, a FCNN shows a 75.03% reduction in area with a 0.33% decrease in accuracy, and Resnet-32 exhibits a 74.88% decrease in area with a 2.38% decrease in accuracy."
        ],
        [
            "Optical neural networks (ONNs) have recently received much interest due to their capacity to improve deep learning systems with fast processing of large data sets while using minimal energy. This is achieved by adjusting the light's intensity at the input and output, although the light's phases, which could also be computationally valuable, are currently not utilized. This paper presents a new framework, Oplixnet, which converts image data into both intensity and phase attributes of light signals, thereby allowing ONNs to reduce the area required for input and output processing. This is made possible as ONN components can now handle both intensity and phase data. Additionally, a multi-ONN learning system is set up to ensure precision. The experimental results suggest that Oplixnet significantly decreases the processing area of ONNs without negatively impacting acceptable accuracy levels. For example, a FCNN shows a 75.03% reduction in area with a 0.33% decrease in accuracy, and Resnet-32 exhibits a 74.88% reduction in area with a 2.38% decrease in accuracy."
        ],
        [
            "Optical neural networks (ONNs) have gained significant attention recently because of their ability to enhance deep learning systems with rapid processing of extensive data sets while consuming low energy. ONNs achieve this by adjusting the light's intensity at the input and output, although they currently do not take advantage of the light's phases, which could also be computationally beneficial. This paper introduces a new framework, Oplixnet, which transforms image data into both intensity and phase properties of light signals, thereby enabling ONNs to decrease the area required for input and output processing. This is achievable since ONN components can now manage both intensity and phase data. Furthermore, a learning system consisting of multiple ONNs is established to ensure precision. The experimental results indicate that Oplixnet considerably reduces the processing area of ONNs without adversely affecting acceptable accuracy levels. For instance, a FCNN shows a 75.03% reduction in area with a 0.33% decrease in accuracy, and Resnet-32 exhibits a 74.88% reduction in area with a 2.38% decrease in accuracy."
        ],
        [
            "Optical neural networks (ONNs) have recently received much interest due to their capacity to improve deep learning systems with fast processing of large data sets while using minimal energy. ONNs accomplish this by modifying the light's intensity at the input and output, although they presently do not utilize the light's phases, which could also be computationally advantageous. This paper presents a new framework, Oplixnet, which converts image data into both intensity and phase attributes of light signals, thereby allowing ONNs to decrease the area needed for input and output processing. This is achieved as ONN components can now handle both intensity and phase data. Moreover, a multi-ONN learning system is set up to ensure accuracy. The experimental results demonstrate that Oplixnet significantly decreases the processing area of ONNs without negatively impacting acceptable accuracy levels. For example, a FCNN shows a 75.03% reduction in area with a 0.33% decrease in accuracy, and Resnet-32 exhibits a 74.88% reduction in area with a 2.38% decrease in accuracy."
        ],
        [
            "Optical neural networks (ONNs) have gained significant attention recently for their ability to enhance deep learning systems with rapid processing of extensive data sets while consuming minimal energy. ONNs achieve this by adjusting the light's intensity at the input and output, although they currently do not exploit the light's phases, which could also offer computational benefits. This paper introduces a novel framework, Oplixnet, that transforms image data into both intensity and phase properties of light signals, thereby enabling ONNs to reduce the area required for input and output processing. This is made possible as ONN components can now manage both intensity and phase data. Furthermore, a learning system consisting of multiple ONNs is established to ensure accuracy. The experimental results indicate that Oplixnet significantly decreases the processing area of ONNs without negatively affecting acceptable accuracy levels. For instance, a FCNN shows a 75.03% reduction in area with a 0.33% decrease in accuracy, and Resnet-32 exhibits a 74.88% reduction in area with a 2.38% decrease in accuracy."
        ],
        [
            "Optical neural networks (ONNs) have recently received much interest due to their capacity to improve deep learning systems with fast processing of large data sets while using little energy. This is achieved by ONNs adjusting the light's intensity at the input and output, although they presently do not utilize the light's phases, which could also provide computational advantages. This paper presents a new framework, Oplixnet, that converts image data into both intensity and phase attributes of light signals, thereby allowing ONNs to decrease the area needed for input and output processing. This is achievable since ONN components can now handle both intensity and phase data. Moreover, a multi-ONN learning system is set up to ensure accuracy. The experimental results demonstrate that Oplixnet considerably reduces the processing area of ONNs without negatively impacting acceptable accuracy levels. For example, a FCNN shows a 75.03% reduction in area with a 0.33% decrease in accuracy, and Resnet-32 exhibits a 74.88% reduction in area with a 2.38% decrease in accuracy."
        ],
        [
            "Optical neural networks (ONNs) have recently gained significant attention because of their ability to enhance deep learning systems with quick processing of extensive data sets while consuming minimal energy. This is made possible by ONNs adjusting the light's intensity at the input and output, although they currently do not take advantage of the light's phases, which could also offer computational benefits. This paper introduces a new framework, Oplixnet, that transforms image data into both intensity and phase properties of light signals, thus enabling ONNs to decrease the area required for input and output processing. This is achievable since ONN components can now process both intensity and phase data. Additionally, a multi-ONN learning system is established to ensure precision. The experimental results indicate that Oplixnet substantially decreases the processing area of ONNs without negatively affecting acceptable accuracy levels. For instance, a FCNN shows a 75.03% reduction in area with a 0.33% decrease in accuracy, and Resnet-32 exhibits a 74.88% reduction in area with a 2.38% decrease in accuracy."
        ],
        [
            "Optical neural networks (ONNs) have recently received much interest due to their capacity to improve deep learning systems with fast processing of large data sets while using little energy. This is achieved by ONNs adjusting the light's intensity at the input and output, although they do not yet utilize the light's phases, which could also provide computational advantages. This paper presents a new framework, Oplixnet, that converts image data into both intensity and phase attributes of light signals, thereby allowing ONNs to reduce the area needed for input and output processing. This is achieved as ONN components can now handle both intensity and phase data. Furthermore, a multi-ONN learning system is set up to ensure accuracy. The experimental results suggest that Oplixnet significantly decreases the processing area of ONNs without negatively impacting acceptable accuracy levels. For example, a FCNN shows a 75.03% reduction in area with a 0.33% decrease in accuracy, and Resnet-32 exhibits a 74.88% reduction in area with a 2.38% decrease in accuracy."
        ],
        [
            "Optical neural networks (ONNs) have gained significant attention recently because of their ability to enhance deep learning systems with rapid processing of extensive data sets while consuming minimal energy. ONNs adjust the light's intensity at the input and output, but they do not yet take advantage of the light's phases, which could also offer computational benefits. This paper introduces a novel framework, Oplixnet, that transforms image data into both intensity and phase properties of light signals, thereby enabling ONNs to decrease the area required for input and output processing. This is made possible as ONN components can now manage both intensity and phase data. Additionally, a multi-ONN learning system is established to ensure accuracy. The experimental findings indicate that Oplixnet substantially reduces the processing area of ONNs without negatively affecting acceptable accuracy levels. For instance, a FCNN shows a 75.03% reduction in area with a 0.33% decrease in accuracy, and Resnet-32 exhibits a 74.88% reduction in area with a 2.38% decrease in accuracy."
        ],
        [
            "Optical neural networks (ONNs) have recently received much interest due to their capacity to improve deep learning systems by quickly processing large data sets while using little energy. ONNs currently adjust the light's intensity at the input and output but do not utilize the light's phases, which could also provide computational benefits. This paper proposes a new framework, Oplixnet, which converts image data into both intensity and phase attributes of light signals, thereby allowing ONNs to decrease the area needed for input and output processing. This is achieved as ONN components can now handle both intensity and phase data. Furthermore, a multi-ONN learning system is set up to ensure accuracy. The experimental results show that Oplixnet significantly reduces the processing area of ONNs without negatively impacting acceptable accuracy levels. For example, a FCNN shows a 75.03% reduction in area with a 0.33% decrease in accuracy, and Resnet-32 exhibits a 74.88% reduction in area with a 2.38% decrease in accuracy."
        ],
        [
            "Optical neural networks (ONNs) have recently gained significant attention because of their ability to enhance deep learning systems with fast processing of large data sets while using minimal energy. While ONNs currently regulate the light's intensity at the input and output, they do not utilize the light's phases, which could also offer computational advantages. This paper introduces a novel framework, Oplixnet, which transforms image data into both intensity and phase attributes of light signals, thereby enabling ONNs to decrease the area required for input and output processing. This is made possible as ONN components can now manage both intensity and phase data. Additionally, a multi-ONN learning system is established to ensure accuracy. The experimental results indicate that Oplixnet substantially decreases the processing area of ONNs without negatively affecting acceptable accuracy levels. For instance, a FCNN shows a 75.03% reduction in area with a 0.33% decrease in accuracy, and Resnet-32 exhibits a 74.88% reduction in area with a 2.38% decrease in accuracy."
        ],
        [
            "Optical neural networks (ONNs) have recently received much interest due to their capacity to improve deep learning systems by quickly processing large data sets with minimal energy consumption. At present, ONNs control the light's intensity at the input and output but do not take advantage of the light's phases, which could also provide computational benefits. This paper presents a new framework, Oplixnet, that converts image data into both intensity and phase properties of light signals, thereby allowing ONNs to reduce the area needed for input and output processing. This is achieved as ONN components can now handle both intensity and phase data. Furthermore, a multi-ONN learning system is set up to ensure precision. The experimental results suggest that Oplixnet significantly decreases the processing area of ONNs without negatively impacting acceptable accuracy levels. For example, a FCNN shows a 75.03% reduction in area with a 0.33% decrease in accuracy, and Resnet-32 exhibits a 74.88% reduction in area with a 2.38% decrease in accuracy."
        ],
        [
            "Optical neural networks (ONNs) have gained significant attention recently, thanks to their ability to enhance deep learning systems with fast processing of large data sets while consuming minimal energy. Currently, ONNs manage the light's intensity at the input and output levels, but they do not utilize the light's phases, which could offer additional computational advantages. This paper introduces a novel framework, Oplixnet, that transforms image data into both intensity and phase attributes of light signals, thereby enabling ONNs to diminish the area required for input and output processing. This is made possible as ONN components can now process both intensity and phase data. Additionally, a multi-ONN learning system is established to ensure precision. The experimental findings indicate that Oplixnet substantially reduces the processing area of ONNs without compromising acceptable accuracy levels. For instance, a FCNN shows a 75.03% reduction in area with a 0.33% drop in accuracy, and Resnet-32 displays a 74.88% reduction in area with a 2.38% decrease in accuracy."
        ],
        [
            "Optical neural networks (ONNs) have recently received much interest due to their capacity to improve deep learning systems by quickly processing large data sets while using a small amount of energy, primarily manipulating light's intensity at the input and output stages. Nevertheless, ONNs fail to take advantage of the light's phases, which could provide further computational benefits. This paper proposes a new framework, Oplixnet, that converts image data into both intensity and phase properties of light signals, thereby allowing ONNs to minimize the area needed for input and output processing. This is achieved as ONN components can now manage both intensity and phase data. Furthermore, a multi-ONN learning system is set up to ensure precision. The experimental results demonstrate that Oplixnet significantly decreases the processing area of ONNs without undermining acceptable accuracy levels. For example, a FCNN shows a 75.03% reduction in area with a 0.33% decline in accuracy, and Resnet-32 displays a 74.88% reduction in area with a 2.38% drop in accuracy."
        ],
        [
            "Optical neural networks (ONNs) have gained significant attention recently because of their ability to enhance deep learning systems with fast processing of large data sets while using minimal energy, mainly by manipulating light's intensity at the input and output levels. However, ONNs do not utilize light's phases, which could offer additional computational advantages. This paper introduces a novel framework, Oplixnet, that transforms image data into both intensity and phase attributes of light signals, thereby enabling ONNs to reduce the area required for input and output processing. This is made possible as ONN components can now handle both intensity and phase information. Additionally, a multi-ONN learning system is established to ensure precision. The experimental results indicate that Oplixnet substantially decreases the processing area of ONNs without compromising acceptable accuracy levels. For instance, a FCNN exhibits a 75.03% reduction in area with a 0.33% decrease in accuracy, and Resnet-32 shows a 74.88% reduction in area with a 2.38% drop in accuracy."
        ],
        [
            "Optical neural networks (ONNs) have recently received much interest due to their capacity to improve deep learning systems with rapid processing of extensive data sets utilizing minimal energy, primarily through the manipulation of light's intensity at the input and output levels. Nonetheless, ONNs do not take advantage of light's phases, which could provide further computational benefits. This paper presents a new framework, Oplixnet, that converts image data into both intensity and phase characteristics of light signals, thereby allowing ONNs to decrease the area needed for input and output processing. This is achieved as ONN components can now manage both intensity and phase data. Furthermore, a multi-ONN learning system is set up to ensure precision. The experimental results suggest that Oplixnet significantly lowers the processing area of ONNs without sacrificing acceptable accuracy levels. For example, a FCNN shows a 75.03% reduction in area with a 0.33% decrease in accuracy, and Resnet-32 exhibits a 74.88% reduction in area with a 2.38% drop in accuracy."
        ],
        [
            "Optical neural networks (ONNs) have gained significant attention recently because of their ability to enhance deep learning systems by quickly processing large data sets using minimal energy, mainly by adjusting the light's intensity at the input and output levels. However, ONNs do not currently utilize light's phases, which could offer additional computational advantages. This paper introduces a new framework, Oplixnet, that transforms image data into both intensity and phase features of light signals, thereby enabling ONNs to reduce the area required for input and output processing. This is made possible as ONN components can now handle both intensity and phase information. Additionally, a learning system with multiple ONNs is established to ensure accuracy. The experimental results indicate that Oplixnet significantly decreases the processing area of ONNs without compromising acceptable accuracy levels. For instance, a FCNN shows a 75.03% reduction in area with a 0.33% decrease in accuracy, and Resnet-32 exhibits a 74.88% reduction in area with a 2.38% drop in accuracy."
        ],
        [
            "Optical neural networks (ONNs) have recently received much interest due to their capacity to improve deep learning systems with fast processing of large data sets using minimal energy, primarily by adjusting the light's intensity at the input and output. Nevertheless, ONNs do not yet take advantage of light's phases, which could provide additional computational benefits. This paper proposes a new framework, Oplixnet, that converts image data into both intensity and phase characteristics of light signals, thereby allowing ONNs to decrease the area needed for input and output processing. This is achievable since ONN components can now manage both intensity and phase data. Furthermore, a multi-ONN learning system is created to ensure accuracy. The experimental results suggest that Oplixnet substantially reduces the processing area of ONNs without significant loss in acceptable accuracy levels. For example, a FCNN shows a 75.03% reduction in area with a 0.33% decrease in accuracy, and Resnet-32 exhibits a 74.88% reduction in area with a 2.38% drop in accuracy."
        ],
        [
            "Optical neural networks (ONNs) have gained significant attention recently because of their ability to enhance deep learning systems by rapidly processing large datasets with minimal energy consumption, mainly by adjusting the light's intensity at the input and output. However, ONNs currently do not utilize light's phases, which could offer further computational benefits. This paper introduces a new framework, Oplixnet, that transforms image data into both intensity and phase features of light signals, thereby enabling ONNs to decrease the area required for input and output processing. This is feasible since ONN components can now handle both intensity and phase information. Additionally, a multi-ONN learning system is developed to ensure accuracy. The experimental results indicate that Oplixnet significantly decreases the processing area of ONNs with negligible impact on acceptable accuracy levels. For instance, a FCNN shows a 75.03% reduction in area with a 0.33% decrease in accuracy, and Resnet-32 exhibits a 74.88% reduction in area with a 2.38% drop in accuracy."
        ],
        [
            "Optical neural networks (ONNs) have recently received much interest due to their capacity to improve deep learning systems with fast processing of large datasets while consuming minimal energy, primarily by adjusting the light's intensity at the input and output. Yet, ONNs currently do not take advantage of light's phases, which could provide additional computational advantages. This paper proposes a new framework, Oplixnet, that converts image data into both intensity and phase features of light signals, thus allowing ONNs to reduce the area needed for input and output processing. This is achievable since ONN components can now process both intensity and phase information. Furthermore, a multi-ONN learning system is established to ensure precision. The experimental results suggest that Oplixnet considerably decreases the processing area of ONNs with a minimal effect on acceptable accuracy levels. For example, a FCNN shows a 75.03% reduction in area with a 0.33% decrease in accuracy, and Resnet-32 exhibits a 74.88% reduction in area with a 2.38% drop in accuracy."
        ],
        [
            "Optical neural networks (ONNs) have gained significant attention recently because of their ability to enhance deep learning systems with swift processing and minimal energy consumption, mainly by manipulating the light's intensity at the input and output. However, ONNs currently neglect the use of light's phases, which could offer further computational benefits. This paper introduces a new framework, Oplixnet, that transforms image data into both intensity and phase features of light signals, thereby enabling ONNs to minimize the area required for input and output processing. This is feasible as ONN components can now handle both intensity and phase information. Moreover, a multi-ONN learning system is set up to guarantee accuracy. The experimental results indicate that Oplixnet substantially reduces the processing area of ONNs with a negligible impact on acceptable accuracy levels. For instance, a FCNN shows a 75.03% reduction in area with a 0.33% decrease in accuracy, and Resnet-32 exhibits a 74.88% reduction in area with a 2.38% drop in accuracy."
        ],
        [
            "Optical neural networks (ONNs) have recently gained considerable interest due to their capability of improving deep learning systems with fast processing and low energy usage, primarily through the manipulation of light's intensity at the input and output. Nevertheless, current ONNs do not utilize light's phases, which could provide additional computational advantages. This paper presents a new framework, Oplixnet, that converts image data into both intensity and phase features of light signals, thereby allowing ONNs to minimize the area needed for input and output processing. This is achievable since ONN components can now manage both intensity and phase information. Furthermore, a learning system with multiple ONNs is established to ensure accuracy. The experimental results suggest that Oplixnet significantly decreases the processing area of ONNs with a minimal effect on acceptable accuracy levels. For example, a FCNN shows a 75.03% reduction in area with a 0.33% decrease in accuracy, and Resnet-32 exhibits a 74.88% reduction in area with a 2.38% drop in accuracy."
        ],
        [
            "Optical neural networks (ONNs) have recently received significant attention because of their ability to enhance deep learning systems with quick processing and low energy consumption, mainly by controlling the light's intensity at the input and output. However, existing ONNs do not take advantage of light's phases, which could offer further computational benefits. This paper introduces a new framework, Oplixnet, that transforms image data into both intensity and phase characteristics of light signals, thereby enabling ONNs to minimize the area required for input and output processing. This is possible since ONN components can now handle both intensity and phase data. Moreover, a multi-ONN learning system is set up to ensure accuracy. The experimental results indicate that Oplixnet substantially reduces the processing area of ONNs with a negligible impact on acceptable accuracy levels. For instance, a FCNN shows a 75.03% reduction in area with a 0.33% decrease in accuracy, and Resnet-32 exhibits a 74.88% reduction in area with a 2.38% drop in accuracy."
        ],
        [
            "Optical neural networks (ONNs) have recently gained considerable interest due to their potential to improve deep learning systems with fast processing and low energy usage, primarily by managing the light's intensity at the input and output. Yet, current ONNs do not utilize light's phases, which could provide additional computational advantages. This paper proposes a new framework, Oplixnet, that converts image data into both intensity and phase properties of light signals, thereby allowing ONNs to minimize the area needed for input and output processing. This is achievable since ONN components can now process both intensity and phase data. Furthermore, a multi-ONN learning system is established to ensure precision. The experimental results demonstrate that Oplixnet significantly decreases the processing area of ONNs with a minimal impact on acceptable accuracy levels. For example, a FCNN shows a 75.03% reduction in area with a 0.33% decrease in accuracy, and Resnet-32 exhibits a 74.88% reduction in area with a 2.38% decline in accuracy."
        ],
        [
            "Optical neural networks (ONNs) have recently received significant attention because of their ability to enhance deep learning systems with quick processing and low energy consumption, mainly by controlling the light's intensity at the input and output. However, existing ONNs do not take advantage of light's phases, which could offer further computational benefits. This paper presents a new framework, Oplixnet, that transforms image data into both intensity and phase characteristics of light signals, thereby enabling ONNs to reduce the area required for input and output processing. This is made possible as ONN components can now handle both intensity and phase data. Additionally, a multi-ONN learning system is set up to ensure precision. The experimental results indicate that Oplixnet substantially reduces the processing area of ONNs with a slight effect on acceptable accuracy levels. For instance, a FCNN shows a 75.03% reduction in area with a 0.33% drop in accuracy, and Resnet-32 exhibits a 74.88% reduction in area with a 2.38% decrease in accuracy."
        ],
        [
            "Optical neural networks (ONNs) have recently gained considerable interest due to their capacity to improve deep learning systems with fast processing and low energy usage, largely through manipulation of light's intensity at the input and output. Yet, current ONNs do not utilize light's phases, which could provide additional computational advantages. This paper introduces a new framework, Oplixnet, that converts image data into both intensity and phase attributes of light signals, thereby allowing ONNs to decrease the area needed for input and output processing. This is achieved as ONN components can now manage both intensity and phase data. Furthermore, a multi-ONN learning system is established to ensure accuracy. The experimental results demonstrate that Oplixnet significantly decreases the processing area of ONNs with a minor impact on acceptable accuracy levels. For example, a FCNN shows a 75.03% reduction in area with a 0.33% decline in accuracy, and Resnet-32 displays a 74.88% reduction in area with a 2.38% drop in accuracy."
        ],
        [
            "Optical neural networks (ONNs) have recently received significant attention due to their ability to enhance deep learning systems with quick processing and low energy consumption, mainly by controlling the light's intensity at the input and output. However, existing ONNs do not take advantage of light's phases, which could offer further computational benefits. This paper proposes a novel framework, Oplixnet, that transforms image data into both intensity and phase properties of light signals, thereby enabling ONNs to minimize the area required for input and output processing. This is made possible as ONN components can now handle both intensity and phase data. Additionally, a multi-ONN learning system is set up to guarantee accuracy. The experimental results indicate that Oplixnet substantially reduces the processing area of ONNs with a minimal effect on acceptable accuracy levels. For instance, a FCNN shows a 75.03% reduction in area with a 0.33% decrease in accuracy, and Resnet-32 displays a 74.88% reduction in area with a 2.38% drop in accuracy."
        ],
        [
            "Optical neural networks (ONNs) have recently gained considerable interest because of their capacity to improve deep learning systems with fast processing and low energy usage, largely through managing the light's intensity at the input and output. Nevertheless, current ONNs do not utilize light's phases, which could provide additional computational advantages. This paper presents a new framework, Oplixnet, that converts image data into both intensity and phase characteristics of light signals, thus allowing ONNs to minimize the area needed for input and output processing. This is achievable since ONN components can now manage both intensity and phase data. Furthermore, a multi-ONN learning system is established to ensure accuracy. The experimental results show that Oplixnet significantly decreases the processing area of ONNs with a negligible impact on acceptable accuracy levels. For example, a FCNN shows a 75.03% reduction in area with a 0.33% decrease in accuracy, and Resnet-32 exhibits a 74.88% reduction in area with a 2.38% decline in accuracy."
        ],
        [
            "Optical neural networks (ONNs) have recently received significant attention due to their ability to enhance deep learning systems with quick processing and low energy consumption, mainly by controlling the light's intensity at the input and output. However, current ONNs do not take advantage of light's phases, which could offer further computational benefits. This paper introduces a new framework, Oplixnet, that transforms image data into both intensity and phase attributes of light signals, thereby enabling ONNs to minimize the area required for input and output processing. This is made possible since ONN components can now handle both intensity and phase data. Additionally, a multi-ONN learning system is set up to ensure precision. The experimental results indicate that Oplixnet substantially reduces the processing area of ONNs with a minimal impact on acceptable accuracy levels. For instance, a FCNN shows a 75.03% reduction in area with a 0.33% decrease in accuracy, and Resnet-32 exhibits a 74.88% reduction in area with a 2.38% decline in accuracy."
        ]
    ]
}