{
    "adjacency_matrix": [
        [
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0
        ]
    ],
    "prompt_init": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "prompt_update": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "personality_list": [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        ""
    ],
    "format_prompt": [
        ""
    ],
    "initial_story": "having the potential for high speed, high throughput, and low energy cost,optical neural networks (onns) have emerged as a promising candidate foraccelerating deep learning tasks. in conventional onns, light amplitudes aremodulated at the input and detected at the output. however, the light phasesare still ignored in conventional structures, although they can also carryinformation for computing. to address this issue, in this paper, we propose aframework called oplixnet to compress the areas of onns by modulating inputimage data into the amplitudes and phase parts of light signals. the input andoutput parts of the onns are redesigned to make full use of both amplitude andphase information. moreover, mutual learning across different onn structures isintroduced to maintain the accuracy. experimental results demonstrate that theproposed framework significantly reduces the areas of onns with the accuracywithin an acceptable range. for instance, 75.03% area is reduced with a 0.33%accuracy decrease on fully connected neural network (fcnn) and 74.88% area isreduced with a 2.38% accuracy decrease on resnet-32. ",
    "stories": [
        [
            "Optical neural networks (ONNs) have gained attention as a possible way to speed up deep learning tasks, thanks to their high speed, high throughput, and low energy consumption. In traditional ONNs, only the light amplitudes are modified at the input and detected at the output, while the light phases are disregarded. However, these phases can also contain information that is useful for computing. To tackle this problem, the authors of this paper introduce a framework called Oplixnet, which compresses the areas of ONNs by encoding input image data into both the amplitude and phase components of light signals. The input and output sections of the ONNs are redesigned to take advantage of both the amplitude and phase data. Additionally, a mutual learning approach between different ONN structures is used to preserve accuracy. The experimental results show that this framework significantly decreases the areas of ONNs while keeping the accuracy within an acceptable range. For example, a 75.03% reduction in area was achieved with a 0.33% decrease in accuracy for a fully connected neural network (FCNN), and a 74.88% reduction in area was achieved with a 2.38% decrease in accuracy for Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently gained interest as they have the potential to accelerate deep learning tasks due to their high speed, high data throughput, and low energy usage. Conventional ONNs only adjust the light amplitudes at the input and detect them at the output while ignoring the light phases. However, the light phases can also contain beneficial computing information. To address this, the authors of this paper propose a framework named Oplixnet, which compresses the ONNs by mapping input image data to both the amplitude and phase components of light signals. The input and output components of ONNs are modified to utilize both the amplitude and phase data. Furthermore, a mutual learning strategy between various ONN structures is employed to maintain accuracy. The experimental results indicate that this framework considerably reduces the size of ONNs while keeping the accuracy within an acceptable range. For instance, a 75.03% reduction in area was achieved with a 0.33% decrease in accuracy for a fully connected neural network (FCNN), and a 74.88% reduction in area was achieved with a 2.38% decrease in accuracy for Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently become a focus of study as they can enhance deep learning tasks by providing high speed, large data capacity, and low energy consumption. Traditional ONNs adjust only the light input amplitudes and detect output amplitudes, disregarding potential computing information in light phases. A new framework named Oplixnet is introduced in this paper to optimize ONNs by mapping input image data to both the light amplitude and phase components. The input and output of ONNs are altered to handle both amplitude and phase data. Additionally, a mutual learning approach is used among various ONN structures to maintain accuracy. Experimental results demonstrate that this framework significantly decreases ONN size while maintaining acceptable accuracy levels. For example, a 75.03% reduction in area was achieved with a 0.33% decrease in accuracy for a fully connected neural network (FCNN), and a 74.88% reduction in area was achieved with a 2.38% decrease in accuracy for Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently gained significant attention due to their ability to improve deep learning tasks with high-speed processing, large data capacity, and reduced energy consumption. Conventional ONNs only adjust light input amplitudes and measure output amplitudes, neglecting the possible computational power of light phases. This paper proposes a novel framework, Oplixnet, to optimize ONNs by mapping input image data to both light amplitude and phase components. The input and output of ONNs are modified to accommodate both amplitude and phase data. Furthermore, a mutual learning strategy is implemented among different ONN structures to preserve accuracy. The experimental results indicate that this framework significantly reduces the size of ONNs while maintaining acceptable accuracy levels. For instance, a 75.03% reduction in area was achieved with a 0.33% decrease in accuracy for a fully connected neural network (FCNN), and a 74.88% reduction in area was achieved with a 2.38% decrease in accuracy for Resnet-32."
        ],
        [
            "Optical neural networks (ONNs) have recently received much interest due to their potential to enhance deep learning tasks through fast processing, large data capacity, and lower energy usage. Traditional ONNs only adjust and read light input amplitudes, overlooking the computational potential of light phases. This paper puts forth a new framework, Oplixnet, that optimizes ONNs by mapping input image data to both light amplitude and phase components. The input and output of ONNs are adjusted to handle amplitude and phase data. Additionally, a mutual learning approach is utilized among various ONN structures to maintain accuracy. The experimental results show that this framework significantly decreases the size of ONNs while preserving acceptable accuracy levels. For example, a 75.03% reduction in area was achieved with a 0.33% drop in accuracy for a fully connected neural network (FCNN), and a 74.88% reduction in area was achieved with a 2.38% drop in accuracy for Resnet-32."
        ],
        [
            "Recent attention has been drawn to Optical Neural Networks (ONNs) because of their ability to improve deep learning tasks with quick processing, large data capacity, and reduced energy consumption. However, conventional ONNs only modify and detect light input amplitudes, neglecting the computational power of light phases. This paper introduces a new framework, Oplixnet, that optimizes ONNs by converting input image data into both light amplitude and phase components. The input and output of ONNs are modified to manage amplitude and phase data. Furthermore, a mutual learning strategy is implemented among various ONN structures to maintain accuracy. The experimental results indicate that this framework considerably decreases the size of ONNs while maintaining acceptable accuracy levels. For instance, a 75.03% reduction in area was achieved with a 0.33% decrease in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was achieved with a 2.38% decrease in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have recently gained popularity due to their potential to enhance deep learning tasks through fast processing, large data handling, and reduced energy usage. The current ONNs, however, only adjust and recognize light input amplitudes, disregarding the computational potential of light phases. This paper presents a novel framework, Oplixnet, that optimizes ONNs by transforming input image data into both light amplitude and phase components. This modification affects both the input and output of ONNs to manage amplitude and phase data. Additionally, a mutual learning approach is implemented among different ONN structures to maintain accuracy. The experimental results suggest that this framework significantly reduces the size of ONNs while maintaining acceptable accuracy levels. For example, a 75.03% reduction in area was achieved with a 0.33% decrease in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was achieved with a 2.38% decrease in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have recently seen a surge in interest because of their ability to improve deep learning tasks through quick processing, large data management, and lower energy consumption. However, existing ONNs only adjust and recognize input light amplitudes, neglecting the computational capability of light phases. This paper introduces a new framework, Oplixnet, that enhances ONNs by converting input image data into both light amplitude and phase components. This change affects both the input and output of ONNs to handle amplitude and phase information. Furthermore, a mutual learning strategy is used among various ONN structures to maintain accuracy. The experimental results indicate that this framework significantly decreases the size of ONNs while maintaining acceptable accuracy levels. For instance, a 75.03% reduction in area was accomplished with a 0.33% drop in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was achieved with a 2.38% decrease in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been gaining significant attention due to their potential to optimize deep learning tasks with fast processing, large data handling, and reduced energy use. Current ONNs only adjust and recognize input light intensity, overlooking the computational power of light phases. This paper presents a novel framework, Oplixnet, which enhances ONNs by transforming image data into both light amplitude and phase components. This modification impacts both the input and output of ONNs to manage amplitude and phase information. Additionally, a mutual learning strategy is implemented among various ONN structures to maintain precision. Experimental results show that this framework substantially decreases the size of ONNs while preserving acceptable accuracy levels. For example, a 75.03% reduction in area was achieved with a 0.33% decline in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was realized with a 2.38% decrease in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been rapidly gaining interest due to their ability to optimize deep learning tasks through quick processing, large data management, and lower energy consumption. However, current ONNs only adjust and recognize the intensity of input light, neglecting the computational capabilities of light phases. This paper introduces a new framework, Oplixnet, which improves ONNs by converting image data into both light amplitude and phase components. This change affects both the input and output of ONNs to handle amplitude and phase information. Furthermore, a mutual learning strategy is utilized among various ONN structures to ensure precision. The experimental results indicate that this framework significantly reduces the size of ONNs while maintaining acceptable accuracy levels. For instance, a 75.03% reduction in area was achieved with a 0.33% drop in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was realized with a 2.38% decrease in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been increasingly attracting attention because of their capacity to optimize deep learning tasks through fast processing, large data handling, and reduced energy usage. Nevertheless, existing ONNs only adjust and identify the intensity of input light, overlooking the computational potential of light phases. This paper presents a novel framework, Oplixnet, which enhances ONNs by transforming image data into both light amplitude and phase components. This modification affects both the input and output of ONNs to manage amplitude and phase information. Moreover, a mutual learning approach is employed among different ONN structures to guarantee precision. The experimental results demonstrate that this framework significantly decreases the size of ONNs while maintaining acceptable accuracy levels. For example, a 75.03% reduction in area was accomplished with a 0.33% decrease in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was achieved with a 2.38% drop in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been gaining significant interest due to their ability to optimize deep learning tasks through quick processing, large data management, and lower energy consumption. However, current ONNs only adjust and recognize the intensity of input light, neglecting the computational power of light phases. This paper introduces a new framework, Oplixnet, which improves ONNs by converting image data into both light amplitude and phase components. This change affects both the input and output of ONNs to handle amplitude and phase data. Additionally, a mutual learning method is utilized among various ONN structures to ensure precision. The experimental results show that this framework substantially reduces the size of ONNs while maintaining acceptable accuracy levels. For instance, a 75.03% reduction in area was achieved with a 0.33% decrease in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was realized with a 2.38% drop in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been attracting considerable attention because of their potential to enhance deep learning tasks through fast processing, large data handling, and reduced energy usage. Nevertheless, existing ONNs only modify and identify the intensity of input light, overlooking the computational capability of light phases. This paper presents a novel framework, Oplixnet, which enhances ONNs by transforming image data into both light amplitude and phase components. This adjustment impacts both the input and output of ONNs, enabling them to manage amplitude and phase data. Furthermore, a mutual learning approach is employed among different ONN structures to ensure precision. The experimental results indicate that this framework significantly decreases the size of ONNs while maintaining acceptable accuracy levels. For example, a 75.03% reduction in area was accomplished with a 0.33% decrease in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was achieved with a 2.38% decline in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been gaining significant interest due to their ability to improve deep learning tasks with fast processing, large data management, and reduced energy consumption. However, current ONNs only modify and recognize the intensity of input light, neglecting the computational power of light phases. A new framework, called Oplixnet, is introduced in this paper to augment ONNs by converting image data into both light amplitude and phase components. This modification affects both the input and output of ONNs, allowing them to process amplitude and phase data. Additionally, a mutual learning strategy is used among various ONN structures to ensure precision. The experimental results demonstrate that this framework significantly reduces the size of ONNs while maintaining acceptable accuracy levels. For instance, a 75.03% reduction in area was achieved with a 0.33% drop in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was realized with a 2.38% decrease in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been attracting considerable attention because of their potential to enhance deep learning activities through quick processing, large data handling, and lower energy usage. Nevertheless, existing ONNs only adjust and identify the intensity of incoming light, overlooking the computational capabilities of light phases. In this paper, a new structure named Oplixnet is presented which aims to supplement ONNs by transforming image data into both light amplitude and phase components. This alteration impacts both the input and output of ONNs, empowering them to handle amplitude and phase data. Furthermore, a collaborative learning strategy is implemented among various ONN designs to guarantee precision. The experimental findings indicate that this structure substantially decreases the size of ONNs while preserving acceptable accuracy levels. For example, a reduction of 75.03% in area was accomplished with a slight decrease of 0.33% in accuracy for a Fully Connected Neural Network (FCNN), and a reduction of 74.88% in area was seen with a 2.38% drop in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been gaining significant interest due to their ability to improve deep learning tasks by providing fast processing, managing large data, and reducing energy consumption. However, current ONNs only adjust and recognize the intensity of incoming light, neglecting the computational power of light phases. This paper introduces a new design, called Oplixnet, that aims to enhance ONNs by converting image data into both light amplitude and phase components. This modification affects both the input and output of ONNs, allowing them to process amplitude and phase data. Additionally, a collaborative learning approach is used among various ONN models to ensure precision. The experimental results show that this structure significantly reduces the size of ONNs while maintaining acceptable accuracy levels. For instance, a 75.03% reduction in area was achieved with a 0.33% decrease in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was observed with a 2.38% drop in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been attracting considerable attention recently, as they enhance deep learning tasks through fast processing, large data handling, and reduced energy consumption. Nevertheless, existing ONNs only adjust and recognize the intensity of incoming light, disregarding the computational potential of light phases. This paper presents a novel design, named Oplixnet, which aims to augment ONNs by transforming image data into both light amplitude and phase components. This change affects both the input and output of ONNs, enabling them to handle amplitude and phase data. Furthermore, the paper implements a collaborative learning strategy among multiple ONN models to ensure precision. The experimental findings indicate that this design considerably decreases the size of ONNs while preserving acceptable accuracy levels. For example, a 75.03% reduction in area was achieved with a 0.33% decline in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was noted with a 2.38% drop in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been gaining significant interest recently due to their ability to improve deep learning tasks by offering fast processing, large data handling, and reduced energy consumption. However, current ONNs only adjust and identify the intensity of incoming light, neglecting the computational capability of light phases. This paper introduces a new design, called Oplixnet, which seeks to enhance ONNs by converting image data into both light amplitude and phase components. This modification impacts both the input and output of ONNs, allowing them to process amplitude and phase data. The paper also employs a collaborative learning approach among multiple ONN models to ensure accuracy. The experimental results demonstrate that this design substantially reduces the size of ONNs while maintaining acceptable accuracy levels. For instance, a 75.03% reduction in area was achieved with a 0.33% decrease in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was observed with a 2.38% drop in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been attracting considerable attention lately because of their potential to enhance deep learning tasks through quick processing, large data management, and lowered energy usage. Yet, existing ONNs only adjust and recognize the intensity of incoming light, overlooking the computational power of light phases. A fresh design, named Oplixnet, is presented in this paper, which aims to augment ONNs by transforming image data into both light amplitude and phase components. This change affects both the input and output of ONNs, enabling them to handle amplitude and phase data. The paper also utilizes a collaborative learning strategy among multiple ONN models to guarantee accuracy. The experimental results indicate that this design significantly decreases the size of ONNs while preserving acceptable accuracy levels. For example, a reduction of 75.03% in area was achieved with a 0.33% decline in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was noted with a 2.38% decrease in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been gaining significant interest recently due to their ability to improve deep learning tasks with fast processing, large data handling, and reduced energy consumption. However, current ONNs only adjust and recognize the intensity of incoming light, neglecting the computational capabilities of light phases. This paper introduces a novel design called Oplixnet, which aims to enhance ONNs by converting image data into both light amplitude and phase components. This modification affects both the input and output of ONNs, allowing them to process amplitude and phase data. The paper also employs a collaborative learning approach among multiple ONN models to ensure accuracy. The experimental results show that this design substantially decreases the size of ONNs while maintaining acceptable accuracy levels. For instance, a reduction of 75.03% in area was achieved with a 0.33% drop in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was observed with a 2.38% decrease in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been attracting considerable attention lately because of their potential to enhance deep learning tasks through quick processing, large data management, and lowered energy usage. Nevertheless, current ONNs only adjust and identify the intensity of incoming light, overlooking the computational power of light phases. A new design is presented in this paper, named Oplixnet, which aims to augment ONNs by transforming image data into both light amplitude and phase components. This change affects both the input and output of ONNs, enabling them to process amplitude and phase data. The paper also implements a collaborative learning strategy among multiple ONN models to ensure precision. The experimental results indicate that this design significantly decreases the size of ONNs while maintaining acceptable accuracy levels. For example, a reduction of 75.03% in area was achieved with a 0.33% decrease in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was observed with a 2.38% drop in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been gaining significant interest recently due to their ability to improve deep learning tasks by offering fast processing, large data handling, and reduced energy consumption. However, current ONNs only adjust and identify the intensity of incoming light, neglecting the computational capability of light phases. In this paper, a new design called Oplixnet is introduced, which aims to enhance ONNs by converting image data into both light amplitude and phase components. This modification impacts both the input and output of ONNs, allowing them to process amplitude and phase data. The paper also introduces a collaborative learning approach among multiple ONN models to ensure precision. The experimental results demonstrate that this design substantially decreases the size of ONNs while maintaining acceptable accuracy levels. For instance, a 75.03% reduction in area was achieved with a 0.33% decrease in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was observed with a 2.38% drop in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been rapidly gaining attention recently because of their potential to enhance deep learning tasks through quick processing, large data handling, and lower energy usage. Yet, current ONNs only adjust and recognize the intensity of incoming light, overlooking the computational power of light phases. This paper presents a new design named Oplixnet, which aims to augment ONNs by transforming image data into both light amplitude and phase components. This change affects both the input and output of ONNs, enabling them to process amplitude and phase data. Additionally, the paper proposes a collaborative learning strategy among multiple ONN models to ensure precision. The experimental results indicate that this design significantly reduces the size of ONNs while maintaining reasonable accuracy levels. For example, a 75.03% reduction in area was achieved with a 0.33% decrease in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was observed with a 2.38% drop in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been rapidly growing in popularity lately due to their ability to improve deep learning tasks with fast processing, large data handling, and reduced energy consumption. However, current ONNs only adjust and identify the intensity of incoming light, neglecting the computational capabilities of light phases. This paper introduces a new design called \"Oplixnet,\" which aims to enhance ONNs by converting image data into both light amplitude and phase components. This modification affects both the input and output of ONNs, allowing them to process amplitude and phase data. Furthermore, the paper proposes a collaborative learning approach among multiple ONN models for precision. The experimental results suggest that this design significantly decreases the size of ONNs while maintaining acceptable accuracy levels. For instance, there was a 75.03% reduction in area with a 0.33% decrease in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was seen with a 2.38% drop in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been gaining considerable attention recently, thanks to their capacity to enhance deep learning tasks with quick processing, large data management, and lower energy usage. Yet, existing ONNs primarily adjust and recognize the intensity of incoming light, overlooking the computational potential of light phases. A fresh design, titled \"Oplixnet,\" is presented in this paper, with the objective of elevating ONNs by transforming image data into both light amplitude and phase components. This alteration impacts both the input and output of ONNs, enabling them to handle amplitude and phase data. The paper also suggests a collaborative learning strategy among multiple ONN models to increase precision. The experimental findings indicate that this design substantially reduces the size of ONNs while preserving acceptable accuracy levels. Specifically, a 75.03% decrease in area was observed with a 0.33% decrease in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was seen with a 2.38% drop in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been receiving significant interest lately due to their ability to improve deep learning tasks with fast processing, large data handling, and reduced energy consumption. However, current ONNs mainly focus on adjusting and recognizing the intensity of incoming light, neglecting the computational power of light phases. In this paper, a new design called \"Oplixnet\" is introduced, which aims to enhance ONNs by converting image data into both light amplitude and phase components. This modification affects both the input and output of ONNs, allowing them to process amplitude and phase data. The paper also proposes a collaborative learning approach between multiple ONN models to increase precision. The experimental results show that this design significantly reduces the size of ONNs while maintaining acceptable accuracy levels. For instance, a 75.03% decrease in area was observed with a 0.33% decrease in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was seen with a 2.38% drop in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been gaining considerable attention recently, owing to their potential to enhance deep learning tasks through rapid processing, large data management, and lowered energy usage. Nevertheless, current ONNs primarily concentrate on adjusting and identifying the intensity of incoming light, often overlooking the computational capabilities of light phases. This paper introduces a novel design, \"Oplixnet\", which aims to augment ONNs by transforming image data into both light amplitude and phase components. This change affects both the input and output of ONNs, enabling them to handle amplitude and phase data. Furthermore, the paper suggests a collaborative learning strategy between multiple ONN models to increase accuracy. Experimental results indicate that this design substantially decreases the size of ONNs while preserving acceptable accuracy levels. Specifically, a 75.03% decrease in area was measured with a 0.33% decrease in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was noted with a 2.38% drop in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been receiving significant interest lately due to their ability to improve deep learning tasks by providing fast processing, large data handling, and reduced energy consumption. However, current ONNs mainly focus on adjusting and recognizing the intensity of incoming light, often neglecting the computational power of light phases. This paper presents a new design, \"Oplixnet\", which aims to enhance ONNs by converting image data into both light amplitude and phase components. This modification affects both the input and output of ONNs, allowing them to process amplitude and phase data. The paper also proposes a collaborative learning approach between multiple ONN models to increase accuracy. Experimental results suggest that this design significantly reduces the size of ONNs while maintaining acceptable accuracy levels. Specifically, a 75.03% reduction in area was measured with a 0.33% decrease in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% decrease in area was noted with a 2.38% decrease in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been gaining considerable attention recently, as they optimize deep learning tasks through swift processing, large data handling, and diminished energy usage. Nevertheless, the current ONNs primarily concentrate on adjusting and identifying the intensity of incoming light, commonly overlooking the computational potential of light phases. This paper introduces an innovative design, \"Oplixnet\", which strives to augment ONNs by transforming image data into both light amplitude and phase components. This alteration influences both the input and output of ONNs, empowering them to handle amplitude and phase data. The paper also puts forth a collaborative learning strategy between multiple ONN models to boost accuracy. Experimental findings indicate that this design substantially decreases the size of ONNs while preserving acceptable accuracy levels. To be specific, a 75.03% reduction in area was recorded with a 0.33% drop in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was observed with a 2.38% decrease in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been receiving significant interest lately due to their ability to optimize deep learning tasks through fast processing, large data management, and reduced energy consumption. However, current ONNs mainly focus on adjusting and identifying the intensity of incoming light, often neglecting the computational capability of light phases. This paper presents a new design, \"Oplixnet\", which aims to enhance ONNs by converting image data into both light amplitude and phase components. This modification affects both the input and output of ONNs, enabling them to process amplitude and phase data. The paper also proposes a collaborative learning approach between multiple ONN models to increase accuracy. Experimental results show that this design significantly reduces the size of ONNs while maintaining acceptable accuracy levels. Specifically, a 75.03% reduction in area was recorded with a 0.33% decrease in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was observed with a 2.38% drop in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been gaining considerable attention recently because of their capacity to improve deep learning processes through quick handling of large data, increased speed, and lowered energy usage. Nevertheless, current ONNs primarily concentrate on adjusting and recognizing the intensity of incoming light, frequently overlooking the computational potential of light phases. This paper introduces a new design, \"Oplixnet\", which strives to strengthen ONNs by transforming image data into both light amplitude and phase components. This change affects both the input and output of ONNs, allowing them to handle amplitude and phase data. The paper also suggests a collaborative learning strategy between multiple ONN models to enhance accuracy. The experimental results indicate that this design substantially decreases the size of ONNs while preserving acceptable accuracy levels. To be specific, a 75.03% reduction in area was reported with a 0.33% decline in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was noted with a 2.38% decrease in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been receiving significant interest lately due to their ability to optimize deep learning processes by rapidly processing large data sets, increasing speed, and reducing energy consumption. However, current ONNs mainly focus on adjusting and identifying the intensity of incoming light, often neglecting the computational power of light phases. This paper presents a novel design, \"Oplixnet\", which aims to enhance ONNs by converting image data into both light amplitude and phase components. This modification affects both the input and output of ONNs, enabling them to process amplitude and phase data. The paper also proposes a collaborative learning approach between multiple ONN models to increase accuracy. The experimental results show that this design significantly reduces the size of ONNs while maintaining acceptable accuracy levels. Specifically, a 75.03% reduction in area was reported with a 0.33% drop in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was noted with a 2.38% decrease in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been gaining considerable attention recently, as they can optimize deep learning procedures by quickly handling sizable data sets, thereby increasing speed and reducing energy use. Nevertheless, most existing ONNs primarily concentrate on adjusting and recognizing incoming light's intensity, often overlooking the computational potential of light phases. This paper introduces a new design, \"Oplixnet\", which seeks to improve ONNs by transforming image data into both light amplitude and phase components. This adjustment influences both the input and output of ONNs, allowing them to process amplitude and phase data. The paper also suggests a collaborative learning strategy between multiple ONN models to enhance accuracy. The experimental findings indicate that this design significantly decreases the size of ONNs while preserving acceptable accuracy levels. To be specific, a 75.03% reduction in area was achieved with a 0.33% decline in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was observed with a 2.38% decrease in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been attracting significant interest lately, as they can optimize deep learning processes by rapidly processing large datasets, thereby increasing speed and reducing energy consumption. However, many existing ONNs mainly focus on adjusting and recognizing the intensity of incoming light, often neglecting the computational capabilities of light phases. This paper presents a new design, \"Oplixnet\", which aims to enhance ONNs by converting image data into both amplitude and phase components of light. This modification affects both the input and output of ONNs, enabling them to process amplitude and phase data. The paper also proposes a collaborative learning approach between multiple ONN models to increase accuracy. The experimental results show that this design significantly reduces the size of ONNs while maintaining acceptable accuracy levels. For instance, a 75.03% reduction in area was achieved with a 0.33% drop in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was observed with a 2.38% decrease in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been gaining considerable attention recently, due to their ability to optimize deep learning processes by quickly handling large datasets, resulting in increased speed and lower energy consumption. Nevertheless, many current ONNs primarily concentrate on modifying and identifying the intensity of incoming light, frequently overlooking the computational potential of light phases. This paper introduces a novel design, \"Oplixnet\", which seeks to improve ONNs by transforming image data into both amplitude and phase components of light. This change impacts both the input and output of ONNs, allowing them to handle amplitude and phase data. The paper also suggests a collaborative learning strategy between multiple ONN models to enhance accuracy. The experimental results indicate that this design substantially decreases the size of ONNs while preserving acceptable accuracy levels. For example, a 75.03% reduction in area was accomplished with a 0.33% decline in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was noted with a 2.38% drop in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been attracting significant interest lately because of their capacity to optimize deep learning processes through fast handling of large datasets, leading to enhanced speed and reduced energy consumption. However, many existing ONNs mainly focus on modifying and recognizing the intensity of incoming light, often neglecting the computational possibilities of light phases. This paper presents a new design, \"Oplixnet\", which aims to enhance ONNs by converting image data into both amplitude and phase components of light. This modification affects both the input and output of ONNs, enabling them to process amplitude and phase data. The paper also proposes a collaborative learning approach between multiple ONN models to increase accuracy. The experimental results show that this design significantly reduces the size of ONNs while maintaining acceptable accuracy levels. For instance, a reduction of 75.03% in area was achieved with a 0.33% decrease in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was observed with a 2.38% drop in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been gaining considerable attention recently due to their ability to optimize deep learning processes by quickly handling large datasets, resulting in increased speed and lower energy usage. Yet, many current ONNs primarily concentrate on modifying and recognizing the intensity of incoming light, often overlooking the computational potential of light phases. This paper introduces a new design, \"Oplixnet\", which seeks to improve ONNs by transforming image data into both amplitude and phase components of light. This change affects both the input and output of ONNs, allowing them to process amplitude and phase data. The paper also suggests a collaborative learning strategy between multiple ONN models to increase accuracy. The experimental results indicate that this design significantly decreases the size of ONNs while maintaining reasonable accuracy levels. For example, a 75.03% reduction in area was accomplished with a 0.33% decrease in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was seen with a 2.38% drop in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been receiving significant interest lately because of their capacity to optimize deep learning tasks through fast processing of large datasets, leading to enhanced speed and reduced energy consumption. However, many existing ONNs mainly focus on modifying and identifying the intensity of incoming light, frequently neglecting the computational possibilities of light phases. This paper presents a novel design, \"Oplixnet\", which aims to enhance ONNs by converting image data into both amplitude and phase components of light. This modification impacts both the input and output of ONNs, enabling them to handle amplitude and phase data. The paper also proposes a collaborative learning approach between multiple ONN models to increase accuracy. The experimental results suggest that this design substantially reduces the size of ONNs while preserving acceptable accuracy levels. For instance, a 75.03% reduction in area was achieved with a 0.33% decrease in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was observed with a 2.38% decline in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been gaining considerable attention recently due to their ability to optimize deep learning tasks through the rapid processing of extensive datasets, resulting in increased speed and lower energy usage. Yet, many current ONNs primarily concentrate on altering and detecting the intensity of incoming light, often overlooking the computational potential of light phases. This paper introduces a new design, \"Oplixnet\", which intends to improve ONNs by transforming image data into both amplitude and phase components of light. This change affects both the input and output of ONNs, allowing them to manage amplitude and phase data. The paper also suggests a collaborative learning strategy between multiple ONN models to increase accuracy. The experimental findings indicate that this design significantly decreases the size of ONNs while maintaining acceptable accuracy levels. For example, a 75.03% reduction in area was accomplished with a 0.33% drop in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was noted with a 2.38% decrease in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been receiving significant interest lately because of their capacity to optimize deep learning tasks through the fast processing of large datasets, leading to enhanced speed and reduced energy consumption. However, many existing ONNs mainly focus on modifying and detecting the intensity of incoming light, frequently neglecting the computational possibilities of light phases. This paper presents a new design, \"Oplixnet\", which aims to enhance ONNs by converting image data into both amplitude and phase components of light. This modification affects both the input and output of ONNs, enabling them to handle amplitude and phase data. The paper also proposes a collaborative learning approach between multiple ONN models to increase accuracy. The experimental results show that this design considerably decreases the size of ONNs while maintaining acceptable accuracy levels. For instance, a reduction of 75.03% in area was achieved with a 0.33% drop in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was observed with a 2.38% decrease in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been gaining considerable attention recently due to their ability to optimize deep learning tasks through the rapid processing of extensive datasets, resulting in increased speed and lower energy usage. Nevertheless, numerous current ONNs primarily concentrate on altering and detecting the intensity of incoming light, often overlooking the computational potential of light phases. This paper introduces a novel design, \"Oplixnet\", which intends to improve ONNs by transforming image data into both amplitude and phase components of light. This change affects both the input and output of ONNs, allowing them to manage amplitude and phase data. The paper also suggests a collaborative learning strategy between multiple ONN models to increase accuracy. The experimental results indicate that this design substantially reduces the size of ONNs while preserving acceptable accuracy levels. For example, a 75.03% decrease in area was achieved with a 0.33% decrease in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was noted with a 2.38% reduction in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been receiving significant interest lately because of their capacity to optimize deep learning tasks through the fast processing of large datasets, leading to enhanced speed and reduced energy consumption. However, many current ONNs focus mainly on modifying and detecting the intensity of incoming light, frequently neglecting the computational capabilities of light phases. This paper presents a new design, \"Oplixnet\", which aims to enhance ONNs by converting image data into both amplitude and phase components of light. This modification affects both the input and output of ONNs, enabling them to handle amplitude and phase data. The paper also proposes a collaborative learning approach between multiple ONN models to increase accuracy. The experimental results show that this design significantly decreases the size of ONNs while maintaining acceptable accuracy levels. For instance, a 75.03% reduction in area was achieved with a 0.33% decrease in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was observed with a 2.38% reduction in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been gaining considerable attention recently due to their ability to optimize deep learning tasks through the rapid processing of extensive datasets, resulting in improved speed and lower energy consumption. Nevertheless, many existing ONNs primarily focus on modifying and detecting the intensity of incoming light, often overlooking the computational potential of light phases. This paper introduces a novel design, \"Oplixnet\", which seeks to augment ONNs by transforming image data into both amplitude and phase components of light. This alteration affects both the input and output of ONNs, allowing them to manage amplitude and phase data. The paper also suggests a collaborative learning strategy between multiple ONN models to increase accuracy. The experimental findings indicate that this design considerably reduces the size of ONNs while preserving acceptable accuracy levels. For example, a 75.03% reduction in area was achieved with a 0.33% decrease in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was noted with a 2.38% reduction in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been receiving significant interest lately because of their capacity to optimize deep learning tasks through the swift processing of large data sets, thereby increasing speed and reducing energy use. However, many current ONNs mainly concentrate on modifying and detecting the intensity of incoming light, commonly neglecting the computational power of light phases. This paper presents a new design, \"Oplixnet\", which aims to enhance ONNs by converting image data into both amplitude and phase components of light. This modification affects both the input and output of ONNs, enabling them to handle amplitude and phase data. The paper also proposes a collaborative learning approach between multiple ONN models to increase accuracy. The experimental results show that this design significantly decreases the size of ONNs while maintaining acceptable accuracy levels. For instance, a 75.03% reduction in area was accomplished with a 0.33% decrease in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was observed with a 2.38% reduction in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been gaining considerable attention recently due to their ability to optimize deep learning tasks through the rapid processing of extensive data sets, consequently boosting speed and lowering energy consumption. Nevertheless, numerous existing ONNs primarily focus on altering and sensing the intensity of incoming light, often overlooking the computational potential of light phases. This paper introduces a novel design, \"Oplixnet\", which strives to improve ONNs by transforming image data into both amplitude and phase components of light. This adjustment influences both the input and output of ONNs, allowing them to manage amplitude and phase data. The paper also suggests a collaborative learning strategy between multiple ONN models to enhance accuracy. The experimental findings indicate that this design substantially reduces the size of ONNs while preserving acceptable accuracy levels. Specifically, a 75.03% reduction in area was achieved with a 0.33% decrease in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was noted with a 2.38% reduction in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been receiving significant interest recently, as they can optimize deep learning tasks by rapidly processing large data sets, thereby increasing speed and reducing energy use. However, many current ONNs mainly focus on changing and detecting the intensity of incoming light, often neglecting the computational possibilities of light phases. This paper presents a new design, \"Oplixnet\", which aims to enhance ONNs by converting image data into both amplitude and phase components of light. This modification affects both the input and output of ONNs, enabling them to handle amplitude and phase data. The paper also proposes a collaborative learning approach between multiple ONN models to increase accuracy. The experimental results show that this design significantly decreases the size of ONNs while maintaining acceptable accuracy levels. For instance, a 75.03% reduction in area was achieved with a 0.33% decrease in accuracy for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was observed with a 2.38% reduction in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been gaining considerable attention lately due to their ability to optimize deep learning tasks through the rapid processing of extensive data sets, thus improving speed and reducing energy consumption. Yet, many existing ONNs tend to focus primarily on altering and detecting the intensity of incoming light, often overlooking the computational potential of light phases. This paper introduces a novel design, \"Oplixnet\", which seeks to augment ONNs by transforming image data into both amplitude and phase components of light. This change affects both the input and output of ONNs, allowing them to process amplitude and phase data. The paper also suggests a collaborative learning strategy between multiple ONN models to enhance accuracy. The experimental findings indicate that this design substantially decreases the size of ONNs while maintaining acceptable accuracy levels. For example, a reduction of 75.03% in area was achieved with a slight accuracy decrease of 0.33% for a Fully Connected Neural Network (FCNN), and a reduction of 74.88% in area was observed with a 2.38% reduction in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been receiving significant interest recently, as they can optimize deep learning tasks by quickly processing large data sets, thereby increasing speed and reducing energy use. However, many current ONNs mainly focus on changing and detecting the intensity of incoming light, often neglecting the computational power of light phases. This paper presents a new design, \"Oplixnet\", which aims to enhance ONNs by converting image data into both amplitude and phase components of light. This modification affects both the input and output of ONNs, enabling them to process amplitude and phase data. The paper also proposes a collaborative learning approach between multiple ONN models to increase accuracy. The experimental results show that this design significantly reduces the size of ONNs while maintaining acceptable accuracy levels. For instance, a 75.03% reduction in area was achieved with a slight accuracy decrease of 0.33% for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was observed with a 2.38% reduction in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been gaining considerable attention lately due to their ability to optimize deep learning tasks by rapidly handling large data sets, thus improving speed and reducing energy consumption. Nevertheless, most existing ONNs primarily concentrate on modifying and sensing the intensity of incoming light, frequently overlooking the computational capabilities of light phases. This paper introduces a novel design, \"Oplixnet\", which intends to augment ONNs by transforming image data into both amplitude and phase components of light. This alteration influences both the input and output of ONNs, allowing them to handle amplitude and phase data. The paper also suggests a collaborative learning strategy between multiple ONN models to enhance accuracy. The experimental results indicate that this design considerably decreases the size of ONNs while preserving acceptable accuracy levels. For example, a 75.03% decrease in area was achieved with a minor accuracy drop of 0.33% for a Fully Connected Neural Network (FCNN), and a 74.88% reduction in area was noted with a 2.38% reduction in accuracy for Resnet-32."
        ],
        [
            "Optical Neural Networks (ONNs) have been recently attracting significant interest because of their capacity to optimize deep learning tasks by quickly processing large amounts of data, thereby increasing speed and decreasing energy usage. However, many existing ONNs mainly focus on modifying and detecting the intensity of incoming light, often neglecting the computational potential of light phases. This paper proposes a new design, \"Oplixnet\", which aims to enhance ONNs by converting image data into both amplitude and phase components of light. This modification affects both the input and output of ONNs, enabling them to process amplitude and phase data. The paper also suggests a joint learning strategy between multiple ONN models to increase accuracy. The experimental results show that this design substantially reduces the size of ONNs while maintaining acceptable accuracy levels. For instance, a 75.03% reduction in area was achieved with a minor accuracy decrease of 0.33% for a Fully Connected Neural Network (FCNN), and a 74.88% decrease in area was observed with a 2.38% reduction in accuracy for Resnet-32."
        ]
    ]
}