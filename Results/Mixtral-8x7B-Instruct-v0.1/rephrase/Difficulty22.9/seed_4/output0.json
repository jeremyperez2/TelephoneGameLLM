{
    "adjacency_matrix": [
        [
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0
        ]
    ],
    "prompt_init": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "prompt_update": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "personality_list": [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        ""
    ],
    "format_prompt": [
        ""
    ],
    "initial_story": "musculoskeletal diseases and cognitive impairments in patients lead todifficulties in movement as well as negative effects on their psychologicalhealth. clinical gait analysis, a vital tool for early diagnosis and treatment,traditionally relies on expensive optical motion capture systems. recentadvances in computer vision and deep learning have opened the door to moreaccessible and cost-effective alternatives. this paper introduces a novelspatio-temporal transformer network to estimate critical gait parameters fromrgb videos captured by a single-view camera. empirical evaluations on a publicdataset of cerebral palsy patients indicate that the proposed frameworksurpasses current state-of-the-art approaches and show significant improvementsin predicting general gait parameters (including walking speed, gait deviationindex - gdi, and knee flexion angle at maximum extension), while utilizingfewer parameters and alleviating the need for manual feature extraction. ",
    "stories": [
        [
            "The presence of musculoskeletal diseases and cognitive impairments in individuals can result in mobility issues and have adverse effects on their psychological well-being. Clinical gait analysis, which is crucial for early detection and treatment, typically uses costly optical motion capture systems. However, recent developments in computer vision and deep learning now make more affordable and accessible alternatives possible. This paper presents a new spatio-temporal transformer network that can estimate essential gait parameters from RGB videos taken with a single-view camera. Evaluation of this framework on a public dataset of cerebral palsy patients shows that it outperforms existing state-of-the-art methods, resulting in significant improvements in predicting general gait parameters (such as walking speed, gait deviation index, and knee flexion angle at maximum extension) while using fewer parameters and reducing the need for manual feature extraction."
        ],
        [
            "Having musculoskeletal diseases and cognitive impairments in people can lead to mobility problems and negatively impact their psychological health. Clinical gait analysis, which is essential for early detection and treatment, often utilizes expensive optical motion capture systems. But thanks to advancements in computer vision and deep learning, affordable and accessible alternatives are now feasible. This paper introduces a new spatio-temporal transformer network that can derive crucial gait parameters from RGB videos captured with a single-view camera. Testing this model on a public dataset of cerebral palsy patients indicates that it surpasses existing state-of-the-art methods, leading to substantial enhancements in predicting general gait parameters, like walking speed, gait deviation index, and knee flexion angle at maximum extension, while using fewer parameters and minimizing the requirement for manual feature extraction."
        ],
        [
            "People who have musculoskeletal conditions and cognitive declines can experience issues with mobility and have their psychological well-being affected. Clinical gait analysis is crucial for early detection and treatment of these issues, typically using costly optical motion capture systems. However, with advancements in computer vision and deep learning, affordable and accessible alternatives are now possible. This paper presents a novel spatio-temporal transformer network that can extract vital gait parameters from RGB videos taken with a single-view camera. The model was tested on a public dataset of cerebral palsy patients, and results suggest that it outperforms existing state-of-the-art methods. This leads to significant improvements in predicting general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at maximum extension, while using fewer parameters and reducing the need for manual feature extraction."
        ],
        [
            "Individuals with both musculoskeletal disorders and cognitive impairments may face challenges in mobility and see impacts on their psychological health. It is essential to detect and treat these issues early, and this often involves the use of clinical gait analysis, which has traditionally relied on expensive optical motion capture systems. However, recent advancements in computer vision and deep learning now allow for more affordable and accessible alternatives. This paper introduces a new spatio-temporal transformer network that can derive crucial gait parameters from RGB videos captured with a single-view camera. The model was evaluated using a public dataset of cerebral palsy patients and showed improved performance compared to existing state-of-the-art methods. This results in significant advancements in predicting general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at maximum extension, while using fewer parameters and reducing the need for manual feature extraction."
        ],
        [
            "People who have both musculoskeletal conditions and cognitive impairments may encounter difficulties in mobility and experience effects on their psychological well-being. Early detection and treatment of these problems are crucial, and this typically involves the use of clinical gait analysis, which has traditionally depended on costly optical motion capture systems. Nevertheless, progress in computer vision and deep learning now enable more budget-friendly and accessible alternatives. This paper presents a new spatio-temporal transformer network that can extract important gait parameters from RGB videos obtained with a single-view camera. The model was assessed using a public dataset of cerebral palsy patients and demonstrated better performance than existing top-tier methods. This leads to significant breakthroughs in predicting general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at maximum extension, while using fewer parameters and minimizing the requirement for manual feature extraction."
        ],
        [
            "Individuals who suffer from both musculoskeletal disorders and cognitive impairments can face challenges in mobility and see impacts on their psychological health. Recognizing and addressing these issues early, often through clinical gait analysis, is vital. Traditionally, this has relied on expensive optical motion capture systems. However, advancements in computer vision and deep learning now offer more affordable and accessible options. This paper introduces a new spatio-temporal transformer network that can pull out key gait parameters from RGB videos captured with a single-view camera. The model was tested on a public dataset of cerebral palsy patients and outperformed existing leading methods. This technology could significantly improve predictions of general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at peak extension, while using fewer parameters and lessening the need for manual feature extraction."
        ],
        [
            "People who have both musculoskeletal conditions and cognitive declines can encounter difficulties in movement and experience effects on their psychological well-being. It is crucial to identify and address these problems early, frequently by using clinical gait analysis. In the past, this has mainly depended on costly optical motion capture systems. Nevertheless, progress in computer vision and deep learning now present more budget-friendly and accessible solutions. This paper presents a new spatio-temporal transformer network that can extract essential gait parameters from RGB videos taken with a single-view camera. The model was evaluated on a public dataset of cerebral palsy patients, and it surpassed existing top methods. This technology could greatly enhance predictions of general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at maximum extension, while utilizing fewer parameters and reducing the need for manual feature extraction."
        ],
        [
            "Individuals who suffer from both musculoskeletal disorders and cognitive decline can face challenges in mobility and see impacts on their psychological health. It is vital to identify and manage these issues early, often through the use of clinical gait analysis. Historically, this has relied heavily on expensive optical motion capture systems. However, advances in computer vision and deep learning now provide more affordable and accessible alternatives. This paper introduces a new spatio-temporal transformer network capable of extracting key gait parameters from RGB videos captured with a single-view camera. The model was tested on a public dataset of cerebral palsy patients, and it outperformed existing leading methods. This technology has the potential to significantly improve predictions of general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at maximum extension, while using fewer parameters and reducing the need for manual feature extraction."
        ],
        [
            "People who experience musculoskeletal disorders and cognitive decline may encounter mobility issues and suffer psychological effects. Early identification and management of these problems are crucial, often involving clinical gait analysis. Traditionally, this has depended largely on costly optical motion capture systems. But recent progress in computer vision and deep learning now offers more economical and accessible options. This paper presents a novel spatio-temporal transformer network that can derive essential gait parameters from RGB videos taken with a single-view camera. The model was evaluated on a public dataset of cerebral palsy patients, and it surpassed existing top-performing methods. This technology could enhance the prediction accuracy of general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at peak extension, while requiring fewer parameters and less manual feature extraction."
        ],
        [
            "Individuals who have musculoskeletal disorders and cognitive impairment may face challenges with mobility and experience psychological impacts. It is vital to identify and manage these issues early, frequently using clinical gait analysis. In the past, this has typically relied on expensive optical motion capture systems. However, advancements in computer vision and deep learning now provide more affordable and accessible alternatives. This paper introduces a novel spatio-temporal transformer network that can extract key gait parameters from RGB videos captured by a single-view camera. The model was tested on a public dataset of cerebral palsy patients, and it outperformed existing leading methods. This technology has the potential to improve the accuracy of predicting general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at maximum extension, while requiring fewer parameters and less manual feature extraction."
        ],
        [
            "People with both musculoskeletal disorders and cognitive impairment may encounter problems with mobility and undergo psychological effects. Early identification and management of these issues are crucial, often utilizing clinical gait analysis. Traditionally, this has depended on costly optical motion capture systems. Nevertheless, progress in computer vision and deep learning now offers more economical and accessible solutions. This paper presents a new spatio-temporal transformer network that can derive essential gait parameters from RGB videos obtained by a single-view camera. The model was evaluated on a public dataset of cerebral palsy patients, and it surpassed existing top methods. This technology could enhance the precision of estimating general gait parameters, like walking speed, gait deviation index, and knee flexion angle at maximum extension, while demanding fewer parameters and less manual feature extraction."
        ],
        [
            "Individuals who have both musculoskeletal conditions and cognitive impairment may face challenges with mobility and experience psychological impacts. It is vital to identify and address these issues early, often using clinical gait analysis. Historically, this has required expensive optical motion capture systems. However, advancements in computer vision and deep learning now provide more affordable and accessible alternatives. This paper introduces a novel spatio-temporal transformer network that can extract crucial gait parameters from RGB videos taken by a single-view camera. The model was tested on a public dataset of cerebral palsy patients, and it outperformed existing leading methods. This technology could improve the accuracy of estimating general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at maximum extension, while requiring fewer parameters and less manual feature extraction."
        ],
        [
            "People who suffer from both musculoskeletal disorders and cognitive impairments may encounter difficulties in mobility and undergo psychological effects. Early detection and handling of these problems are crucial, frequently utilizing clinical gait analysis. In the past, this has normally involved costly optical motion capture systems. Nevertheless, progress in computer vision and deep learning now offer more economical and accessible options. This paper presents a new spatio-temporal transformer network that can derive essential gait parameters from RGB videos captured by a single-view camera. The model was evaluated on a public dataset of cerebral palsy patients, and it surpassed existing top-performing methods. This innovation could enhance the precision of estimating general gait parameters, like walking speed, gait deviation index, and knee flexion angle at peak extension, while needing fewer parameters and less manual feature extraction."
        ],
        [
            "Individuals with co-occurring musculoskeletal conditions and cognitive issues may face challenges in mobility and experience psychological impacts. It is vital to identify and address these issues early, often using clinical gait analysis. Traditionally, this has required expensive optical motion capture systems. However, advances in computer vision and deep learning now provide more affordable and accessible alternatives. This paper introduces a novel spatio-temporal transformer network that can extract key gait parameters from RGB videos taken with a single-view camera. The model was tested on a public dataset of cerebral palsy patients, outperforming existing leading methods. This development could improve the accuracy of estimating general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at peak extension, while requiring fewer parameters and less manual feature extraction."
        ],
        [
            "People who have both musculoskeletal disorders and cognitive problems may encounter mobility issues and psychological effects. Early identification and addressing these problems are crucial, often using clinical gait analysis. In the past, this has typically involved costly optical motion capture systems. But now, advancements in computer vision and deep learning offer more budget-friendly and accessible options. This paper presents a new spatio-temporal transformer network that can derive essential gait parameters from RGB videos captured by a single-view camera. The model was evaluated on a public dataset of cerebral palsy patients, surpassing existing top-performing methods. This innovation may enhance the precision of estimating general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at maximum extension, while using fewer parameters and less manual feature extraction."
        ],
        [
            "Individuals who simultaneously experience musculoskeletal conditions and cognitive issues may face challenges in mobility and psychology. Recognizing and addressing these issues early, often through clinical gait analysis, is vital. Traditionally, this has required expensive optical motion capture systems. However, advancements in computer vision and deep learning now provide more affordable and accessible alternatives. This paper introduces a new spatio-temporal transformer network that can extract key gait parameters from RGB videos obtained by a single-view camera. The model was tested on a public dataset of cerebral palsy patients, outperforming existing leading methods. This development could improve the accuracy of estimating general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at maximum extension, while using fewer parameters and less manual feature extraction."
        ],
        [
            "People who have both musculoskeletal disorders and cognitive problems may encounter difficulties in mobility and psychology. It is crucial to identify and manage these issues early, frequently with the help of clinical gait analysis. In the past, this has typically involved costly optical motion capture systems. Nevertheless, progress in computer vision and deep learning now offers more economical and accessible options. This paper presents a novel spatio-temporal transformer network capable of extracting essential gait parameters from RGB videos captured by a single-view camera. The model was evaluated on a public dataset of cerebral palsy patients, surpassing current top methods. This innovation could enhance the precision of estimating general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at peak extension, while utilizing fewer parameters and less manual feature extraction."
        ],
        [
            "Individuals who suffer from both musculoskeletal conditions and cognitive issues may face challenges in terms of mobility and psychology. It is crucial to identify and address these issues promptly, often with the assistance of clinical gait analysis. Traditionally, this has required the use of expensive optical motion capture systems. However, advancements in computer vision and deep learning now provide more affordable and accessible alternatives. This paper introduces a new spatio-temporal transformer network that can extract key gait parameters from RGB videos captured by a single-view camera. The model was tested on a public dataset of cerebral palsy patients, outperforming existing methods. This development could improve the accuracy of estimating general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at maximum extension, while using fewer parameters and less manual feature extraction."
        ],
        [
            "People who have both musculoskeletal disorders and cognitive problems may encounter mobility and psychological difficulties. It is essential to identify and tackle these issues swiftly, which often involves the use of clinical gait analysis. In the past, this typically meant utilizing costly optical motion capture systems. Nevertheless, recent progress in computer vision and deep learning now offers more budget-friendly and accessible options. This paper presents a novel spatio-temporal transformer network capable of extracting crucial gait parameters from RGB videos obtained by a single-view camera. The model was evaluated on a public dataset of cerebral palsy patients, surpassing existing methods. This innovation could enhance the precision of estimating general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at maximum extension, while utilizing fewer parameters and less manual feature extraction."
        ],
        [
            "Individuals who suffer from both musculoskeletal conditions and cognitive issues can experience challenges in mobility and psychology. It is crucial to identify and address these problems promptly, which often involves using clinical gait analysis. Earlier, this typically required the use of expensive optical motion capture systems. However, advancements in computer vision and deep learning now provide more affordable and accessible alternatives. This paper introduces a new spatio-temporal transformer network that can extract vital gait parameters from RGB videos obtained by a single-view camera. The model was tested on a public dataset of cerebral palsy patients, outperforming existing methods. This development could improve the accuracy of estimating general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at peak extension, while using fewer parameters and less manual feature extraction."
        ],
        [
            "People who have musculoskeletal disorders and cognitive problems can face issues in mobility and psychology. It is important to identify and tackle these issues quickly, which frequently involves using clinical gait analysis. In the past, this typically needed the use of costly optical motion capture systems. But now, advancements in computer vision and deep learning offer more affordable and accessible options. This paper presents a new spatio-temporal transformer network that can pull out essential gait parameters from RGB videos taken by a single-view camera. The model was tried out on a public dataset of cerebral palsy patients, and it outperformed existing methods. This progress could enhance the accuracy of estimating general gait parameters, like walking speed, gait deviation index, and knee flexion angle at peak extension, while using fewer parameters and less manual feature extraction."
        ],
        [
            "Individuals who suffer from both musculoskeletal conditions and cognitive issues may experience challenges in mobility and psychology. It is crucial to promptly identify and address these issues, often involving clinical gait analysis. Traditionally, this required expensive optical motion capture systems. However, recent advancements in computer vision and deep learning now provide more cost-effective and accessible solutions. This paper introduces a novel spatio-temporal transformer network that can extract key gait parameters from RGB videos captured by a single-view camera. The model was tested on a public dataset of cerebral palsy patients, and it surpassed existing methods. This development could improve the accuracy of estimating general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at peak extension, while using fewer parameters and less manual feature extraction."
        ],
        [
            "People who have both musculoskeletal disorders and cognitive problems may face difficulties in mobility and psychological well-being. It is essential to quickly identify and manage these problems, which often involves clinical gait analysis. In the past, this typically required costly optical motion capture systems. Nevertheless, recent developments in computer vision and deep learning now offer more affordable and accessible alternatives. This paper presents a new spatio-temporal transformer network that can derive crucial gait parameters from RGB videos obtained by a single-view camera. The model was evaluated on a public dataset of cerebral palsy patients, and it outperformed existing methods. This innovation could enhance the precision of estimating general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at peak extension, while utilizing fewer parameters and less manual feature extraction."
        ],
        [
            "Individuals who suffer from both musculoskeletal conditions and cognitive issues may encounter challenges in terms of mobility and psychological health. It is vital to promptly detect and address these issues, which frequently involves conducting clinical gait analysis. In the past, this usually entailed the use of expensive optical motion capture systems. However, advancements in computer vision and deep learning now provide more economical and accessible options. This paper introduces a novel spatio-temporal transformer network that can extract key gait parameters from RGB videos captured by a single-view camera. The model was tested on a public dataset of cerebral palsy patients, and it surpassed existing methods in performance. This development could improve the accuracy of estimating general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at maximum extension, while utilizing fewer parameters and less manual feature extraction."
        ],
        [
            "People who have both musculoskeletal disorders and cognitive problems may face difficulties in terms of mobility and mental health. It is crucial to promptly identify and tackle these issues, often requiring clinical gait analysis. Earlier, this typically involved costly optical motion capture systems. Nevertheless, progress in computer vision and deep learning now offers more budget-friendly and accessible alternatives. This paper presents a new spatio-temporal transformer network that can derive crucial gait parameters from RGB videos obtained by a single-view camera. The model was evaluated on a public dataset of cerebral palsy patients, outperforming existing methods. This advancement could enhance the precision of estimating general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at peak extension, while using fewer parameters and less manual feature extraction."
        ],
        [
            "Individuals who experience both musculoskeletal conditions and cognitive issues may encounter challenges in terms of mobility and mental well-being. It is essential to promptly identify and address these problems, which often necessitates clinical gait analysis. Previously, this typically required expensive optical motion capture systems. However, advancements in computer vision and deep learning now provide more affordable and accessible options. This paper introduces a new spatio-temporal transformer network capable of extracting key gait parameters from RGB videos obtained by a single-view camera. The model was tested on a public dataset of cerebral palsy patients, outperforming existing methods. This development could improve the accuracy of estimating general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at peak extension, while using fewer parameters and less manual feature extraction."
        ],
        [
            "People who have both musculoskeletal disorders and cognitive problems may face difficulties in terms of movement and mental health. It is crucial to quickly recognize and address these issues, which frequently involves clinical gait analysis. In the past, this usually needed costly optical motion capture systems. But, progress in computer vision and deep learning now offers more affordable and accessible alternatives. This paper presents a new spatio-temporal transformer network that can extract crucial gait parameters from RGB videos taken by a single-view camera. The model was tried out on a public dataset of cerebral palsy patients, surpassing existing methods. This advancement could enhance the accuracy of estimating general gait parameters, like walking speed, gait deviation index, and knee flexion angle at peak extension, while using fewer parameters and less manual feature extraction."
        ],
        [
            "Individuals who simultaneously experience musculoskeletal conditions and cognitive issues may encounter challenges related to movement and mental health. It is essential to promptly identify and tackle these problems, often involving clinical gait analysis. Earlier, this typically required expensive optical motion capture systems. However, recent advancements in computer vision and deep learning now provide more economical and accessible solutions. This study introduces a novel spatio-temporal transformer network, capable of extracting vital gait parameters from RGB videos captured by a single-view camera. The model was tested on a public dataset of cerebral palsy patients, outperforming existing methods. This progress could improve the precision of estimating general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at peak extension, while utilizing fewer parameters and reduced manual feature extraction."
        ],
        [
            "People who have both musculoskeletal disorders and cognitive problems may face difficulties in movement and mental health. It is crucial to promptly recognize and address these issues, often involving clinical analysis of how they move (gait analysis). Previously, this typically needed costly motion capture systems. But now, developments in computer vision and deep learning provide more affordable and accessible options. This research presents a new network called a spatio-temporal transformer that can get important details about gait from regular video (RGB) taken by a single-view camera. The model was tried out on a public dataset of cerebral palsy patients and did better than other methods. This advancement could make it more accurate to estimate general gait parameters, like walking speed, gait deviation index, and knee flexion angle at peak extension, while using fewer parameters and less manual feature extraction."
        ],
        [
            "Individuals who suffer from both musculoskeletal conditions and cognitive issues may encounter challenges in terms of mobility and mental health. It is essential to identify and address these issues early, often involving an analysis of their movement or gait. In the past, this typically required expensive motion capture systems. However, recent advancements in computer vision and deep learning now offer more cost-effective and accessible solutions. This research introduces a new network called a spatio-temporal transformer that can extract crucial gait details from regular video (RGB) taken by a single-view camera. The model was tested on a public dataset of cerebral palsy patients and outperformed other methods. This progress could result in more accurate estimations of general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at peak extension, all while using fewer parameters and less manual feature extraction."
        ],
        [
            "People dealing with both musculoskeletal disorders and cognitive problems can face difficulties in terms of mobility and mental health. Early identification and addressing these problems are crucial, often involving an examination of their movement or gait. Earlier, this typically needed costly motion capture systems. But, with the latest developments in computer vision and deep learning, there are now more affordable and accessible solutions. This research presents a new network called a spatio-temporal transformer that can pull out vital gait details from regular video (RGB) taken by a single-view camera. The model was tried out on a public dataset of cerebral palsy patients and surpassed other methods. This advancement could lead to improved accuracy in estimating general gait parameters, including walking speed, gait deviation index, and knee flexion angle at peak extension, all while using fewer parameters and less manual feature extraction."
        ],
        [
            "Individuals with co-occurring musculoskeletal conditions and cognitive issues may encounter challenges in terms of mobility and mental health. Recognizing and addressing these issues early is vital, frequently requiring an analysis of their movement or stride pattern. In the past, this usually required expensive motion capture systems. However, with the recent advancements in computer vision and deep learning, there are now more economical and accessible options. This research introduces a new network called a spatio-temporal transformer, which can extract essential gait details from regular video (RGB) taken by a single-view camera. The model was tested on a public dataset of cerebral palsy patients and outperformed other methods. This development could result in enhanced precision in evaluating general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at peak extension, all while using fewer parameters and minimal manual feature extraction."
        ],
        [
            "People who have both musculoskeletal disorders and cognitive problems may face difficulties in terms of mobility and mental health. Early detection and treatment of these issues are crucial, often necessitating an examination of their movement or walking pattern. Earlier, this typically involved costly motion capture systems. But, with the latest improvements in computer vision and deep learning, there are now more affordable and accessible alternatives. This study presents a new network called a spatio-temporal transformer, which can draw out vital gait details from regular video (RGB) taken by a single-view camera. The model was tried out on a public dataset of cerebral palsy patients and outperformed other approaches. This progress could lead to enhanced accuracy in assessing general gait measurements, such as walking speed, gait deviation index, and knee flexion angle at maximum extension, while utilizing fewer parameters and minimal manual feature extraction."
        ],
        [
            "Individuals who suffer from both musculoskeletal conditions and cognitive issues may encounter challenges in relation to mobility and mental well-being. The early identification and treatment of these problems are essential, frequently requiring an analysis of their movement or walking patterns. Previously, this usually entailed the use of expensive motion capture systems. However, with recent advancements in computer vision and deep learning, there are now more economical and accessible options available. This research introduces a new network called a spatio-temporal transformer, which can extract crucial gait details from regular video (RGB) captured by a single-view camera. The model was tested on a publicly accessible dataset of cerebral palsy patients and outperformed other methods. This development could result in enhanced precision in evaluating general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at maximum extension, while utilizing fewer parameters and minimal manual feature extraction."
        ],
        [
            "People dealing with both musculoskeletal disorders and cognitive issues may face difficulties in terms of mobility and mental health. It is vital to promptly detect and address these issues, often involving an analysis of their movement or walking patterns. In the past, this typically required costly motion capture systems. But with current progress in computer vision and deep learning, there are now more affordable and accessible solutions. This study presents a new network called a spatio-temporal transformer. It can draw out key gait details from regular video (RGB) taken by a single-camera view. The model was evaluated on a publicly accessible dataset of cerebral palsy patients, and it outperformed other methods. This innovation could lead to improved accuracy in assessing general gait measures, such as walking speed, gait deviation index, and knee flexion angle at full extension, while using fewer parameters and minimal manual feature extraction."
        ],
        [
            "Individuals with both musculoskeletal conditions and cognitive problems may encounter challenges in relation to mobility and mental health. Early detection and treatment of these issues are crucial, often involving the examination of their movement or walking patterns, which in the past typically needed expensive motion capture systems. However, with recent advancements in computer vision and deep learning, there are now more budget-friendly and accessible solutions. This research introduces a new network called a spatio-temporal transformer, which can extract crucial gait details from regular video (RGB) taken by a single-camera view. The model was tested on a publicly available dataset of cerebral palsy patients and outperformed other methods. This development could result in enhanced accuracy in evaluating general gait measures, such as walking speed, gait deviation index, and knee flexion angle at full extension, while utilizing fewer parameters and minimal manual feature extraction."
        ],
        [
            "People who have both musculoskeletal disorders and cognitive issues may face difficulties in terms of mobility and mental health. It is vital to identify and address these problems early, which often includes analyzing their movement or walking patterns, a process that has typically required costly motion capture systems. But with the latest advancements in computer vision and deep learning, there are now more affordable and accessible alternatives. This research presents a new network called a spatio-temporal transformer, which can pull out essential gait details from regular RGB video taken by a single camera. The model was tested on a publicly accessible dataset of cerebral palsy patients and outperformed other methods. This innovation could lead to better accuracy in measuring general gait characteristics, such as walking speed, gait deviation index, and knee flexion angle at full extension, all while using fewer parameters and minimal manual feature extraction."
        ],
        [
            "Individuals who suffer from both musculoskeletal conditions and cognitive issues may encounter challenges in relation to mobility and mental health. It is crucial to identify and tackle these issues at an early stage, which often involves examining their movement or walking patterns, a process that has commonly required expensive motion capture systems. However, thanks to recent advancements in computer vision and deep learning, there are now more budget-friendly and accessible options. This research introduces a new network called a spatio-temporal transformer, which can extract key gait details from regular RGB videos captured by a single camera. The model was evaluated using a publicly available dataset of cerebral palsy patients and surpassed other methods in performance. This development could result in enhanced precision in measuring general gait attributes, such as walking speed, gait deviation index, and knee flexion angle at full extension, all while utilizing fewer parameters and minimal manual feature extraction."
        ],
        [
            "People who have both musculoskeletal disorders and cognitive problems may face difficulties in terms of mobility and mental health. It is essential to address these issues early on, which typically involves analyzing their movement or walking patterns, a process that has usually required costly motion capture systems. But, due to progress in computer vision and deep learning, there are now more affordable and accessible solutions. This research presents a new network called a spatio-temporal transformer, which can pull out crucial gait details from regular RGB videos taken by a single camera. The model was tested using a publicly available dataset of cerebral palsy patients and outperformed other methods. This innovation could lead to improved accuracy in measuring general gait attributes, such as walking speed, gait deviation index, and knee flexion angle at complete extension, all while using fewer parameters and minimal manual feature extraction."
        ],
        [
            "Individuals who suffer from both musculoskeletal conditions and cognitive issues may encounter challenges in terms of mobility and mental health. It is vital to tackle these problems promptly, often involving the analysis of their movement or walking patterns, which previously required expensive motion capture systems. However, advancements in computer vision and deep learning have led to more affordable and accessible alternatives. This research introduces a new network called a spatio-temporal transformer, which can extract crucial gait details from regular RGB videos captured by a single camera. The model was evaluated using a publicly available dataset of cerebral palsy patients and surpassed other methods in performance. This innovation could enhance the precision of measuring general gait attributes, such as walking speed, gait deviation index, and knee flexion angle at full extension, while utilizing fewer parameters and minimal manual feature extraction."
        ],
        [
            "People who have both musculoskeletal disorders and cognitive problems may face difficulties in terms of mobility and mental well-being. It is essential to address these issues quickly, which often involves examining their movement or walking patterns, a process that once needed costly motion capture systems. But now, thanks to progress in computer vision and deep learning, there are more affordable and accessible solutions. This research presents a new network called a spatio-temporal transformer, capable of identifying critical gait details from regular RGB videos taken by a single camera. The model was tested using a publicly accessible dataset of cerebral palsy patients and outperformed other methods. This development could improve the accuracy of measuring general gait attributes, such as walking speed, gait deviation index, and knee flexion angle at full extension, while using fewer parameters and minimal manual feature extraction."
        ],
        [
            "Individuals who suffer from both musculoskeletal conditions and cognitive issues may encounter challenges in relation to mobility and mental health. It is crucial to promptly address these issues, which frequently involves analyzing their movement or walking patterns, something that previously required expensive motion capture systems. However, advancements in computer vision and deep learning have led to more affordable and accessible solutions. This research introduces a new network called a spatio-temporal transformer, which can detect crucial gait details from standard RGB videos taken by a single camera. The model was evaluated using a publicly available dataset of cerebral palsy patients and surpassed other methods in performance. This innovation could enhance the precision of measuring general gait attributes, such as walking speed, gait deviation index, and knee flexion angle at full extension, while using fewer parameters and minimal manual feature extraction."
        ],
        [
            "People who have both musculoskeletal disorders and cognitive problems may face difficulties in terms of mobility and mental health. It is essential to quickly tackle these issues, which often involves examining their movement or walking behaviors, a process that was once dependent on costly motion capture systems. Nevertheless, progress in computer vision and deep learning has resulted in more budget-friendly and accessible alternatives. This research presents a new network called a spatio-temporal transformer, which can identify critical gait elements from standard RGB videos captured by a single camera. The model was assessed using a publicly accessible dataset of cerebral palsy patients and outperformed other methods. This development could improve the accuracy of measuring general gait attributes, such as walking speed, gait deviation index, and knee flexion angle at complete extension, while utilizing fewer parameters and minimal manual feature extraction."
        ],
        [
            "Individuals who suffer from both musculoskeletal conditions and cognitive issues may encounter challenges in relation to mobility and mental health. It is crucial to address these problems promptly, which frequently entails analyzing their movement or walking patterns, a procedure that was previously reliant on expensive motion capture systems. However, advancements in computer vision and deep learning have led to more affordable and accessible solutions. This research introduces a new network called a spatio-temporal transformer, which can detect key elements of gait from standard RGB videos captured by a single camera. The model was evaluated using a publicly available dataset of cerebral palsy patients and outperformed other methods. This progress could enhance the precision of measuring general gait attributes, such as walking speed, gait deviation index, and knee flexion angle at full extension, while utilizing fewer parameters and minimal manual feature extraction."
        ],
        [
            "People who have both musculoskeletal disorders and cognitive problems may face issues concerning mobility and mental health. It is vital to address these issues promptly, which often involves examining their movement or walking patterns, a process that once depended on costly motion capture systems. Nevertheless, developments in computer vision and deep learning have resulted in more economical and accessible options. This research presents a new network called a spatio-temporal transformer, which can identify critical elements of gait from standard RGB videos captured by a single camera. The model was tested using a publicly available dataset of cerebral palsy patients and outperformed other methods. This advancement could improve the accuracy of measuring general gait attributes, such as walking speed, gait deviation index, and knee flexion angle at complete extension, while using fewer parameters and minimal manual feature extraction."
        ],
        [
            "Individuals who suffer from both musculoskeletal conditions and cognitive issues may encounter problems related to mobility and mental health. It is essential to address these issues swiftly, which frequently involves analyzing their walking or movement patterns, something that was previously reliant on expensive motion capture systems. However, progress in computer vision and deep learning has led to more affordable and accessible alternatives. This research introduces a new network called a spatio-temporal transformer, which can extract crucial gait elements from regular RGB videos captured by a single camera. The model was evaluated using a publicly accessible dataset of cerebral palsy patients and surpassed other methods in performance. This development could enhance the precision of measuring general gait attributes, such as walking speed, gait deviation index, and knee flexion angle at full extension, while utilizing fewer parameters and minimal manual feature extraction."
        ],
        [
            "People who have both musculoskeletal disorders and cognitive problems may face challenges in terms of mobility and mental health. It is crucial to quickly address these issues, often involving the analysis of their walking or movement patterns, which was once dependent on costly motion capture systems. But with advancements in computer vision and deep learning, more economical and accessible options are now available. This research presents a new network called a spatio-temporal transformer, which can pull out vital gait features from regular RGB videos taken by a single camera. The model was tested using a publicly accessible dataset of cerebral palsy patients and outperformed other methods. This innovation could improve the accuracy of measuring general gait attributes, such as walking speed, gait deviation index, and knee flexion angle at full extension, all while using fewer parameters and minimal manual feature extraction."
        ],
        [
            "Individuals who suffer from both musculoskeletal conditions and cognitive issues may encounter difficulties in terms of mobility and mental health. It is essential to promptly address these problems, which were previously reliant on expensive motion capture systems to analyze their walking or movement patterns. However, with the progress in computer vision and deep learning, more affordable and accessible solutions are now at our disposal. This research introduces a new network called a spatio-temporal transformer, which can extract crucial gait features from regular RGB videos captured by a single camera. The model was evaluated using a publicly accessible dataset of cerebral palsy patients and surpassed other methodologies in performance. This innovation could enhance the precision of measuring general gait attributes, such as walking speed, gait deviation index, and knee flexion angle at full extension, all while utilizing fewer parameters and minimal manual feature extraction."
        ],
        [
            "People dealing with both musculoskeletal disorders and cognitive problems can face challenges in terms of mobility and mental well-being. It's vital to promptly tackle these issues, which in the past depended on costly motion capture systems for analyzing their walking or movement patterns. Nevertheless, with advancements in computer vision and deep learning, more budget-friendly and accessible solutions are now available. This research presents a new network called a spatio-temporal transformer, which can pull out key gait features from regular RGB videos taken by a single camera. The model was tested using a publicly accessible dataset of cerebral palsy patients and outperformed other methods in performance. This development could improve the accuracy of measuring general gait attributes, like walking speed, gait deviation index, and knee flexion angle at complete extension, all while using fewer parameters and minimal manual feature extraction."
        ],
        [
            "Individuals with co-occurring musculoskeletal conditions and cognitive issues may encounter difficulties in terms of mobility and mental health. It is crucial to address these problems promptly, which previously relied on expensive motion capture systems for analyzing their gait or movement patterns. However, with the progress in computer vision and deep learning, more affordable and accessible solutions are now within reach. This research introduces a new network called a spatio-temporal transformer, which can extract vital gait features from regular RGB videos captured by a single camera. The model was evaluated using a publicly available dataset of cerebral palsy patients and surpassed other methods in performance. This innovation could enhance the precision of measuring general gait attributes, such as walking speed, gait deviation index, and knee flexion angle at full extension, all while using fewer parameters and minimal manual feature extraction."
        ]
    ]
}