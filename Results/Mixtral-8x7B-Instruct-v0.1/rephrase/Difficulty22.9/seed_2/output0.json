{
    "adjacency_matrix": [
        [
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0
        ]
    ],
    "prompt_init": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "prompt_update": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "personality_list": [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        ""
    ],
    "format_prompt": [
        ""
    ],
    "initial_story": "musculoskeletal diseases and cognitive impairments in patients lead todifficulties in movement as well as negative effects on their psychologicalhealth. clinical gait analysis, a vital tool for early diagnosis and treatment,traditionally relies on expensive optical motion capture systems. recentadvances in computer vision and deep learning have opened the door to moreaccessible and cost-effective alternatives. this paper introduces a novelspatio-temporal transformer network to estimate critical gait parameters fromrgb videos captured by a single-view camera. empirical evaluations on a publicdataset of cerebral palsy patients indicate that the proposed frameworksurpasses current state-of-the-art approaches and show significant improvementsin predicting general gait parameters (including walking speed, gait deviationindex - gdi, and knee flexion angle at maximum extension), while utilizingfewer parameters and alleviating the need for manual feature extraction. ",
    "stories": [
        [
            "The presence of musculoskeletal diseases and cognitive impairments in individuals can result in mobility issues and have adverse effects on their psychological well-being. Clinical gait analysis is a crucial method for early detection and treatment; however, it typically depends on costly optical motion capture systems. New developments in computer vision and deep learning now offer more affordable and practical solutions. This paper presents a novel spatio-temporal transformer network to determine essential gait parameters from RGB videos captured by a single-view camera. Experimental evaluations on a public dataset of cerebral palsy patients suggest that this framework outperforms existing state-of-the-art approaches, resulting in significant improvements in predicting general gait parameters (such as walking speed, gait deviation index, and knee flexion angle at maximum extension) while utilizing fewer parameters and reducing the need for manual feature extraction."
        ],
        [
            "The existence of musculoskeletal disorders and cognitive impairments in people can lead to mobility problems and negatively impact their psychological health. Clinical gait analysis is a key tool for early detection and treatment, but it usually relies on expensive optical motion capture systems. Recent advancements in computer vision and deep learning have introduced more budget-friendly and viable solutions. This paper introduces a new spatio-temporal transformer network to extract important gait parameters from RGB videos taken by a single-view camera. Evaluations on a public dataset of cerebral palsy patients indicate that this model surpasses existing state-of-the-art methods, resulting in substantial enhancements in predicting general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at maximum extension. Additionally, it uses fewer parameters and reduces the need for manual feature extraction."
        ],
        [
            "The presence of musculoskeletal conditions and cognitive dysfunctions in individuals can cause issues with mobility and negatively affect their psychological well-being. Clinical gait analysis is crucial for early detection and treatment; however, it typically depends on costly optical motion capture systems. Progress in computer vision and deep learning has resulted in more cost-effective and practical alternatives. This paper presents a new spatio-temporal transformer network that can extract key gait parameters from RGB videos captured by a single-view camera. Experiments on a public dataset of cerebral palsy patients show that this model outperforms existing state-of-the-art methods, resulting in significant improvements in predicting general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at maximum extension. Furthermore, it uses fewer parameters and reduces the need for manual feature extraction."
        ],
        [
            "The existence of musculoskeletal disorders and cognitive impairments in people can lead to mobility problems and have a negative impact on their psychological health. Clinical gait analysis is essential for early detection and treatment; however, it usually relies on expensive optical motion capture systems. With advancements in computer vision and deep learning, there are now more affordable and feasible options available. This paper introduces a new spatio-temporal transformer network that can derive crucial gait parameters from RGB videos taken with a single-view camera. Testing on a public dataset of cerebral palsy patients indicates that this model surpasses existing state-of-the-art methods, leading to substantial enhancements in predicting general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at maximum extension. Additionally, it uses fewer parameters and decreases the requirement for manual feature extraction."
        ],
        [
            "The presence of musculoskeletal conditions and cognitive declines in individuals can result in issues with mobility and negatively affect their psychological well-being. It is crucial to have early detection and treatment through clinical gait analysis; however, this often depends on costly optical motion capture systems. Fortunately, with advancements in computer vision and deep learning, there are now more cost-effective and practical alternatives. This paper presents a novel spatio-temporal transformer network that can extract important gait parameters from RGB videos captured with a single-view camera. Experiments on a public dataset of cerebral palsy patients show that this model outperforms existing state-of-the-art methods, resulting in significant improvements in predicting general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at maximum extension. Furthermore, it uses fewer parameters and reduces the need for manual feature extraction."
        ],
        [
            "The existence of musculoskeletal disorders and cognitive impairments in people can lead to mobility problems and have a negative impact on their psychological health. It is essential to have early identification and treatment using clinical gait analysis, which often relies on expensive optical motion capture systems. However, with the progression in computer vision and deep learning, there are now more affordable and practical solutions. This paper introduces a new spatio-temporal transformer network that can derive crucial gait parameters from RGB videos taken with a single-view camera. Testing on a public dataset of cerebral palsy patients indicates that this model surpasses current state-of-the-art methods, leading to enhancements in predicting general gait parameters, like walking speed, gait deviation index, and knee flexion angle at maximum extension. Additionally, it uses fewer parameters and decreases the requirement for manual feature extraction."
        ],
        [
            "Musculoskeletal disorders and cognitive issues in individuals can result in mobility difficulties and harm their psychological well-being. Early detection and treatment through clinical gait analysis are crucial, although this usually requires costly optical motion capture systems. Nevertheless, advancements in computer vision and deep learning now provide more affordable and viable alternatives. This paper presents a novel spatio-temporal transformer network that can extract key gait parameters from RGB videos captured by a single-view camera. Experiments on a public dataset of cerebral palsy patients suggest that this model outperforms existing state-of-the-art methods, improving the prediction of general gait parameters such as walking speed, gait deviation index, and knee flexion angle at full extension. Furthermore, it utilizes fewer parameters and reduces the need for manual feature extraction."
        ],
        [
            "Musculoskeletal disorders and cognitive problems in people can lead to mobility problems and negatively affect their psychological health. It is essential to identify and treat these issues early through clinical gait analysis, even though this typically needs expensive optical motion capture systems. However, recent advancements in computer vision and deep learning now offer cheaper and practical solutions. This paper introduces a new spatio-temporal transformer network that can derive crucial gait parameters from RGB videos taken by a single-view camera. The model has been tested on a public dataset of cerebral palsy patients and has been found to surpass existing state-of-the-art methods. It enhances the prediction of general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at full extension. Also, it uses fewer parameters and minimizes the requirement for manual feature extraction."
        ],
        [
            "Musculoskeletal and cognitive issues in individuals can result in mobility challenges and have adverse effects on their psychological well-being. Early identification and treatment of these problems are crucial, which typically requires clinical gait analysis using costly optical motion capture systems. Nevertheless, new developments in computer vision and deep learning provide more affordable and feasible alternatives. This paper presents a novel spatio-temporal transformer network that can extract key gait parameters from RGB videos captured by a single-camera view. The model has been evaluated on a public dataset of cerebral palsy patients and has outperformed existing state-of-the-art methods. It improves the prediction of general gait parameters, such as walking speed, gait deviation index, and knee flexion angle in full extension. Furthermore, it uses fewer parameters and reduces the need for manual feature extraction."
        ],
        [
            "The presence of musculoskeletal and cognitive concerns in people can lead to difficulties in mobility and negatively impact their psychological health. It is essential to identify and address these issues early, which usually involves the use of expensive optical motion capture systems for clinical gait analysis. However, recent advancements in computer vision and deep learning now offer more cost-effective and practical solutions. This paper introduces a new spatio-temporal transformer network capable of extracting critical gait parameters from RGB videos taken with a single-camera view. The model was tested on a publicly available dataset of cerebral palsy patients and surpassed existing state-of-the-art methods. It enhances the prediction of general gait parameters, including walking speed, gait deviation index, and knee flexion angle at full extension. Additionally, the model uses fewer parameters and reduces the requirement for manual feature extraction."
        ],
        [
            "Having musculoskeletal and cognitive problems in individuals can result in challenges with mobility and harm their psychological well-being. It is crucial to identify and handle these issues promptly, which often requires the use of costly optical motion capture systems for clinical gait analysis. Nevertheless, progress in computer vision and deep learning now provides more affordable and practical alternatives. This paper presents a novel spatio-temporal transformer network that can derive crucial gait parameters from RGB videos obtained with a single-camera view. The model was evaluated on a publicly accessible dataset of cerebral palsy patients and outperformed current state-of-the-art methods. It improves the prediction of general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at full extension. Furthermore, the model uses fewer parameters and decreases the need for manual feature extraction."
        ],
        [
            "Individuals who have musculoskeletal and cognitive issues may face difficulties in mobility and experience negative impacts on their psychological health. It is essential to quickly identify and address these problems, which typically involves the use of expensive optical motion capture systems for clinical gait analysis. However, advancements in computer vision and deep learning now offer more affordable and feasible solutions. This paper introduces a novel spatio-temporal transformer network that can extract key gait parameters from RGB videos taken with a single-camera view. The model was tested on a publicly available dataset of cerebral palsy patients and outperformed existing state-of-the-art methods. The model enhances the prediction of general gait parameters, including walking speed, gait deviation index, and knee flexion angle at full extension. Additionally, the model uses fewer parameters and reduces the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive challenges may encounter mobility issues and see negative effects on their psychological well-being. It is crucial to promptly identify and tackle these problems, which often requires the use of costly optical motion capture systems for clinical gait analysis. Nevertheless, progress in computer vision and deep learning now provides more budget-friendly and practical alternatives. This paper presents a new spatio-temporal transformer network that can derive crucial gait parameters from RGB videos obtained with a single-camera view. The model was evaluated on a publicly accessible dataset of cerebral palsy patients and surpassed existing state-of-the-art techniques. The model improves the prediction of general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at full extension. Furthermore, the model uses fewer parameters and minimizes the requirement for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive difficulties may face issues with mobility and experience harmful effects on their psychological health. It is essential to quickly identify and address these problems, which typically involves the use of expensive optical motion capture systems for clinical gait analysis. However, advancements in computer vision and deep learning now offer more affordable and practical solutions. This paper introduces a new spatio-temporal transformer network that can extract key gait parameters from RGB videos taken with a single-camera view. The model was tested on a publicly available dataset of cerebral palsy patients and outperformed existing state-of-the-art methods. The model enhances the prediction of general gait parameters, including walking speed, gait deviation index, and knee flexion angle at maximum extension. Additionally, the model uses fewer parameters and reduces the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive challenges may encounter mobility problems and negative impacts on their psychological well-being. Rapid detection and intervention of these issues are crucial, usually requiring costly optical motion capture systems for clinical gait analysis. Nevertheless, progress in computer vision and deep learning now provide more cost-effective and viable alternatives. This study presents a novel spatio-temporal transformer network, capable of deriving crucial gait parameters from RGB videos obtained with a single-camera perspective. The model, tested on a publicly accessible dataset of cerebral palsy patients, surpassed existing state-of-the-art methods. It improves the prediction of general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at peak extension. Furthermore, the model operates with fewer parameters and lessens the demand for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive difficulties often face issues with mobility and experience harmful effects on their psychological health. It is essential to quickly identify and address these problems, which typically requires expensive optical motion capture systems for clinical gait analysis. However, advancements in computer vision and deep learning now offer more affordable and practical solutions. This research introduces a novel spatio-temporal transformer network that can extract key gait parameters from RGB videos taken with a single-camera view. The model, evaluated on a publicly available dataset of cerebral palsy patients, outperformed existing state-of-the-art methods. It enhances the prediction of general gait parameters, including walking speed, gait deviation index, and knee flexion angle at peak extension. Moreover, the model uses fewer parameters and reduces the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive challenges often encounter mobility issues and endure negative impacts on their psychological well-being. Rapid detection and resolution of these issues are crucial, typically necessitating costly optical motion capture systems for clinical gait analysis. Nevertheless, progress in computer vision and deep learning now present more cost-effective and viable alternatives. This research proposes a new spatio-temporal transformer network that can derive essential gait parameters from RGB videos obtained using a single-camera view. The model, tested on a publicly accessible dataset of cerebral palsy patients, surpassed existing state-of-the-art methods. It improves the prediction of general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at peak extension. Additionally, the model uses fewer parameters and decreases the requirement for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive difficulties frequently face difficulties in mobility and experience harmful effects on their psychological health. It is important to quickly identify and address these issues, which often require expensive optical motion capture systems for clinical gait analysis. However, advancements in computer vision and deep learning now offer more affordable and practical solutions. This research introduces a new spatio-temporal transformer network that can extract key gait parameters from RGB videos taken with a single-camera view. The model, which was tested on a publicly available dataset of cerebral palsy patients, outperformed existing state-of-the-art methods. It enhances the prediction of general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at maximum extension. Furthermore, the model uses fewer parameters and reduces the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive challenges often encounter challenges in mobility and experience negative impacts on their psychological well-being. It is crucial to promptly identify and address these issues, which typically necessitate costly optical motion capture systems for clinical gait analysis. Nevertheless, developments in computer vision and deep learning now provide more cost-effective and practical alternatives. This research presents a new spatio-temporal transformer network that can derive essential gait parameters from RGB videos captured with a single-camera view. The model, which was evaluated on a publicly accessible dataset of cerebral palsy patients, surpassed existing state-of-the-art methods. It improves the prediction of general gait parameters, including walking speed, gait deviation index, and knee flexion angle at maximum extension. Moreover, the model uses fewer parameters and decreases the requirement for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive difficulties frequently face issues in mobility and see negative effects on their psychological health. It is vital to quickly identify and address these problems, which traditionally require expensive optical motion capture systems for clinical gait analysis. However, advancements in computer vision and deep learning now offer more affordable and practical solutions. This research introduces a new spatio-temporal transformer network that can extract key gait parameters from RGB videos taken with a single-camera view. The model, which was tested on a publicly available dataset of cerebral palsy patients, outperformed existing state-of-the-art methods. It enhances the prediction of general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at maximum extension. Furthermore, the model uses fewer parameters and reduces the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive challenges often experience problems in mobility, which can negatively impact their psychological well-being. Rapidly identifying and addressing these issues is crucial, but this typically requires costly optical motion capture systems for clinical gait analysis. Fortunately, advancements in computer vision and deep learning now provide more affordable and practical alternatives. This research presents a novel spatio-temporal transformer network that can extract crucial gait parameters from RGB videos taken with a single-camera view. The model, which was evaluated on a publicly accessible dataset of cerebral palsy patients, surpassed existing state-of-the-art methods. It improves the prediction of general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at maximum extension. Additionally, the model uses fewer parameters and reduces the requirement for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive difficulties often face mobility problems, which can have a negative effect on their psychological health. It is essential to quickly identify and address these mobility problems, however, this usually needs expensive optical motion capture systems for clinical gait analysis. Fortunately, progress in computer vision and deep learning now offers more cost-effective and practical solutions. This research proposes a new spatio-temporal transformer network that can derive crucial gait parameters from RGB videos taken with a single-camera view. The model, which was tested on a publicly available dataset of cerebral palsy patients, outperformed existing state-of-the-art methods. It enhances the prediction of general gait parameters, including walking speed, gait deviation index, and knee flexion angle at maximum extension. Furthermore, the model uses fewer parameters and decreases the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive impairments often experience difficulty moving, which can negatively impact their mental health. Rapidly identifying and addressing these mobility issues is crucial, but this typically requires costly optical motion capture systems for clinical gait analysis. However, advancements in computer vision and deep learning now provide more affordable and practical alternatives. This research proposes a new spatio-temporal transformer network that can extract vital gait parameters from RGB videos taken with a single-camera view. The model, which was evaluated on a publicly accessible dataset of cerebral palsy patients, surpassed existing state-of-the-art methods. It improves the prediction of general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at maximum extension. Moreover, the model utilizes fewer parameters and reduces the requirement for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive impairments often face challenges in movement that can adversely affect their mental health. It is essential to quickly identify and tackle these mobility problems, usually done through expensive optical motion capture systems for clinical gait analysis. However, recent advancements in computer vision and deep learning offer more affordable and feasible solutions. This research introduces a new spatio-temporal transformer network that can derive crucial gait parameters from RGB videos taken with a single-camera view. The model, tested on a publicly available dataset of cerebral palsy patients, outperformed existing state-of-the-art methods. It enhances the prediction of general gait parameters, including walking speed, gait deviation index, and knee flexion angle at peak extension. Furthermore, the model uses fewer parameters and decreases the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive disabilities often encounter difficulties in mobility that can negatively impact their mental health. Rapidly identifying and addressing these mobility issues, typically through costly optical motion capture systems for clinical gait analysis, is crucial. Nevertheless, advancements in computer vision and deep learning have paved the way for more economical and practical solutions. This research presents a novel spatio-temporal transformer network that can extract key gait parameters from RGB videos taken with a single-camera view. The model, evaluated on a publicly accessible dataset of cerebral palsy patients, surpassed existing state-of-the-art methods. It improves the prediction of general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at peak extension. Additionally, the model utilizes fewer parameters and reduces the requirement for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive impairments frequently face mobility challenges that can adversely affect their mental health. It is essential to quickly identify and handle these mobility problems, which have traditionally been done using expensive optical motion capture systems for clinical gait analysis. However, recent progress in computer vision and deep learning now allows for more affordable and practical alternatives. This research proposes a new spatio-temporal transformer network capable of extracting critical gait parameters from RGB videos taken with a single camera. The model, tested on a publicly available dataset of cerebral palsy patients, outperformed existing state-of-the-art methods. It enhances the prediction of general gait parameters, including walking speed, gait deviation index, and knee flexion angle at peak extension. Furthermore, the model uses fewer parameters and decreases the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive issues often encounter mobility issues that can negatively impact their mental health. Rapidly detecting and addressing these mobility problems, which have typically been accomplished through costly optical motion capture systems in clinical gait analysis, is crucial. Nevertheless, advancements in computer vision and deep learning now offer more cost-effective and practical solutions. This research introduces a new spatio-temporal transformer network that can extract key gait parameters from RGB videos captured by a single camera. The model, evaluated on a publicly accessible dataset of cerebral palsy patients, surpassed existing state-of-the-art methods. It improves the prediction of general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at peak extension. Additionally, the model utilizes fewer parameters and reduces the need for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive challenges often face mobility issues that can adversely affect their mental health. It is essential to quickly identify and address these mobility problems, which have traditionally been detected using expensive optical motion capture systems in clinical gait analysis. However, recent advances in computer vision and deep learning now provide more affordable and practical alternatives. This research introduces a new spatio-temporal transformer network that can extract crucial gait parameters from RGB videos captured by a single camera. The model, tested on a publicly available dataset of cerebral palsy patients, outperformed existing state-of-the-art methods. It enhances the prediction of general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at maximum extension. Furthermore, the model uses fewer parameters and reduces the requirement for manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive difficulties often experience mobility issues that can have negative effects on their mental health. It is important to promptly identify and tackle these mobility problems, which have typically been recognized using costly optical motion capture systems in clinical gait analysis. Nevertheless, progress in computer vision and deep learning now offers more budget-friendly and efficient solutions. This study presents a new spatio-temporal transformer network that can derive critical gait parameters from RGB videos captured by a single camera. The model, evaluated on a publicly accessible dataset of cerebral palsy patients, surpassed existing top-performing methods. It improves the prediction of general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at peak extension. Additionally, the model uses fewer parameters and decreases the need for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive challenges often face mobility issues, which can negatively impact their mental health. Identifying and addressing these mobility problems quickly is crucial, as they have traditionally been detected using expensive optical motion capture systems in clinical gait analysis. However, advancements in computer vision and deep learning now provide more cost-effective and efficient solutions. This research introduces a novel spatio-temporal transformer network that can extract essential gait parameters from RGB videos captured by a single camera. The model, tested on a publicly available dataset of cerebral palsy patients, outperformed existing high-ranking methods. It enhances the prediction of general gait parameters, including walking speed, gait deviation index, and knee flexion angle at maximum extension. Moreover, the model uses fewer parameters and reduces the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive difficulties often experience issues with mobility, which can adversely affect their mental health. It is vital to promptly identify and address these mobility problems, which have typically been identified using costly optical motion capture systems in clinical gait analysis. Nevertheless, progress in computer vision and deep learning now offers more affordable and efficient alternatives. This research presents a new spatio-temporal transformer network that can derive crucial gait parameters from RGB videos taken by a single camera. The model, evaluated on a publicly accessible dataset of cerebral palsy patients, surpassed existing high-performing methods. It improves the prediction of general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at maximum extension. Furthermore, the model uses fewer parameters and reduces the need for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive challenges often face mobility issues, which can negatively impact their mental health. Identifying and addressing these mobility problems quickly is crucial, and while this has typically been done using expensive optical motion capture systems in clinical gait analysis, recent advancements in computer vision and deep learning provide more affordable and efficient solutions. This research introduces a new spatio-temporal transformer network that can extract vital gait parameters from RGB videos taken by a single camera. The model, tested on a publicly available dataset of cerebral palsy patients, outperformed existing high-performing methods. It enhances the prediction of general gait parameters, including walking speed, gait deviation index, and knee flexion angle at maximum extension. Additionally, the model uses fewer parameters and reduces the requirement for manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive difficulties often experience movement problems, which can adversely affect their mental health. Rapidly detecting and solving these mobility issues is critical, and while this has traditionally been achieved using costly optical motion capture systems in clinical gait analysis, new developments in computer vision and deep learning now offer more cost-effective and efficient alternatives. This study presents a novel spatio-temporal transformer network that can derive essential gait parameters from RGB videos captured by a single camera. The model, evaluated on a publicly accessible dataset of cerebral palsy patients, surpassed existing high-performing methods. It improves the prediction of general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at maximum extension. Furthermore, the model uses fewer parameters and decreases the need for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive challenges often face issues with movement, which can negatively impact their mental health. It is crucial to quickly identify and address these mobility problems, and while this has typically been done using expensive optical motion capture systems in clinical gait analysis, new advancements in computer vision and deep learning now provide more affordable and efficient solutions. This study introduces a new spatio-temporal transformer network that can extract crucial gait parameters from RGB videos captured by a single camera. The model, which was tested on a publicly available dataset of cerebral palsy patients, outperformed existing high-performing methods. It enhances the prediction of general gait parameters, including walking speed, gait deviation index, and knee flexion angle at maximum extension. Additionally, the model uses fewer parameters and reduces the requirement for manual feature extraction."
        ],
        [
            "Individuals who have difficulties with movement due to musculoskeletal and cognitive issues often experience negative effects on their mental health. It is essential to promptly identify and solve these mobility problems. In the past, this has usually been done using costly optical motion capture systems in clinical gait analysis. However, recent advancements in computer vision and deep learning now offer more affordable and efficient alternatives. This study presents a new spatio-temporal transformer network that can extract key gait parameters from RGB videos taken by a single camera. The model, which was evaluated on a publicly accessible dataset of cerebral palsy patients, surpassed the performance of existing high-performing methods. It improves the prediction of general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at maximum extension. Furthermore, the model uses fewer parameters and reduces the need for manual feature extraction."
        ],
        [
            "People who struggle with movement due to musculoskeletal and cognitive challenges often encounter issues affecting their mental health. It is crucial to quickly identify and address these mobility problems. In the past, this was typically done using expensive optical motion capture systems in clinical gait analysis. But, thanks to recent progress in computer vision and deep learning, there are now more cost-effective and efficient solutions. This research introduces a new spatio-temporal transformer network that can extract crucial gait parameters from RGB videos captured by a single camera. The model, tested on a publicly available dataset of cerebral palsy patients, outperformed existing high-performing methods. It enhances the prediction of general gait parameters, like walking speed, gait deviation index, and knee flexion angle at peak extension. Moreover, the model uses fewer parameters and decreases the need for manual feature extraction."
        ],
        [
            "Individuals who face difficulties with movement due to musculoskeletal and cognitive issues often experience mental health consequences, making it important to promptly identify and address mobility problems. Traditionally, this was accomplished using costly optical motion capture systems in clinical gait analysis, but advancements in computer vision and deep learning have led to more affordable and efficient alternatives. This research presents a novel spatio-temporal transformer network that can derive crucial gait parameters from RGB videos captured by a single camera. The model, evaluated on a publicly accessible dataset of cerebral palsy patients, surpassed existing high-performing methods in predicting general gait parameters such as walking speed, gait deviation index, and knee flexion angle at peak extension. Additionally, the model uses fewer parameters and reduces the requirement for manual feature extraction."
        ],
        [
            "People who struggle with movement due to musculoskeletal and cognitive challenges often encounter mental health impacts, highlighting the importance of quickly identifying and addressing mobility issues. In the past, this was typically done using expensive optical motion capture systems in clinical gait analysis. However, recent advancements in computer vision and deep learning have resulted in more cost-effective and efficient solutions. This research introduces a novel spatio-temporal transformer network capable of extracting key gait parameters from RGB videos taken by a single camera. The model, tested on a publicly available dataset of cerebral palsy patients, outperformed existing high-performing methods in predicting general gait parameters, including walking speed, gait deviation index, and knee flexion angle at peak extension. Furthermore, the model uses fewer parameters and minimizes the need for manual feature extraction."
        ],
        [
            "Individuals who face difficulties with movement due to musculoskeletal and cognitive issues often experience mental health consequences, emphasizing the need for promptly identifying and addressing mobility problems. Earlier, this was usually accomplished using costly optical motion capture systems in clinical gait analysis. But, thanks to progress in computer vision and deep learning, more affordable and efficient solutions are now available. This research presents a new spatio-temporal transformer network that can extract crucial gait parameters from RGB videos captured by a single camera. The model, tested on a publicly accessible dataset of cerebral palsy patients, surpassed existing high-performing methods in predicting general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at peak extension. Moreover, the model uses fewer parameters and reduces the need for manual feature extraction."
        ],
        [
            "People who struggle with movement due to musculoskeletal and cognitive challenges often encounter mental health issues, highlighting the importance of quickly identifying and addressing mobility problems. In the past, this was typically done using expensive optical motion capture systems in clinical gait analysis. However, advancements in computer vision and deep learning have led to the development of more affordable and efficient solutions. This research introduces a new spatio-temporal transformer network that can extract key gait parameters from RGB videos captured by a single camera. The model, which was tested on a publicly accessible dataset of cerebral palsy patients, outperformed existing high-performing methods in predicting general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at maximum extension. Furthermore, the model uses fewer parameters and decreases the need for manual feature extraction."
        ],
        [
            "Individuals who face difficulties with movement due to musculoskeletal and cognitive issues often experience mental health issues, stressing the need for promptly identifying and tackling mobility problems. Earlier, this was usually accomplished using costly optical motion capture systems in clinical gait analysis. Nevertheless, progress in computer vision and deep learning has paved the way for more affordable and efficient alternatives. This research presents a new spatio-temporal transformer network capable of extracting crucial gait parameters from RGB videos taken by a single camera. The model, tested on a publicly available dataset of cerebral palsy patients, surpassed existing high-performing methods in estimating general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at peak extension. Additionally, the model operates with fewer parameters and reduces the requirement for manual feature extraction."
        ],
        [
            "People who struggle with movement due to musculoskeletal and cognitive challenges often deal with mental health issues, highlighting the importance of quickly identifying and addressing mobility problems. In the past, this was typically done using expensive optical motion capture systems in clinical gait analysis. However, advancements in computer vision and deep learning have led to more affordable and efficient solutions. This research introduces a new spatio-temporal transformer network that can extract crucial gait parameters from RGB videos captured by a single camera. The model, tested on a dataset of cerebral palsy patients, outperformed existing high-performing methods in estimating general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at peak extension. Furthermore, the model uses fewer parameters and decreases the need for manual feature extraction."
        ],
        [
            "Individuals facing difficulties with movement due to musculoskeletal and cognitive issues often experience mental health concerns, emphasizing the need for prompt detection and treatment of mobility problems. Historically, this process usually involved costly optical motion capture systems in clinical gait analysis. Nevertheless, progress in computer vision and deep learning has resulted in more cost-effective and efficient alternatives. This study presents a novel spatio-temporal transformer network capable of identifying essential gait parameters from RGB videos obtained by a single camera. The model, evaluated on a cerebral palsy patient dataset, surpassed existing high-performing methods in estimating general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at maximum extension. Additionally, the model operates with fewer parameters and reduces the requirement for manual feature extraction."
        ],
        [
            "People who have trouble moving due to musculoskeletal and cognitive challenges often also deal with mental health issues, highlighting the importance of quickly detecting and treating mobility problems. In the past, identifying and analyzing these issues typically required expensive optical motion capture systems. However, advancements in computer vision and deep learning have led to more affordable and efficient solutions. This study introduces a new spatio-temporal transformer network that can extract key gait parameters from RGB videos captured by a single camera. The model, which was tested using a cerebral palsy patient dataset, outperformed other high-ranking methods in estimating general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at maximum extension. Furthermore, the model uses fewer parameters and decreases the need for manual feature extraction."
        ],
        [
            "Individuals facing difficulties with mobility due to musculoskeletal and cognitive issues often experience mental health problems, emphasizing the necessity of rapidly identifying and addressing mobility problems. Earlier, detecting and analyzing these issues usually involved costly optical motion capture systems. But now, with advancements in computer vision and deep learning, more affordable and efficient solutions are available. This study presents a new spatio-temporal transformer network that can extract crucial gait parameters from RGB videos obtained by a single camera. The model, which was evaluated using a cerebral palsy patient dataset, surpassed other leading methods in estimating general gait parameters like walking speed, gait deviation index, and knee flexion angle at maximum extension. Additionally, the model uses fewer parameters and reduces the need for manual feature extraction."
        ],
        [
            "People with mobility challenges, caused by musculoskeletal and cognitive problems, often also have mental health issues, highlighting the importance of quickly identifying and addressing mobility issues. In the past, detecting and analyzing these issues typically required expensive optical motion capture systems. However, with recent advancements in computer vision and deep learning, more affordable and efficient solutions are now accessible. This research introduces a new spatio-temporal transformer network that can derive crucial gait parameters from RGB videos taken by a single camera. The model, which was tested using a cerebral palsy patient dataset, outperformed other leading methods in estimating general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at maximum extension. Moreover, the model uses fewer parameters and minimizes the need for manual feature extraction."
        ],
        [
            "Individuals with mobility difficulties, which can stem from musculoskeletal and cognitive issues, often grapple with mental health conditions as well. This underscores the significance of promptly recognizing and addressing mobility problems. Earlier, identifying and analyzing these issues normally involved costly optical motion capture systems. But thanks to contemporary progress in computer vision and deep learning, more economical and efficient methods are now available. This study presents a novel spatio-temporal transformer network capable of extracting key gait parameters from RGB videos captured by a single camera. The model, evaluated using a cerebral palsy patient dataset, surpassed other top methods in estimating general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at peak extension. Additionally, the model operates with fewer parameters and reduces the need for manual feature extraction."
        ],
        [
            "People with mobility challenges, which may be caused by musculoskeletal and cognitive problems, often experience mental health issues as well. This highlights the importance of quickly identifying and addressing mobility problems. In the past, identifying and analyzing these issues typically required expensive optical motion capture systems. However, advancements in computer vision and deep learning have led to the development of more affordable and efficient methods. This research introduces a new spatio-temporal transformer network that can extract crucial gait parameters from RGB videos taken by a single camera. The model, tested on a dataset of cerebral palsy patients, outperformed other leading methods in estimating general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at maximum extension. Furthermore, the model uses fewer parameters and reduces the need for manual feature extraction."
        ],
        [
            "Individuals facing mobility difficulties, which can be a result of musculoskeletal and cognitive issues, often also deal with mental health problems. This emphasizes the significance of promptly recognizing and addressing mobility problems. Earlier, the identification and analysis of these issues usually involved costly optical motion capture systems. But, progress in computer vision and deep learning has paved the way for more cost-effective and efficient methods. This research proposes a new spatio-temporal transformer network that can derive crucial gait parameters from RGB videos captured by a single camera. The model, when tested on a dataset of cerebral palsy patients, surpassed other existing methods in estimating general gait parameters, like walking speed, gait deviation index, and knee flexion angle at maximum extension. Additionally, the model uses fewer parameters and decreases the requirement for manual feature extraction."
        ],
        [
            "People with trouble moving, possibly due to musculoskeletal and cognitive challenges, often also experience mental health issues. This highlights the importance of quickly identifying and addressing mobility problems. In the past, identifying and analyzing these issues typically required expensive optical motion capture systems. However, advancements in computer vision and deep learning have made more affordable and efficient methods possible. This research presents a new spatio-temporal transformer network that can extract key gait parameters from RGB videos taken by a single camera. The model, when evaluated on a cerebral palsy patient dataset, outperformed other existing methods in estimating general gait parameters, such as walking speed, gait deviation index, and knee flexion angle at maximum extension. Furthermore, the model uses fewer parameters and reduces the need for manual feature extraction."
        ]
    ]
}