{
    "adjacency_matrix": [
        [
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0
        ]
    ],
    "prompt_init": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "prompt_update": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "personality_list": [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        ""
    ],
    "format_prompt": [
        ""
    ],
    "initial_story": "musculoskeletal diseases and cognitive impairments in patients lead todifficulties in movement as well as negative effects on their psychologicalhealth. clinical gait analysis, a vital tool for early diagnosis and treatment,traditionally relies on expensive optical motion capture systems. recentadvances in computer vision and deep learning have opened the door to moreaccessible and cost-effective alternatives. this paper introduces a novelspatio-temporal transformer network to estimate critical gait parameters fromrgb videos captured by a single-view camera. empirical evaluations on a publicdataset of cerebral palsy patients indicate that the proposed frameworksurpasses current state-of-the-art approaches and show significant improvementsin predicting general gait parameters (including walking speed, gait deviationindex - gdi, and knee flexion angle at maximum extension), while utilizingfewer parameters and alleviating the need for manual feature extraction. ",
    "stories": [
        [
            "The presence of musculoskeletal diseases and cognitive disorders in individuals can result in mobility issues and have adverse effects on their psychological well-being. Clinical gait analysis, which is crucial for early detection and treatment, typically uses costly optical motion capture systems. However, recent developments in computer vision and deep learning now make more affordable and accessible alternatives possible. This paper presents a new spatio-temporal transformer network for estimating key gait parameters from RGB videos captured by a single-view camera. Evaluations on a public dataset of cerebral palsy patients suggest that this method outperforms existing state-of-the-art approaches, resulting in significant improvements in predicting general gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Furthermore, it uses fewer parameters and eliminates the need for manual feature extraction."
        ],
        [
            "Musculoskeletal diseases and cognitive disorders in people can lead to mobility problems and negatively impact their psychological health. Early detection and treatment of these issues typically rely on clinical gait analysis, which has traditionally used expensive optical motion capture systems. But, advances in computer vision and deep learning now allow for more affordable and accessible options. This paper introduces a new spatio-temporal transformer network for estimating critical gait parameters from RGB videos taken with a single-view camera. Testing on a public dataset of cerebral palsy patients indicates that this method surpasses existing state-of-the-art approaches, resulting in major enhancements in predicting general gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Additionally, it uses fewer parameters and does not require manual feature extraction."
        ],
        [
            "Musculoskeletal and cognitive conditions in individuals can cause mobility difficulties and harm their psychological well-being. Identifying and addressing these problems early on usually involves clinical gait analysis, which has historically used costly optical motion capture systems. However, recent advancements in computer vision and deep learning now provide more affordable and accessible alternatives. This paper presents a novel spatio-temporal transformer network for estimating essential gait parameters from RGB videos taken with a single-view camera. Evaluation using a public dataset of cerebral palsy patients shows that this method outperforms existing state-of-the-art techniques, significantly improving the prediction of general gait parameters, such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Furthermore, it utilizes fewer parameters and does not necessitate manual feature extraction."
        ],
        [
            "The presence of musculoskeletal and cognitive issues in people can lead to mobility challenges and negatively impact their psychological health. Early detection and addressing these problems typically involve clinical gait analysis, which has traditionally relied on expensive optical motion capture systems. But, progress in computer vision and deep learning now offer more budget-friendly and accessible options. This paper introduces a new spatio-temporal transformer network for estimating crucial gait parameters from RGB videos captured with a single-view camera. Testing on a public dataset of cerebral palsy patients indicates that this method surpasses existing state-of-the-art techniques, resulting in significant enhancements in predicting general gait parameters, like walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Additionally, it uses fewer parameters and does not require manual feature extraction."
        ],
        [
            "The existence of musculoskeletal and cognitive problems in individuals can result in difficulties with mobility and negatively influence their psychological well-being. Identifying and handling these issues early on typically involves clinical gait analysis, which has traditionally utilized costly optical motion capture systems. However, advancements in computer vision and deep learning now provide more cost-effective and accessible alternatives. This paper presents a new spatio-temporal transformer network for estimating vital gait parameters from RGB videos captured with a single-view camera. Experiments on a public dataset of cerebral palsy patients suggest that this method outperforms current state-of-the-art techniques, resulting in substantial improvements in predicting general gait parameters, such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Moreover, it uses fewer parameters and does not need manual feature extraction."
        ],
        [
            "The presence of musculoskeletal and cognitive challenges in people can lead to problems with movement and negatively impact their psychological health. Early detection and management of these problems usually involve clinical gait analysis, which traditionally relied on expensive optical motion capture systems. Nevertheless, progress in computer vision and deep learning now offer more affordable and accessible options. This paper introduces a new spatio-temporal transformer network for estimating essential gait parameters from RGB videos obtained with a single-view camera. Experiments on a public dataset of cerebral palsy patients indicate that this method surpasses existing state-of-the-art techniques, resulting in significant advancements in predicting general gait parameters, such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Additionally, this method uses fewer parameters and does not require manual feature extraction."
        ],
        [
            "Having musculoskeletal and cognitive difficulties in individuals can cause issues with movement and negatively affect their psychological well-being. Identifying and addressing these issues early typically involves clinical gait analysis, which traditionally used costly optical motion capture systems. However, advancements in computer vision and deep learning now provide more affordable and accessible alternatives. This paper presents a new spatio-temporal transformer network for estimating crucial gait parameters from RGB videos taken with a single-view camera. Experiments on a public dataset of cerebral palsy patients show that this method outperforms existing state-of-the-art techniques, resulting in significant improvements in predicting general gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Furthermore, this method uses fewer parameters and does not need manual feature extraction."
        ],
        [
            "Individuals who have musculoskeletal and cognitive challenges may encounter problems with movement and experience adverse effects on their psychological health. Early detection and addressing these problems usually involve clinical gait analysis, which historically has utilized expensive optical motion capture systems. Nevertheless, innovations in computer vision and deep learning now offer more budget-friendly and accessible options. This paper introduces a novel spatio-temporal transformer network for estimating vital gait parameters from RGB videos captured by a single-view camera. The results of experiments conducted on a public dataset of cerebral palsy patients indicate that this method surpasses existing state-of-the-art techniques, leading to substantial enhancements in predicting general gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Additionally, this method utilizes fewer parameters and does not require manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive difficulties may face difficulties in movement and see negative impacts on their psychological well-being. Identifying and handling these issues early often involves clinical gait analysis, which has traditionally used costly optical motion capture systems. However, advances in computer vision and deep learning now provide more affordable and accessible alternatives. This paper presents a new spatio-temporal transformer network for estimating key gait parameters from RGB videos taken with a single-view camera. Experiments on a public dataset of cerebral palsy patients show that this method outperforms current state-of-the-art techniques, resulting in significant improvements in predicting general gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Furthermore, this method uses fewer parameters and does not need manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive challenges may encounter problems in mobility and experience adversely affected psychological health. Early detection and management of these issues typically involve clinical gait analysis, which has historically relied on expensive optical motion capture systems. Nevertheless, progress in computer vision and deep learning now offer more budget-friendly and accessible options. This paper introduces a new spatio-temporal transformer network for estimating critical gait parameters from RGB videos captured with a single-view camera. Our method, tested on a public dataset of cerebral palsy patients, surpasses current state-of-the-art techniques, leading to substantial enhancements in predicting general gait parameters, such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Additionally, our approach utilizes fewer parameters and does not require manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive difficulties may face difficulties in movement and have negatively impacted psychological well-being. Traditionally, identifying and managing these issues have typically involved clinical gait analysis using costly optical motion capture systems. However, advancements in computer vision and deep learning now provide more affordable and accessible alternatives. This paper presents a new spatio-temporal transformer network for estimating crucial gait parameters from RGB videos captured with a single-view camera. The proposed method, evaluated on a public dataset of cerebral palsy patients, outperforms existing state-of-the-art techniques, resulting in significant improvements in predicting general gait parameters, including walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Moreover, the approach utilizes fewer parameters and does not need manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive challenges may experience problems in mobility and possess a reduced psychological well-being. Traditionally, recognizing and addressing these problems have normally involved clinical gait analysis using high-priced optical motion capture systems. Nevertheless, progress in computer vision and deep learning now offer cheaper and more accessible solutions. This paper introduces a novel spatio-temporal transformer network to estimate key gait parameters from RGB videos obtained by a single-view camera. The proposed technique, tested on a public dataset of cerebral palsy patients, surpasses current state-of-the-art methods, leading to substantial enhancements in predicting general gait parameters, such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Furthermore, the approach uses fewer parameters and does not require manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive difficulties may face issues in mobility and have lower psychological well-being. In the past, identifying and dealing with these issues typically involved clinical gait analysis using expensive optical motion capture systems. However, advancements in computer vision and deep learning now provide more affordable and accessible alternatives. This paper presents a new spatio-temporal transformer network to determine crucial gait parameters from RGB videos taken by a single-view camera. The proposed method, evaluated on a public dataset of cerebral palsy patients, outperforms existing state-of-the-art techniques, resulting in significant improvements in predicting general gait parameters, such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Additionally, this approach uses fewer parameters and does not need manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive challenges may encounter problems in mobility and possess lower psychological well-being. Earlier, identifying and addressing these issues usually involved clinical gait analysis with costly optical motion capture systems. Nevertheless, progress in computer vision and deep learning now offers more budget-friendly and accessible solutions. This paper introduces a novel spatio-temporal transformer network to extract key gait parameters from RGB videos captured by a single-view camera. The suggested technique, assessed on a public dataset of cerebral palsy patients, surpasses current state-of-the-art methods, leading to substantial enhancements in predicting general gait parameters, such as walking speed, gait deviation index (GDI), and knee flexion angle at peak extension. Furthermore, this method utilizes fewer parameters and does not require manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive difficulties often face issues in mobility and have lower psychological well-being. In the past, identifying and addressing these problems typically involved expensive optical motion capture systems for clinical gait analysis. However, advancements in computer vision and deep learning now provide more affordable and accessible alternatives. This paper presents a new spatio-temporal transformer network that can extract crucial gait parameters from RGB videos taken by a single-view camera. The proposed method, tested on a public dataset of cerebral palsy patients, outperforms existing state-of-the-art techniques, resulting in significant improvements in predicting general gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at peak extension. Moreover, this technique uses fewer parameters and does not need manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive challenges often encounter mobility problems and experience reduced psychological well-being. Earlier, identifying and tackling these issues normally required costly optical motion capture systems for clinical gait analysis. Nevertheless, progress in computer vision and deep learning now offers more economical and accessible solutions. This paper introduces a novel spatio-temporal transformer network capable of deriving essential gait parameters from RGB videos captured by a single-view camera. The proposed approach, evaluated on a publicly available dataset of cerebral palsy patients, surpasses current state-of-the-art methods, leading to substantial enhancements in predicting general gait parameters, such as walking speed, gait deviation index (GDI), and knee flexion angle at peak extension. Furthermore, this method utilizes fewer parameters and does not depend on manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive difficulties often face issues with mobility and see a decline in their psychological well-being. In the past, identifying and addressing these problems typically involved expensive optical motion capture systems for clinical gait analysis. However, advancements in computer vision and deep learning now provide more affordable and accessible alternatives. This paper presents a new spatio-temporal transformer network that can extract crucial gait parameters from RGB videos taken by a single-view camera. The proposed method, which was tested on a publicly accessible dataset of cerebral palsy patients, outperforms current state-of-the-art techniques, resulting in significant improvements in predicting general gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at peak extension. Additionally, this approach uses fewer parameters and does not require manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive challenges often encounter mobility problems and experience a decrease in their psychological health. Earlier, detecting and tackling these issues normally involved costly optical motion capture systems for clinical gait analysis. But, recent advancements in computer vision and deep learning now offer more cost-effective and accessible solutions. This paper introduces a new spatio-temporal transformer network that can derive vital gait parameters from RGB videos captured by a single-view camera. The proposed technique, which was evaluated on a publicly available dataset of cerebral palsy patients, surpasses existing state-of-the-art methods, resulting in substantial enhancements in predicting general gait parameters, including walking speed, gait deviation index (GDI), and knee flexion angle at peak extension. Moreover, this method utilizes fewer parameters and doesn't need manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive difficulties often face issues with mobility and see a decline in their psychological well-being. In the past, identifying and addressing these problems typically involved expensive optical motion capture systems for clinical gait analysis. However, recent developments in computer vision and deep learning now provide more affordable and accessible alternatives. This paper presents a new spatio-temporal transformer network that can extract crucial gait parameters from RGB videos captured by a single-view camera. The proposed approach, which was tested on a publicly accessible dataset of cerebral palsy patients, outperforms existing state-of-the-art methods, resulting in significant improvements in predicting general gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at peak extension. Furthermore, this method uses fewer parameters and does not require manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive challenges often encounter mobility problems and a decrease in their psychological health. Earlier, detecting and tackling these issues normally involved costly optical motion capture systems for clinical gait analysis. But, advancements in computer vision and deep learning now offer more economical and accessible solutions. This paper introduces a novel spatio-temporal transformer network that can derive vital gait parameters from RGB videos obtained by a single-view camera. The suggested method, which was evaluated on a publicly available dataset of cerebral palsy patients, surpasses current cutting-edge techniques, leading to substantial enhancements in predicting general gait parameters like walking speed, gait deviation index (GDI), and knee flexion angle at peak extension. Additionally, this approach utilizes fewer parameters and does not need manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive difficulties often face issues with mobility and see a decline in their psychological well-being. In the past, identifying and addressing these problems typically involved expensive optical motion capture systems for clinical gait analysis. However, progress in computer vision and deep learning now provides more affordable and accessible alternatives. This paper presents a new spatio-temporal transformer network that can extract crucial gait parameters from RGB videos taken by a single-view camera. The proposed method, which was tested on a publicly accessible dataset of cerebral palsy patients, outperforms current state-of-the-art techniques, resulting in significant improvements in predicting general gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at peak extension. Furthermore, this approach uses fewer parameters and does not require manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive impairments often experience mobility challenges and a decrease in psychological health. In the past, identifying and tackling these issues usually involved costly optical motion capture systems for clinical gait analysis. But, advancements in computer vision and deep learning now offer more budget-friendly and accessible solutions. This paper introduces a new spatio-temporal transformer network that can derive vital gait parameters from RGB videos captured by a single-view camera. The suggested technique, which was evaluated on a publicly available dataset of cerebral palsy patients, surpasses existing state-of-the-art methods, leading to substantial enhancements in predicting general gait parameters, including walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Additionally, this method utilizes fewer parameters and does not need manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive difficulties often face difficulties in mobility and see a decline in their psychological well-being. In the past, identifying and addressing these problems typically required expensive optical motion capture systems for clinical gait analysis. However, progress in computer vision and deep learning now provides more affordable and accessible alternatives. This paper presents a new spatio-temporal transformer network capable of extracting crucial gait parameters from RGB videos taken with a single-view camera. The proposed method, which was tested on a publicly available dataset of cerebral palsy patients, outperforms existing state-of-the-art methods, resulting in significant improvements in predicting general gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Furthermore, this technique uses fewer parameters and does not require manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive challenges often encounter mobility issues and experience a decrease in their psychological health. Earlier, recognizing and tackling these challenges usually involved costly optical motion capture systems for clinical gait analysis. But, advancements in computer vision and deep learning now offer more economical and accessible solutions. This paper introduces a new spatio-temporal transformer network that can extract vital gait parameters from RGB videos captured with a single-view camera. The proposed approach, evaluated on a publicly accessible dataset of cerebral palsy patients, surpasses current state-of-the-art methods, leading to substantial enhancements in predicting general gait parameters, including walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Moreover, this method utilizes fewer parameters and does not need manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive difficulties often face difficulties in mobility and see a decline in their psychological well-being. In the past, identifying and addressing these issues typically required expensive optical motion capture systems for clinical gait analysis. However, developments in computer vision and deep learning now provide more affordable and accessible alternatives. This paper presents a new spatio-temporal transformer network that can derive crucial gait parameters from RGB videos taken with a single-view camera. The proposed method, tested on a publicly available dataset of cerebral palsy patients, outperforms existing state-of-the-art techniques, resulting in significant improvements in predicting general gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Furthermore, this approach uses fewer parameters and does not require manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive challenges often encounter mobility issues and experience a decrease in their psychological health. Earlier, recognizing and tackling these problems normally involved costly optical motion capture systems for clinical gait analysis. But, advancements in computer vision and deep learning now offer more budget-friendly and accessible solutions. This paper introduces a novel spatio-temporal transformer network that can extract essential gait parameters from RGB videos captured with a single-view camera. The proposed technique, evaluated on a publicly accessible dataset of cerebral palsy patients, surpasses existing top-tier methods, leading to substantial enhancements in predicting general gait parameters, including walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Moreover, this method utilizes fewer parameters and does not need manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive difficulties often face difficulties in mobility and see a decline in their psychological well-being. In the past, identifying and addressing these issues typically required expensive optical motion capture systems for clinical gait analysis. However, progress in computer vision and deep learning now provides more affordable and accessible options. This paper presents a new spatio-temporal transformer network that can extract crucial gait parameters from RGB videos taken with a single-view camera. The proposed method, tested on a publicly available dataset of cerebral palsy patients, outperforms existing leading methods, resulting in significant improvements in predicting general gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Additionally, this technique uses fewer parameters and does not require manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive challenges often encounter mobility issues and experience a decrease in their psychological health. Earlier, recognizing and tackling these problems usually involved costly optical motion capture systems for clinical gait analysis. Nevertheless, advancements in computer vision and deep learning now offer more cost-effective and accessible alternatives. This paper introduces a new spatio-temporal transformer network capable of deriving essential gait parameters from RGB videos captured with a single-view camera. The proposed approach, evaluated on a publicly accessible dataset of cerebral palsy patients, surpasses existing top-performing methods, leading to substantial enhancements in predicting general gait parameters, including walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Furthermore, this method utilizes fewer parameters and does not depend on manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive difficulties often face issues with mobility and see a decline in their psychological well-being. In the past, identifying and addressing these problems typically required expensive optical motion capture systems for clinical gait analysis. However, recent advancements in computer vision and deep learning now provide more affordable and accessible solutions. This paper presents a new spatio-temporal transformer network that can extract crucial gait parameters from RGB videos taken with a single-view camera. The proposed method, which was tested on a publicly available dataset of cerebral palsy patients, outperforms existing leading methods, resulting in significant improvements in predicting general gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Additionally, this approach uses fewer parameters and does not require manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive challenges often experience problems with mobility and a decrease in their psychological health. Earlier, recognizing and tackling these issues usually needed costly optical motion capture systems for clinical gait analysis. But, modern progress in computer vision and deep learning now offer more budget-friendly and accessible options. This paper introduces a new spatio-temporal transformer network that can derive vital gait parameters from RGB videos taken with a single-view camera. The suggested technique, which was evaluated on a publicly accessible dataset of cerebral palsy patients, surpasses current top methods, leading to substantial advancements in estimating general gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Furthermore, this method utilizes fewer parameters and does not need manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive difficulties often face issues with mobility and see a decline in their psychological well-being. In the past, identifying and addressing these problems typically required expensive optical motion capture systems for clinical gait analysis. However, recent advancements in computer vision and deep learning now provide more cost-effective and accessible solutions. This paper presents a new spatio-temporal transformer network capable of extracting crucial gait parameters from RGB videos captured with a single-view camera. The proposed method, which was tested on a publicly available dataset of cerebral palsy patients, outperforms existing techniques, resulting in significant improvements in estimating general gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Additionally, this technique uses fewer parameters and does not require manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive challenges often encounter mobility problems and a decrease in psychological health. Earlier, recognizing and tackling these issues usually needed costly optical motion capture systems for clinical gait analysis. But, modern developments in computer vision and deep learning now offer more budget-friendly and accessible alternatives. This paper introduces a new spatio-temporal transformer network that can derive essential gait parameters from RGB videos obtained with a single-view camera. The suggested approach, evaluated on a publicly accessible dataset of cerebral palsy patients, surpasses existing methods, leading to substantial enhancements in estimating general gait parameters, including walking speed, gait deviation index (GDI), and knee flexion angle at peak extension. Moreover, this method utilizes fewer parameters and does not necessitate manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive difficulties often face issues with mobility and see a decline in their psychological well-being. In the past, identifying and addressing these problems typically required expensive optical motion capture systems for clinical gait analysis. However, advancements in computer vision and deep learning now provide more affordable and accessible options. This paper presents a new spatio-temporal transformer network capable of extracting crucial gait parameters from RGB videos taken with a single-view camera. The proposed method, tested on a publicly available dataset of cerebral palsy patients, outperforms existing methods, resulting in significant improvements in estimating general gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at peak extension. Furthermore, this approach uses fewer parameters and does not require manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive challenges often encounter mobility problems and experience a decrease in their psychological health. Earlier, recognizing and tackling these issues usually involved costly optical motion capture systems for clinical gait analysis. But now, progress in computer vision and deep learning offers more economical and convenient solutions. This paper introduces a new spatio-temporal transformer network that can extract vital gait parameters from RGB videos captured with a single-view camera. The suggested technique, evaluated on a publicly accessible dataset of cerebral palsy patients, surpasses existing methods, leading to substantial enhancements in estimating general gait parameters, including walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Additionally, this method utilizes fewer parameters and does not need manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive difficulties often face issues with mobility and see a decline in their psychological well-being. In the past, identifying and addressing these problems typically involved expensive optical motion capture systems for clinical gait analysis. However, advancements in computer vision and deep learning now provide more affordable and accessible solutions. This paper presents a new spatio-temporal transformer network capable of extracting crucial gait parameters from RGB videos taken with a single-view camera. The proposed method, tested on a publicly available dataset of cerebral palsy patients, outperforms existing techniques, resulting in significant improvements in estimating general gait parameters such as walking speed, gait deviation index (GDI), and knee flexion angle at maximum extension. Furthermore, this approach uses fewer parameters and does not require manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive challenges often encounter mobility problems and experience a decrease in their psychological health. Earlier, recognizing and tackling these issues normally involved costly optical motion capture systems for clinical gait analysis. But, progress in computer vision and deep learning now offer more budget-friendly and accessible solutions. This paper introduces a new spatio-temporal transformer network that can extract vital gait parameters from RGB videos captured with a single-view camera. The suggested technique, evaluated on a publicly accessible dataset of cerebral palsy patients, surpasses existing methods, leading to substantial enhancements in estimating general gait parameters, like walking speed, gait deviation index (GDI), and knee angle at maximum flexion. Moreover, this method utilizes fewer parameters and doesn't need manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive difficulties often face issues with mobility and see a decline in their psychological well-being. In the past, identifying and addressing these challenges typically required expensive optical motion capture systems for clinical gait analysis. However, advancements in computer vision and deep learning now provide more affordable and accessible solutions. This paper presents a new spatio-temporal transformer network capable of extracting crucial gait parameters from RGB videos taken with a single-view camera. The proposed method, tested on a publicly available dataset of cerebral palsy patients, outperforms existing techniques, resulting in significant improvements in estimating general gait parameters such as walking speed, gait deviation index (GDI), and knee angle at maximum flexion. Furthermore, this approach uses fewer parameters and does not require manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive impairments often experience mobility problems and a decrease in psychological health. Earlier, recognizing and tackling these issues normally involved costly optical motion capture systems for clinical gait analysis. But, progress in computer vision and deep learning now offer more cost-effective and accessible options. This paper introduces a new spatio-temporal transformer network that can extract vital gait parameters from RGB videos captured with a single-view camera. The proposed technique, evaluated on a publicly accessible dataset of cerebral palsy patients, surpasses existing methods, leading to substantial enhancements in estimating general gait parameters, such as walking speed, gait deviation index (GDI), and knee angle at peak flexion. Additionally, this method utilizes fewer parameters and does not need manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive disabilities often face challenges in mobility and see a decline in mental health. In the past, identifying and addressing these issues typically required expensive optical motion capture systems for clinical gait analysis. However, advancements in computer vision and deep learning now provide more affordable and accessible alternatives. This paper presents a new spatio-temporal transformer network that can derive crucial gait parameters from RGB videos captured with a single-view camera. The proposed method, tested on a publicly available dataset of cerebral palsy patients, outperforms existing techniques and significantly improves the estimation of general gait parameters, such as walking speed, gait deviation index (GDI), and knee angle at maximum flexion. Furthermore, this technique uses fewer parameters and does not require manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive impairments frequently encounter difficulties in mobility and experience a deterioration in mental health. Historically, identifying and addressing these problems normally involved costly optical motion capture systems for clinical gait analysis. Nevertheless, progress in computer vision and deep learning now offers more economical and accessible solutions. This paper introduces a novel spatio-temporal transformer network that can extract vital gait parameters from RGB videos captured with a single-view camera. The suggested approach, evaluated on a publicly accessible dataset of cerebral palsy patients, surpasses existing methods and significantly enhances the estimation of general gait parameters, including walking speed, gait deviation index (GDI), and knee angle at peak flexion. Additionally, this technique utilizes fewer parameters and does not need manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive issues often face challenges in mobility and see a decline in mental health. In the past, identifying and addressing these issues typically involved expensive optical motion capture systems for clinical gait analysis. However, advancements in computer vision and deep learning now provide more affordable and accessible alternatives. This paper presents a new spatio-temporal transformer network capable of extracting crucial gait parameters from RGB videos taken with a single-view camera. The proposed method, tested on a publicly available dataset of cerebral palsy patients, outperforms existing methods and significantly improves the estimation of general gait parameters, such as walking speed, gait deviation index (GDI), and knee angle at maximum flexion. Furthermore, this technique uses fewer parameters and does not require manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive problems often encounter difficulties in mobility and experience a decline in mental health. In the past, identifying and dealing with these issues normally required costly optical motion capture systems for clinical gait analysis. Nevertheless, progress in computer vision and deep learning now offer more economical and accessible solutions. This paper introduces a new spatio-temporal transformer network that can extract vital gait parameters from RGB videos captured with a single-view camera. The suggested approach, evaluated on a publicly accessible dataset of cerebral palsy patients, surpasses existing methods and significantly enhances the estimation of general gait parameters, including walking speed, gait deviation index (GDI), and knee angle at peak flexion. Moreover, this method utilizes fewer parameters and does not need manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive issues often face challenges in mobility and see a decrease in mental health. In the past, identifying and addressing these problems typically involved expensive optical motion capture systems for clinical gait analysis. However, advancements in computer vision and deep learning now provide more affordable and accessible alternatives. This paper presents a new spatio-temporal transformer network capable of extracting crucial gait parameters from RGB videos captured with a single-view camera. The proposed method, tested on a publicly available dataset of cerebral palsy patients, outperforms existing methods and significantly improves the estimation of general gait parameters, such as walking speed, gait deviation index (GDI), and knee angle at maximum flexion. Furthermore, this approach uses fewer parameters and does not require manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive difficulties often encounter mobility issues and experience a decline in mental health. Earlier, detecting and addressing these problems normally involved costly optical motion capture systems for clinical gait analysis. But, recent advancements in computer vision and deep learning now offer more budget-friendly and accessible solutions. This paper introduces a new spatio-temporal transformer network that can extract essential gait parameters from RGB videos captured with a single-view camera. The proposed technique, evaluated on a publicly accessible dataset of cerebral palsy patients, surpasses existing methods and considerably enhances the estimation of general gait parameters, like walking speed, gait deviation index (GDI), and knee angle at peak flexion. Additionally, this method uses fewer parameters and does not need manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive challenges often face mobility problems and see a decline in their mental health. In the past, identifying and handling these issues typically required expensive optical motion capture systems for clinical gait analysis. However, developments in computer vision and deep learning now provide more affordable and accessible alternatives. This paper presents a novel spatio-temporal transformer network capable of extracting key gait parameters from RGB videos captured with a single-view camera. The proposed approach, tested on a publicly available dataset of cerebral palsy patients, outperforms existing methods and significantly improves the estimation of general gait parameters, such as walking speed, gait deviation index (GDI), and knee angle at maximum flexion. Furthermore, this technique uses fewer parameters and does not require manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive difficulties often encounter mobility issues and experience a deterioration in their mental health. Earlier, recognizing and addressing these challenges mainly relied on costly optical motion capture systems for clinical gait analysis. Nevertheless, advancements in computer vision and deep learning now offer more economical and accessible solutions. This paper introduces a novel spatio-temporal transformer network that can derive crucial gait parameters from RGB videos obtained with a single-view camera. The proposed method, evaluated on a publicly accessible dataset of cerebral palsy patients, surpasses existing techniques and enhances the estimation of general gait parameters, including walking speed, gait deviation index (GDI), and knee angle at peak flexion. Additionally, this approach utilizes fewer parameters and does not demand manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive problems often face challenges in mobility and see a decline in their mental health. In the past, identifying and dealing with these issues mainly depended on expensive optical motion capture systems for clinical gait analysis. However, progress in computer vision and deep learning now provides more affordable and accessible options. This paper presents a new spatio-temporal transformer network that can extract key gait parameters from RGB videos taken with a single-view camera. The proposed method, tested on a publicly available dataset of cerebral palsy patients, outperforms existing methods and improves the estimation of general gait parameters, such as walking speed, gait deviation index (GDI), and knee angle at maximum flexion. Furthermore, this approach uses fewer parameters and does not require manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive difficulties often encounter difficulties in mobility and experience a deterioration in their mental health. In the past, identifying and addressing these issues primarily relied on costly optical motion capture systems for clinical gait analysis. However, advancements in computer vision and deep learning now offer more economical and accessible solutions. This paper introduces a new spatio-temporal transformer network that can derive crucial gait parameters from RGB videos captured with a single-view camera. The proposed method, evaluated on a publicly accessible dataset of cerebral palsy patients, surpasses existing methods and enhances the estimation of general gait parameters, including walking speed, gait deviation index (GDI), and knee angle at peak flexion. Moreover, this approach utilizes fewer parameters and does not necessitate manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive challenges often face issues in movement and see a decline in their mental health. Earlier, identifying and dealing with these problems mainly depended on expensive optical motion capture systems for clinical gait analysis. But now, progress in computer vision and deep learning provide more affordable and accessible alternatives. This paper presents a new spatio-temporal transformer network that can extract vital gait parameters from RGB videos taken with a single-view camera. The suggested technique, tested on a publicly available dataset of cerebral palsy patients, outperforms existing methods and improves the estimation of general gait parameters, such as walking speed, gait deviation index (GDI), and knee angle at maximum flexion. Furthermore, this method uses fewer parameters and does not require manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive difficulties frequently encounter difficulties in mobility and experience a deterioration in their mental health. In the past, identifying and addressing these issues primarily relied on costly optical motion capture systems for clinical gait analysis. However, advancements in computer vision and deep learning now offer more affordable and accessible solutions. This paper introduces a novel spatio-temporal transformer network capable of extracting crucial gait parameters from RGB videos captured with a single-view camera. The proposed method, evaluated on a publicly accessible dataset of cerebral palsy patients, surpasses existing techniques and enhances the estimation of general gait parameters, including walking speed, gait deviation index (GDI), and knee angle at peak flexion. Additionally, this approach uses fewer parameters and does not necessitate manual feature extraction."
        ]
    ]
}