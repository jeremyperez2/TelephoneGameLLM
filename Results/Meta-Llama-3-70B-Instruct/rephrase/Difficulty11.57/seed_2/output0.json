{
    "adjacency_matrix": [
        [
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0
        ]
    ],
    "prompt_init": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "prompt_update": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "personality_list": [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        ""
    ],
    "format_prompt": [
        ""
    ],
    "initial_story": "having the potential for high speed, high throughput, and low energy cost,optical neural networks (onns) have emerged as a promising candidate foraccelerating deep learning tasks. in conventional onns, light amplitudes aremodulated at the input and detected at the output. however, the light phasesare still ignored in conventional structures, although they can also carryinformation for computing. to address this issue, in this paper, we propose aframework called oplixnet to compress the areas of onns by modulating inputimage data into the amplitudes and phase parts of light signals. the input andoutput parts of the onns are redesigned to make full use of both amplitude andphase information. moreover, mutual learning across different onn structures isintroduced to maintain the accuracy. experimental results demonstrate that theproposed framework significantly reduces the areas of onns with the accuracywithin an acceptable range. for instance, 75.03% area is reduced with a 0.33%accuracy decrease on fully connected neural network (fcnn) and 74.88% area isreduced with a 2.38% accuracy decrease on resnet-32. ",
    "stories": [
        [
            "Optical neural networks (ONNs) have shown great promise for accelerating deep learning tasks due to their potential for high speed, high throughput, and low energy cost. In traditional ONNs, light amplitudes are modified at the input and detected at the output, but the phases of light signals, which also carry computational information, are neglected. This paper proposes a novel framework called OplixNet, which compresses ONN areas by encoding input image data into both amplitude and phase components of light signals. The input and output components of ONNs are redesigned to fully utilize both amplitude and phase information, and mutual learning across different ONN structures is introduced to maintain accuracy. Experimental results show that the proposed framework significantly reduces ONN areas while maintaining acceptable accuracy levels, with area reductions of 75.03% and 74.88% and accuracy decreases of 0.33% and 2.38% for fully connected neural networks (FCNN) and ResNet-32, respectively."
        ],
        [
            "Deep learning tasks can be accelerated by optical neural networks (ONNs) due to their potential for high-speed processing, high throughput, and low energy consumption. However, traditional ONNs only modify light amplitudes at the input and detect them at the output, overlooking the computational information carried by light signal phases. This paper introduces OplixNet, a novel framework that compresses ONN areas by encoding input image data into both amplitude and phase components of light signals. By redesigning input and output components to harness both amplitude and phase information and introducing mutual learning across different ONN structures, the framework maintains accuracy. The experimental results demonstrate that OplixNet significantly reduces ONN areas while preserving acceptable accuracy levels, achieving area reductions of 75.03% and 74.88% and accuracy decreases of 0.33% and 2.38% for fully connected neural networks (FCNN) and ResNet-32, respectively."
        ],
        [
            "Optical neural networks (ONNs) offer a promising solution to accelerate deep learning tasks, thanks to their high processing speed, high throughput, and low energy consumption. Nevertheless, conventional ONNs have a significant limitation: they only manipulate light amplitudes at the input and detect them at the output, neglecting the valuable computational information encoded in light signal phases. This study presents OplixNet, a novel framework that minimizes ONN areas by encoding input image data into both amplitude and phase components of light signals. By reconfiguring input and output components to leverage both amplitude and phase information and introducing cross-learning between different ONN structures, the framework maintains its accuracy. Experimental results show that OplixNet achieves significant area reductions of 75.03% and 74.88% for fully connected neural networks (FCNN) and ResNet-32, respectively, while only incurring minimal accuracy losses of 0.33% and 2.38%."
        ],
        [
            "Deep learning tasks can be accelerated using optical neural networks (ONNs), which boast high processing speeds, high throughput, and low energy consumption. However, traditional ONNs have a major limitation: they only process light amplitude at the input and output, overlooking the valuable computational information contained in light signal phases. This study introduces OplixNet, a novel framework that reduces ONN areas by encoding input image data into both light amplitude and phase components. By reconfiguring input and output components to utilize both amplitude and phase information and introducing cross-learning between different ONN structures, the framework maintains its accuracy while achieving significant area reductions of 75.03% for fully connected neural networks (FCNN) and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as demonstrated by experimental results."
        ],
        [
            "Optical neural networks (ONNs) can significantly accelerate deep learning tasks due to their high processing speeds, high throughput, and low energy consumption. Nevertheless, conventional ONNs have a major shortcoming: they only consider light amplitude at the input and output, neglecting the valuable computational information present in light signal phases. This study presents OplixNet, a novel approach that minimizes ONN areas by encoding input image data into both amplitude and phase components of light. By leveraging both amplitude and phase information in input and output components and introducing cross-learning between different ONN structures, the framework achieves substantial area reductions of 75.03% for fully connected neural networks (FCNN) and 74.88% for ResNet-32, with only minor accuracy losses of 0.33% and 2.38%, respectively, as confirmed by experimental results."
        ],
        [
            "Deep learning tasks can be greatly expedited by optical neural networks (ONNs) thanks to their exceptional processing speeds, high-volume throughput, and low energy requirements. However, traditional ONNs have a significant limitation: they solely focus on light amplitude at the input and output, overlooking the valuable computational data inherent in light signal phases. This research introduces OplixNet, a groundbreaking approach that reduces ONN sizes by encoding input image data into both the amplitude and phase aspects of light. By harnessing both amplitude and phase information in input and output components and promoting cross-learning between different ONN architectures, the framework achieves significant area reductions of 75.03% for fully connected neural networks (FCNN) and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as validated by experimental results."
        ],
        [
            "The processing of deep learning tasks can be significantly accelerated by optical neural networks (ONNs), which offer exceptional speed, high-volume processing, and low energy consumption. However, conventional ONNs have a major drawback: they only consider light amplitude at the input and output, neglecting the valuable computational data embedded in light signal phases. This study presents OplixNet, a pioneering approach that reduces ONN sizes by encoding input image data into both the amplitude and phase components of light. By leveraging both amplitude and phase information in input and output components and facilitating cross-learning between different ONN architectures, the framework achieves substantial area reductions of 75.03% for fully connected neural networks (FCNN) and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as confirmed by experimental results."
        ],
        [
            "The execution of deep learning tasks can be substantially sped up by optical neural networks (ONNs), which boast remarkable speed, high-capacity processing, and low power usage. Nonetheless, traditional ONNs have a significant limitation: they only take into account the amplitude of light at the input and output, overlooking the valuable computational information contained in the phase of the light signal. This research introduces OplixNet, a groundbreaking approach that shrinks ONN sizes by encoding input image data into both the amplitude and phase aspects of light. By harnessing both amplitude and phase data in input and output components and enabling cross-learning between different ONN architectures, the framework achieves significant area reductions of 75.03% for fully connected neural networks (FCNN) and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as validated by experimental results."
        ],
        [
            "Optical neural networks (ONNs) can significantly accelerate deep learning tasks due to their exceptional speed, high processing capacity, and low energy consumption. However, conventional ONNs have a notable drawback: they only consider the amplitude of light at the input and output, neglecting the valuable computational data encoded in the light signal's phase. This study presents OplixNet, a pioneering approach that reduces ONN sizes by encoding input image data into both the amplitude and phase components of light. By leveraging both amplitude and phase data in input and output components and facilitating cross-learning between different ONN architectures, the framework achieves substantial area reductions of 75.03% for fully connected neural networks (FCNN) and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as confirmed by experimental results."
        ],
        [
            "Deep learning tasks can be substantially sped up by optical neural networks (ONNs), which boast exceptional speed, high processing capacity, and low energy consumption. However, traditional ONNs have a significant limitation: they only take into account the amplitude of light at the input and output, overlooking the valuable computational information contained in the phase of the light signal. This study introduces OplixNet, an innovative approach that shrinks ONN sizes by encoding input image data into both the amplitude and phase components of light. By harnessing both amplitude and phase data in input and output components and enabling knowledge sharing between different ONN architectures, the framework achieves significant area reductions of 75.03% for fully connected neural networks (FCNN) and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as demonstrated by experimental results."
        ],
        [
            "Optical neural networks (ONNs) offer remarkable advantages in terms of speed, processing capacity, and energy efficiency, making them an attractive solution for accelerating deep learning tasks. However, conventional ONNs have a major drawback: they only consider the amplitude of light at the input and output, neglecting the valuable computational information present in the phase of the light signal. This study presents OplixNet, a groundbreaking approach that reduces ONN sizes by encoding input image data into both the amplitude and phase components of light. By leveraging both amplitude and phase data in input and output components and facilitating knowledge transfer between different ONN architectures, the framework achieves substantial area reductions of 75.03% for fully connected neural networks (FCNN) and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as confirmed by experimental results."
        ],
        [
            "ONNs boast exceptional benefits in speed, processing power, and energy efficiency, rendering them an appealing solution for expediting deep learning tasks. Nevertheless, traditional ONNs have a significant limitation: they solely consider the amplitude of light at the input and output, overlooking the valuable computational information inherent in the light signal's phase. This study introduces OplixNet, a pioneering approach that shrinks ONN sizes by encoding input image data into both the amplitude and phase components of light. By harnessing both amplitude and phase data in input and output components and facilitating knowledge transfer between different ONN architectures, the framework achieves significant area reductions of 75.03% for FCNN and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as validated by experimental results."
        ],
        [
            "ONNs offer outstanding advantages in terms of speed, processing capacity, and energy efficiency, making them an attractive option for accelerating deep learning tasks. However, traditional ONNs have a major drawback: they only take into account the intensity of light at the input and output, neglecting the valuable computational information contained in the phase of the light signal. This study presents OplixNet, a groundbreaking approach that reduces the size of ONNs by encoding input image data into both the intensity and phase components of light. By utilizing both intensity and phase data in input and output components and enabling knowledge sharing between different ONN architectures, the framework achieves substantial area reductions of 75.03% for FCNN and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as confirmed by experimental results."
        ],
        [
            "Optical neural networks (ONNs) boast exceptional benefits in terms of processing speed, capacity, and energy consumption, making them a compelling choice for expediting deep learning tasks. Nonetheless, conventional ONNs have a significant limitation: they solely consider the light intensity at the input and output, overlooking the valuable computational information embedded in the light signal's phase. This study introduces OplixNet, a pioneering approach that miniaturizes ONNs by encoding input image data into both the intensity and phase components of light. By leveraging both intensity and phase data in input and output components and facilitating knowledge sharing between different ONN architectures, the framework achieves significant area reductions of 75.03% for FCNN and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as validated by experimental results."
        ],
        [
            "Optical neural networks (ONNs) offer remarkable advantages in processing speed, capacity, and energy efficiency, making them an attractive option for accelerating deep learning tasks. However, traditional ONNs have a major shortcoming: they only take into account the light intensity at the input and output, neglecting the valuable computational information contained in the phase of the light signal. This research presents OplixNet, a groundbreaking approach that shrinks ONNs by encoding input image data into both the intensity and phase components of light. By harnessing both intensity and phase data in input and output components and enabling knowledge sharing between different ONN architectures, the framework achieves substantial area reductions of 75.03% for FCNN and 74.88% for ResNet-32, with negligible accuracy losses of 0.33% and 2.38%, respectively, as confirmed by experimental results."
        ],
        [
            "Optical neural networks (ONNs) possess significant benefits in terms of processing speed, capacity, and energy efficiency, rendering them a promising solution for expediting deep learning tasks. Nonetheless, conventional ONNs suffer from a major limitation: they solely consider the light intensity at the input and output, overlooking the valuable computational information embedded in the light signal's phase. This study introduces OplixNet, a pioneering approach that miniaturizes ONNs by encoding input image data into both the intensity and phase components of light. By leveraging both intensity and phase data in input and output components and facilitating knowledge sharing between different ONN architectures, the framework achieves considerable area reductions of 75.03% for FCNN and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as validated by experimental results."
        ],
        [
            "ONNs boast impressive advantages in terms of speed, capacity, and energy efficiency, making them a highly promising solution for accelerating deep learning tasks. However, traditional ONNs have a significant shortcoming: they only take into account the intensity of light at the input and output, neglecting the valuable computational data encoded in the light signal's phase. This study presents OplixNet, a groundbreaking approach that miniaturizes ONNs by encoding input image data into both the intensity and phase aspects of light. By harnessing both intensity and phase data in input and output components and enabling knowledge transfer between different ONN architectures, the framework achieves substantial area reductions of 75.03% for FCNN and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as confirmed by experimental results."
        ],
        [
            "Optical neural networks (ONNs) offer remarkable benefits in terms of processing speed, data capacity, and energy consumption, making them a highly promising solution for expediting deep learning tasks. However, a significant limitation of traditional ONNs is that they solely consider the intensity of light at the input and output, overlooking the valuable computational information encoded in the phase of the light signal. This study introduces OplixNet, a pioneering approach that miniaturizes ONNs by encoding input image data into both the intensity and phase components of light. By leveraging both intensity and phase data in input and output components and facilitating knowledge sharing between different ONN architectures, the framework achieves significant area reductions of 75.03% for FCNN and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as validated by experimental results."
        ],
        [
            "ONNs boast impressive advantages in terms of speed, capacity, and energy efficiency, making them an extremely promising solution for accelerating deep learning tasks. Nevertheless, conventional ONNs have a major limitation in that they only take into account the intensity of light at the input and output, neglecting the valuable computational information embedded in the light signal's phase. This study presents OplixNet, a groundbreaking approach that miniaturizes ONNs by encoding input image data into both the intensity and phase aspects of light. By harnessing both intensity and phase data in input and output components and enabling knowledge sharing between different ONN architectures, the framework achieves substantial area reductions of 75.03% for FCNN and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as confirmed by experimental results."
        ],
        [
            "Optical neural networks (ONNs) offer remarkable benefits in terms of processing speed, data capacity, and energy consumption, making them a highly promising solution for expediting deep learning tasks. However, traditional ONNs have a significant drawback: they only consider the intensity of light at the input and output, overlooking the valuable computational information contained in the light signal's phase. This study introduces OplixNet, a pioneering approach that miniaturizes ONNs by encoding input image data into both the intensity and phase components of light. By leveraging both intensity and phase data in input and output components and facilitating knowledge sharing between different ONN architectures, the framework achieves significant area reductions of 75.03% for FCNN and 74.88% for ResNet-32, with negligible accuracy losses of 0.33% and 2.38%, respectively, as validated by experimental results."
        ],
        [
            "ONNs boast impressive advantages in terms of processing speed, data capacity, and energy efficiency, rendering them a highly promising solution for accelerating deep learning tasks. Nevertheless, conventional ONNs have a major limitation: they solely focus on the intensity of light at the input and output, neglecting the valuable computational information embedded in the light signal's phase. This study presents OplixNet, a groundbreaking approach that miniaturizes ONNs by encoding input image data into both the intensity and phase components of light. By harnessing both intensity and phase data in input and output components and enabling knowledge sharing between different ONN architectures, the framework achieves substantial area reductions of 75.03% for FCNN and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as confirmed by experimental results."
        ],
        [
            "Optical Neural Networks (ONNs) offer significant benefits in terms of processing speed, data capacity, and energy efficiency, making them a highly promising solution for deep learning acceleration. However, traditional ONNs have a major drawback: they only consider the intensity of light at the input and output, overlooking the valuable computational information contained in the phase of the light signal. This study introduces OplixNet, a pioneering approach that miniaturizes ONNs by encoding input image data into both the intensity and phase components of light. By leveraging both intensity and phase data in input and output components and facilitating knowledge sharing between different ONN architectures, the framework achieves significant area reductions of 75.03% for FCNN and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as demonstrated by experimental results."
        ],
        [
            "Optical Neural Networks (ONNs) hold great promise for accelerating deep learning due to their advantages in processing speed, data capacity, and energy efficiency. However, conventional ONNs have a significant limitation: they only utilize the intensity of light at the input and output, neglecting the valuable computational information contained in the phase of the light signal. This study presents OplixNet, a groundbreaking approach that miniaturizes ONNs by encoding input image data into both the intensity and phase components of light. By harnessing both intensity and phase data in input and output components and enabling knowledge sharing between different ONN architectures, the framework achieves substantial area reductions of 75.03% for FCNN and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as demonstrated by experimental results."
        ],
        [
            "Deep learning can be significantly accelerated by Optical Neural Networks (ONNs) due to their superior speed, data capacity, and energy efficiency. Nevertheless, traditional ONNs have a major drawback: they only exploit the intensity of light at the input and output, overlooking the valuable computational information embedded in the light signal's phase. This research introduces OplixNet, a pioneering approach that revolutionizes ONNs by encoding input image data into both the intensity and phase components of light. By leveraging both intensity and phase data in input and output components and facilitating knowledge sharing between different ONN architectures, the framework achieves remarkable area reductions of 75.03% for FCNN and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as demonstrated by experimental results."
        ],
        [
            "The speed, capacity, and energy efficiency of Optical Neural Networks (ONNs) make them a powerful tool for accelerating deep learning. However, conventional ONNs have a significant limitation: they only utilize the intensity of light at the input and output, neglecting the valuable computational information contained in the phase of the light signal. This study presents OplixNet, a groundbreaking approach that transforms ONNs by encoding input image data into both the intensity and phase components of light. By harnessing both intensity and phase data in input and output components and enabling knowledge sharing between different ONN architectures, the framework achieves substantial area reductions of 75.03% for FCNN and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as demonstrated by experimental results."
        ],
        [
            "The exceptional speed, capacity, and energy efficiency of Optical Neural Networks (ONNs) make them an attractive option for boosting deep learning performance. Nevertheless, traditional ONNs have a major drawback: they solely rely on the light intensity at the input and output, overlooking the valuable computational information embedded in the light signal's phase. This research introduces OplixNet, a pioneering approach that revolutionizes ONNs by encoding input image data into both the intensity and phase aspects of light. By leveraging both intensity and phase data in input and output components and facilitating knowledge sharing between different ONN architectures, the framework achieves significant area reductions of 75.03% for FCNN and 74.88% for ResNet-32, accompanied by minimal accuracy losses of 0.33% and 2.38%, respectively, as validated by experimental results."
        ],
        [
            "The remarkable speed, capacity, and energy efficiency of Optical Neural Networks (ONNs) make them a promising solution for enhancing deep learning performance. However, conventional ONNs have a significant limitation: they only utilize the light intensity at the input and output, neglecting the valuable computational information contained in the light signal's phase. This study presents OplixNet, a groundbreaking approach that transforms ONNs by encoding input image data into both the intensity and phase components of light. By harnessing both intensity and phase data in input and output components and enabling knowledge sharing between different ONN architectures, the framework achieves substantial area reductions of 75.03% for FCNN and 74.88% for ResNet-32, accompanied by minimal accuracy losses of 0.33% and 2.38%, respectively, as confirmed by experimental results."
        ],
        [
            "The exceptional speed, capacity, and energy efficiency of Optical Neural Networks (ONNs) position them as a promising solution for boosting deep learning performance. However, traditional ONNs have a major drawback: they only leverage the light intensity at the input and output, overlooking the valuable computational information embedded in the light signal's phase. This research introduces OplixNet, a pioneering approach that revolutionizes ONNs by encoding input image data into both the intensity and phase components of light. By exploiting both intensity and phase data in input and output components and facilitating knowledge sharing between different ONN architectures, the framework achieves significant area reductions of 75.03% for FCNN and 74.88% for ResNet-32, accompanied by minimal accuracy losses of 0.33% and 2.38%, respectively, as validated by experimental results."
        ],
        [
            "The remarkable speed, capacity, and energy efficiency of Optical Neural Networks (ONNs) make them an attractive solution for enhancing deep learning performance. However, a significant limitation of traditional ONNs is that they only utilize the light intensity at the input and output, neglecting the valuable computational information contained in the light signal's phase. This study presents OplixNet, a groundbreaking approach that transforms ONNs by encoding input image data into both the intensity and phase components of light. By harnessing both intensity and phase data in input and output components and enabling knowledge sharing between different ONN architectures, the framework achieves substantial area reductions of 75.03% for FCNN and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as confirmed by experimental results."
        ],
        [
            "The exceptional speed, capacity, and energy efficiency of Optical Neural Networks (ONNs) render them a compelling solution for boosting deep learning performance. However, traditional ONNs have a significant shortcoming in that they only leverage the light intensity at the input and output, overlooking the valuable computational information embedded in the light signal's phase. This study introduces OplixNet, a pioneering approach that revolutionizes ONNs by encoding input image data into both the intensity and phase components of light. By exploiting both intensity and phase data in input and output components and facilitating knowledge sharing between different ONN architectures, the framework achieves significant area reductions of 75.03% for FCNN and 74.88% for ResNet-32, with negligible accuracy losses of 0.33% and 2.38%, respectively, as validated by experimental results."
        ],
        [
            "The remarkable speed, capacity, and energy efficiency of Optical Neural Networks (ONNs) make them an attractive option for enhancing deep learning performance. Nevertheless, conventional ONNs have a major limitation in that they solely utilize the light intensity at the input and output, neglecting the valuable computational information encoded in the light signal's phase. This study presents OplixNet, a groundbreaking approach that transforms ONNs by encoding input image data into both the intensity and phase aspects of light. By harnessing both intensity and phase data in input and output components and enabling knowledge sharing between different ONN architectures, the framework achieves substantial area reductions of 75.03% for FCNN and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as confirmed by experimental results."
        ],
        [
            "The exceptional performance, capacity, and energy efficiency of Optical Neural Networks (ONNs) make them a promising solution for boosting deep learning capabilities. However, traditional ONNs have a significant shortcoming in that they only leverage the light intensity at the input and output, overlooking the valuable computational information embedded in the light signal's phase. This research introduces OplixNet, a pioneering approach that revolutionizes ONNs by encoding input image data into both the intensity and phase components of light. By utilizing both intensity and phase data in input and output components and facilitating knowledge sharing between different ONN architectures, the framework achieves significant area reductions of 75.03% for FCNN and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as validated by experimental results."
        ],
        [
            "The outstanding capabilities of Optical Neural Networks (ONNs) in terms of performance, capacity, and energy efficiency make them an attractive solution for enhancing deep learning abilities. However, conventional ONNs have a major limitation in that they only exploit the light intensity at the input and output, neglecting the valuable computational information inherent in the phase of the light signal. This study presents OplixNet, a groundbreaking approach that transforms ONNs by encoding input image data into both the intensity and phase aspects of light. By harnessing both intensity and phase data in input and output components and enabling knowledge sharing between different ONN architectures, the framework achieves substantial area reductions of 75.03% for FCNN and 74.88% for ResNet-32, with negligible accuracy losses of 0.33% and 2.38%, respectively, as confirmed by experimental results."
        ],
        [
            "The exceptional performance, capacity, and energy efficiency of Optical Neural Networks (ONNs) make them a promising solution for advancing deep learning capabilities. However, traditional ONNs have a significant shortcoming in that they solely utilize the light intensity at the input and output, overlooking the valuable computational information embedded in the light signal's phase. This research introduces OplixNet, a pioneering approach that revolutionizes ONNs by encoding input image data into both the intensity and phase aspects of light. By leveraging both intensity and phase data in input and output components and facilitating knowledge sharing between different ONN architectures, the framework achieves significant area reductions of 75.03% for FCNN and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as verified by experimental results."
        ],
        [
            "The remarkable attributes of Optical Neural Networks (ONNs), including their exceptional performance, capacity, and energy efficiency, make them an attractive solution for enhancing deep learning capabilities. Nevertheless, conventional ONNs have a notable limitation in that they exclusively rely on the light intensity at the input and output, neglecting the valuable computational information inherent in the phase of the light signal. This study presents OplixNet, a groundbreaking approach that transforms ONNs by encoding input image data into both the intensity and phase components of light. By harnessing both intensity and phase data in input and output components and enabling knowledge sharing between different ONN architectures, the framework achieves substantial area reductions of 75.03% for FCNN and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as confirmed by experimental results."
        ],
        [
            "The impressive characteristics of Optical Neural Networks, such as their outstanding performance, capacity, and energy efficiency, render them a promising solution for advancing deep learning capabilities. However, traditional ONNs have a significant shortcoming in that they solely rely on the intensity of light at the input and output, overlooking the valuable computational information embedded in the phase of the light signal. This research introduces OplixNet, a pioneering approach that revolutionizes ONNs by encoding input image data into both the intensity and phase components of light. By leveraging both intensity and phase data in input and output components and facilitating knowledge sharing between different ONN architectures, the framework achieves significant area reductions of 75.03% for FCNN and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as validated by experimental results."
        ],
        [
            "The exceptional properties of Optical Neural Networks, including their remarkable performance, capacity, and energy efficiency, make them a highly promising solution for enhancing deep learning capabilities. However, a major limitation of traditional ONNs is that they only utilize the intensity of light at the input and output, neglecting the valuable computational information contained in the light signal's phase. This study presents OplixNet, a groundbreaking approach that transforms ONNs by encoding input image data into both the intensity and phase components of light. By harnessing both intensity and phase data in input and output components and enabling knowledge sharing between different ONN architectures, the framework achieves substantial area reductions of 75.03% for FCNN and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as confirmed by experimental results."
        ],
        [
            "The unique characteristics of Optical Neural Networks, such as their outstanding performance, capacity, and energy efficiency, make them an extremely promising approach to advancing deep learning capabilities. However, a significant drawback of conventional ONNs is that they only leverage the intensity of light at the input and output, overlooking the valuable computational information contained in the phase of the light signal. This study introduces OplixNet, a pioneering approach that revolutionizes ONNs by encoding input image data into both the intensity and phase components of light. By leveraging both intensity and phase data in input and output components and facilitating knowledge sharing between different ONN architectures, the framework achieves significant area reductions of 75.03% for FCNN and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as confirmed by experimental results."
        ],
        [
            "The exceptional attributes of Optical Neural Networks, including their remarkable performance, capacity, and energy efficiency, position them as a highly promising strategy for enhancing deep learning capabilities. Nevertheless, a major limitation of traditional ONNs is that they solely utilize the intensity of light at the input and output, neglecting the valuable computational information inherent in the phase of the light signal. This study presents OplixNet, a groundbreaking approach that transforms ONNs by encoding input image data into both the intensity and phase aspects of light. By harnessing both intensity and phase data in input and output components and facilitating knowledge exchange between different ONN architectures, the framework achieves substantial area reductions of 75.03% for FCNN and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as validated by experimental results."
        ],
        [
            "The outstanding characteristics of Optical Neural Networks, including their impressive processing power, capacity, and energy efficiency, make them an extremely promising approach to advancing deep learning capabilities. However, traditional ONNs have a significant limitation in that they only utilize the brightness of light at the input and output, overlooking the valuable computational information contained in the light signal's phase. This study introduces OplixNet, a pioneering approach that revolutionizes ONNs by encoding input image data into both the brightness and phase aspects of light. By leveraging both brightness and phase data in input and output components and enabling knowledge sharing between different ONN architectures, the framework achieves significant area reductions of 75.03% for FCNN and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as confirmed by experimental results."
        ],
        [
            "The exceptional attributes of Optical Neural Networks, notably their remarkable processing capacity, impressive scalability, and energy efficiency, render them a highly promising avenue for enhancing deep learning capabilities. However, conventional ONNs are limited by their exclusive reliance on the intensity of light at the input and output, neglecting the valuable computational information embedded in the phase of the light signal. This study presents OplixNet, a groundbreaking approach that transforms ONNs by encoding input image data into both the intensity and phase components of light. By harnessing both intensity and phase data in input and output components and facilitating knowledge transfer between different ONN architectures, the framework achieves substantial area reductions of 75.03% for FCNN and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as validated by experimental results."
        ],
        [
            "The outstanding features of Optical Neural Networks, including their extraordinary processing power, scalability, and energy efficiency, make them a highly promising approach to advancing deep learning capabilities. However, traditional ONNs have a significant limitation in that they only utilize the intensity of light at the input and output, overlooking the valuable computational information contained in the phase of the light signal. This research introduces OplixNet, a pioneering method that revolutionizes ONNs by encoding input image data into both the intensity and phase components of light. By leveraging both intensity and phase data in input and output components and enabling knowledge sharing between different ONN architectures, the framework achieves significant area reductions of 75.03% for FCNN and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as confirmed by experimental results."
        ],
        [
            "The exceptional characteristics of Optical Neural Networks, including their remarkable processing capacity, flexibility, and low energy consumption, make them an extremely promising strategy for enhancing deep learning abilities. However, conventional ONNs have a notable constraint in that they solely rely on the intensity of light at the input and output, neglecting the valuable computational data embedded in the phase of the light signal. This study presents OplixNet, a groundbreaking approach that transforms ONNs by encoding input image data into both the intensity and phase aspects of light. By harnessing both intensity and phase data in input and output components and facilitating knowledge exchange between different ONN architectures, the framework achieves substantial area reductions of 75.03% for FCNN and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as verified by experimental results."
        ],
        [
            "The outstanding features of Optical Neural Networks, including their remarkable ability to process information, adaptability, and low power requirements, make them a highly promising approach to improving deep learning capabilities. However, traditional ONNs have a significant limitation in that they only utilize the intensity of light at the input and output, overlooking the valuable computational information contained in the light signal's phase. This research introduces OplixNet, a pioneering method that revolutionizes ONNs by encoding input image data into both the intensity and phase components of light. By leveraging both intensity and phase data in input and output components and enabling knowledge sharing between different ONN architectures, the framework achieves significant area reductions of 75.03% for FCNN and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as confirmed by experimental results."
        ],
        [
            "The exceptional characteristics of Optical Neural Networks, including their impressive information processing capabilities, adaptability, and low energy consumption, make them an extremely promising solution for enhancing deep learning abilities. However, conventional ONNs have a notable shortcoming: they only exploit the intensity of light at the input and output, neglecting the valuable computational information embedded in the light signal's phase. This study presents OplixNet, a groundbreaking approach that transforms ONNs by encoding input image data into both the intensity and phase components of light. By harnessing both intensity and phase data in input and output components and facilitating knowledge sharing between different ONN architectures, the framework achieves substantial area reductions of 75.03% for FCNN and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as validated by experimental results."
        ],
        [
            "The unique features of Optical Neural Networks, including their remarkable capacity for processing information, adaptability, and low energy usage, render them an extremely promising solution for advancing deep learning capabilities. However, traditional ONNs have a significant limitation: they solely utilize the intensity of light at the input and output, overlooking the valuable computational information inherent in the phase of the light signal. This study introduces OplixNet, a pioneering approach that revolutionizes ONNs by encoding input image data into both the intensity and phase components of light. By leveraging both intensity and phase data in input and output components and enabling knowledge sharing between different ONN architectures, the framework achieves significant reductions in area of 75.03% for FCNN and 74.88% for ResNet-32, with minimal losses in accuracy of 0.33% and 2.38%, respectively, as confirmed by experimental results."
        ],
        [
            "The distinctive characteristics of Optical Neural Networks, such as their exceptional information processing abilities, flexibility, and low power consumption, make them a highly promising approach for enhancing deep learning capabilities. However, conventional ONNs have a notable constraint: they only utilize the brightness of light at the input and output, neglecting the valuable computational information contained in the light signal's phase. This study presents OplixNet, a groundbreaking approach that transforms ONNs by encoding input image data into both the brightness and phase aspects of light. By harnessing both brightness and phase data in input and output components and facilitating knowledge sharing between different ONN architectures, the framework achieves substantial area reductions of 75.03% for FCNN and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as validated by experimental results."
        ],
        [
            "The unique features of Optical Neural Networks, including their remarkable data processing capabilities, adaptability, and low energy requirements, make them an extremely promising solution for advancing deep learning capabilities. However, traditional ONNs have a significant limitation: they only leverage the intensity of light at the input and output, overlooking the valuable computational data embedded in the light signal's phase. This study introduces OplixNet, a pioneering approach that revolutionizes ONNs by encoding input image data into both the intensity and phase components of light. By utilizing both intensity and phase data in input and output components and enabling knowledge sharing between different ONN architectures, the framework achieves significant area reductions of 75.03% for FCNN and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as confirmed by experimental results."
        ],
        [
            "The exceptional characteristics of Optical Neural Networks, such as their impressive data processing abilities, flexibility, and low power consumption, render them a highly promising solution for enhancing deep learning capabilities. However, conventional ONNs have a significant constraint: they only utilize the intensity of light at the input and output, neglecting the valuable computational information embedded in the phase of the light signal. This study presents OplixNet, a groundbreaking approach that transforms ONNs by encoding input image data into both the intensity and phase aspects of light. By harnessing both intensity and phase data in input and output components and facilitating knowledge sharing between different ONN architectures, the framework achieves substantial area reductions of 75.03% for FCNN and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as validated by experimental results."
        ],
        [
            "The remarkable properties of Optical Neural Networks, including their extraordinary data processing capabilities, adaptability, and low energy consumption, make them a highly attractive solution for advancing deep learning capabilities. However, traditional ONNs have a significant limitation: they only exploit the intensity of light at the input and output, overlooking the valuable computational information contained in the light signal's phase. This study introduces OplixNet, a pioneering approach that revolutionizes ONNs by encoding input image data into both the intensity and phase components of light. By leveraging both intensity and phase data in input and output components and enabling knowledge sharing between different ONN architectures, the framework achieves significant area reductions of 75.03% for FCNN and 74.88% for ResNet-32, with minimal accuracy losses of 0.33% and 2.38%, respectively, as confirmed by experimental results."
        ]
    ]
}