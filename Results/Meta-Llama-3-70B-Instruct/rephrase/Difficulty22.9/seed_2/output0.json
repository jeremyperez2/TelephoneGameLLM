{
    "adjacency_matrix": [
        [
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0
        ]
    ],
    "prompt_init": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "prompt_update": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "personality_list": [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        ""
    ],
    "format_prompt": [
        ""
    ],
    "initial_story": "musculoskeletal diseases and cognitive impairments in patients lead todifficulties in movement as well as negative effects on their psychologicalhealth. clinical gait analysis, a vital tool for early diagnosis and treatment,traditionally relies on expensive optical motion capture systems. recentadvances in computer vision and deep learning have opened the door to moreaccessible and cost-effective alternatives. this paper introduces a novelspatio-temporal transformer network to estimate critical gait parameters fromrgb videos captured by a single-view camera. empirical evaluations on a publicdataset of cerebral palsy patients indicate that the proposed frameworksurpasses current state-of-the-art approaches and show significant improvementsin predicting general gait parameters (including walking speed, gait deviationindex - gdi, and knee flexion angle at maximum extension), while utilizingfewer parameters and alleviating the need for manual feature extraction. ",
    "stories": [
        [
            "Diseases affecting the muscles and bones, as well as cognitive impairments, can hinder patients' mobility and have detrimental effects on their mental wellbeing. Clinical gait analysis is crucial for early detection and treatment, but traditionally relies on costly optical motion capture systems. However, breakthroughs in computer vision and deep learning have paved the way for more affordable and accessible alternatives. This paper presents a novel spatio-temporal transformer network that can estimate key gait parameters from RGB videos captured by a single camera. The proposed framework has been evaluated on a publicly available dataset of cerebral palsy patients, outperforming current state-of-the-art approaches and demonstrating significant improvements in predicting general gait parameters, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Musculoskeletal diseases and cognitive impairments can significantly impede patient mobility and negatively impact their mental health. Early identification and intervention through clinical gait analysis are essential, but conventional methods relying on expensive motion capture systems have limitations. Recent advances in computer vision and deep learning have opened up opportunities for more affordable and accessible solutions. This study introduces a novel spatio-temporal transformer network capable of extracting key gait metrics from single-camera RGB videos. The proposed model has been tested on a publicly available dataset of cerebral palsy patients, surpassing existing state-of-the-art methods and showing substantial improvements in predicting general gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating manual feature extraction."
        ],
        [
            "Mobility and mental well-being can be severely compromised by musculoskeletal diseases and cognitive impairments. Identifying these issues early and taking prompt action through gait analysis is crucial, but traditional methods that rely on costly motion capture systems have their drawbacks. Fortunately, breakthroughs in computer vision and deep learning have paved the way for more affordable and accessible alternatives. This study presents a novel spatio-temporal transformer network that can extract essential gait metrics from single-camera RGB videos. When tested on a publicly available dataset of patients with cerebral palsy, the proposed model outperformed existing state-of-the-art methods, achieving significant improvements in predicting key gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Musculoskeletal diseases and cognitive impairments can have a devastating impact on a person's mobility and mental health. Early detection and intervention through gait analysis are essential, but traditional approaches that rely on expensive motion capture technology have limitations. However, recent advances in computer vision and deep learning have made it possible to develop more cost-effective and accessible solutions. This study introduces a novel spatio-temporal transformer network that can derive critical gait metrics from single-camera RGB videos. When evaluated on a publicly available dataset of patients with cerebral palsy, the proposed model surpassed existing state-of-the-art methods, achieving substantial improvements in predicting key gait metrics such as walking speed, gait deviation index, and knee flexion angle, all while requiring fewer parameters and eliminating manual feature extraction."
        ],
        [
            "Musculoskeletal disorders and cognitive impairments can severely affect an individual's physical mobility and mental wellbeing. Identifying these issues early on and taking prompt action is crucial, with gait analysis playing a vital role in this process. However, conventional methods that rely on costly motion capture systems have their limitations. Fortunately, breakthroughs in computer vision and deep learning have paved the way for the development of more affordable and widely accessible alternatives. This research presents a novel spatio-temporal transformer network capable of extracting essential gait metrics from single-camera RGB video footage. In evaluations using a publicly available dataset of patients with cerebral palsy, the proposed model outperformed existing state-of-the-art approaches, achieving significant improvements in predicting critical gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Mobility and mental health can be significantly impacted by musculoskeletal disorders and cognitive impairments, making early detection and intervention essential. Gait analysis is a crucial component of this process, but traditional methods relying on expensive motion capture systems have limitations. Fortunately, advances in computer vision and deep learning have enabled the development of more affordable and accessible alternatives. This study introduces a novel spatio-temporal transformer network that can extract key gait metrics from single-camera RGB video footage. In tests using a publicly available dataset of patients with cerebral palsy, the proposed model surpassed existing state-of-the-art approaches, achieving significant improvements in predicting critical gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating manual feature extraction."
        ],
        [
            "Musculoskeletal disorders and cognitive impairments can have a profound effect on mobility and mental wellbeing, highlighting the importance of early identification and treatment. A vital part of this process is gait analysis, but conventional methods that rely on costly motion capture systems have their drawbacks. However, recent breakthroughs in computer vision and deep learning have paved the way for more affordable and widely available solutions. This research presents a new spatio-temporal transformer network capable of extracting crucial gait metrics from single-camera RGB video recordings. When tested on a publicly available dataset of patients with cerebral palsy, the proposed model outperformed existing top-performing approaches, achieving notable improvements in predicting key gait metrics such as walking speed, gait deviation index, and knee flexion angle, all while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Mobility and mental wellbeing can be significantly impacted by musculoskeletal disorders and cognitive impairments, emphasizing the need for prompt diagnosis and intervention. A crucial step in this process involves gait analysis, but traditional methods relying on expensive motion capture systems have limitations. Fortunately, advancements in computer vision and deep learning have opened up opportunities for more accessible and cost-effective alternatives. This study introduces a novel spatio-temporal transformer network that can extract essential gait metrics from single-camera RGB video recordings. When evaluated on a publicly available dataset of cerebral palsy patients, the proposed model surpassed existing state-of-the-art approaches, achieving substantial improvements in predicting key gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating manual feature extraction."
        ],
        [
            "Musculoskeletal disorders and cognitive impairments can have a profound effect on mobility and mental wellbeing, highlighting the importance of early identification and treatment. A key part of this process is gait analysis, but conventional methods that rely on costly motion capture systems have their drawbacks. However, recent breakthroughs in computer vision and deep learning have paved the way for more affordable and accessible solutions. This study presents a new spatio-temporal transformer network capable of extracting vital gait metrics from single-camera RGB video recordings. When tested on a publicly available dataset of patients with cerebral palsy, the proposed model outperformed existing state-of-the-art approaches, achieving significant improvements in predicting key gait metrics, including walking speed, gait deviation index, and knee flexion angle, while using fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Mobility and mental wellbeing can be severely impacted by musculoskeletal disorders and cognitive impairments, emphasizing the need for prompt detection and intervention. Gait analysis plays a crucial role in this process, but traditional methods that utilize expensive motion capture systems have limitations. Fortunately, advances in computer vision and deep learning have made it possible to develop more affordable and accessible alternatives. This study introduces a novel spatio-temporal transformer network that can extract essential gait metrics from single-camera RGB video recordings. When evaluated on a publicly available dataset of patients with cerebral palsy, the proposed model surpassed existing state-of-the-art approaches, achieving notable improvements in predicting key gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating manual feature extraction."
        ],
        [
            "Musculoskeletal disorders and cognitive impairments can have a profound impact on mobility and mental wellbeing, highlighting the importance of early identification and treatment. Gait analysis is a vital component of this process, but conventional methods relying on costly motion capture systems have their drawbacks. However, recent breakthroughs in computer vision and deep learning have enabled the development of more cost-effective and widely available alternatives. This study presents a novel spatio-temporal transformer network capable of extracting vital gait metrics from single-camera RGB video recordings. When tested on a publicly available dataset of patients with cerebral palsy, the proposed model outperformed existing state-of-the-art approaches, achieving significant improvements in predicting key gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating manual feature extraction."
        ],
        [
            "The effects of musculoskeletal disorders and cognitive impairments on mobility and mental health can be far-reaching, underscoring the need for prompt diagnosis and intervention. A crucial step in this process is gait analysis, but traditional methods that rely on expensive motion capture systems have limitations. Fortunately, advances in computer vision and deep learning have paved the way for more accessible and affordable alternatives. This study introduces a novel spatio-temporal transformer network that can extract essential gait metrics from single-camera RGB video recordings. When evaluated on a publicly available dataset of patients with cerebral palsy, the proposed model surpassed existing state-of-the-art approaches, achieving notable improvements in predicting key gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating manual feature extraction."
        ],
        [
            "The profound impact of musculoskeletal disorders and cognitive impairments on mobility and mental wellbeing highlights the importance of timely identification and treatment. A vital component of this process is the analysis of an individual's gait, but conventional methods relying on costly motion capture technology have significant limitations. However, recent breakthroughs in computer vision and deep learning have enabled the development of more accessible and cost-effective alternatives. This research presents a novel spatio-temporal transformer network capable of extracting crucial gait metrics from single-camera RGB video recordings. When tested on a publicly available dataset of patients with cerebral palsy, the proposed model outperformed existing state-of-the-art approaches, achieving significant improvements in predicting key gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "The significant influence of musculoskeletal disorders and cognitive impairments on mobility and mental health underscores the need for early detection and intervention. A crucial step in this process is the assessment of an individual's gait pattern, but traditional methods that rely on expensive motion capture technology have notable constraints. Nevertheless, advances in computer vision and deep learning have paved the way for the development of more affordable and accessible alternatives. This study introduces a novel spatio-temporal transformer network that can extract essential gait metrics from single-camera RGB video recordings. When evaluated on a publicly available dataset of patients with cerebral palsy, the proposed model surpassed existing state-of-the-art approaches, achieving substantial improvements in predicting key gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "The importance of identifying musculoskeletal disorders and cognitive impairments early on, due to their significant impact on mobility and mental wellbeing, is highlighted. A vital part of this process involves analyzing an individual's walking pattern, but conventional methods that rely on costly motion capture systems have several limitations. However, recent breakthroughs in computer vision and deep learning have enabled the creation of more affordable and widely accessible alternatives. This research presents a new spatio-temporal transformer network capable of extracting crucial gait metrics from single-camera RGB video recordings. When tested on a publicly available dataset of patients with cerebral palsy, the proposed model outperformed existing state-of-the-art approaches, achieving significant improvements in predicting key gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Early detection of musculoskeletal disorders and cognitive impairments is crucial, given their substantial influence on mobility and mental health. A key aspect of this process is the analysis of an individual's gait, but traditional methods relying on expensive motion capture systems have several drawbacks. Fortunately, advancements in computer vision and deep learning have made it possible to develop more affordable and widely available alternatives. This study introduces a novel spatio-temporal transformer network that can extract essential gait metrics from single-camera RGB video recordings. When evaluated using a publicly available dataset of patients with cerebral palsy, the proposed model surpassed existing state-of-the-art approaches, achieving notable improvements in predicting crucial gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating manual feature extraction."
        ],
        [
            "Identifying musculoskeletal disorders and cognitive impairments at an early stage is vital, as they significantly impact both physical mobility and mental wellbeing. A crucial step in this process involves analyzing a person's gait pattern, but conventional methods that rely on costly motion capture systems have several limitations. However, recent breakthroughs in computer vision and deep learning have enabled the development of more cost-effective and accessible solutions. This research presents a novel spatio-temporal transformer network capable of extracting key gait metrics from single-camera RGB video recordings. When tested on a publicly available dataset of patients with cerebral palsy, the proposed model outperformed existing state-of-the-art approaches, achieving significant improvements in predicting vital gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Detecting musculoskeletal disorders and cognitive impairments at their onset is crucial, as they have a profound impact on both physical movement and mental health. A key part of this process is examining an individual's walking pattern, but traditional methods relying on expensive motion capture technology have several drawbacks. Fortunately, advances in computer vision and deep learning have paved the way for more affordable and accessible alternatives. This study introduces a novel spatio-temporal transformer network that can extract essential gait metrics from single-camera RGB video recordings. When tested on a publicly available dataset of cerebral palsy patients, the proposed model surpassed existing state-of-the-art approaches, achieving significant improvements in predicting vital gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating manual feature extraction."
        ],
        [
            "Identifying musculoskeletal disorders and cognitive impairments at an early stage is vital, as they significantly affect both physical mobility and mental wellbeing. A crucial aspect of this identification process involves analyzing an individual's gait pattern, but conventional methods that rely on costly motion capture technology have several limitations. However, recent breakthroughs in computer vision and deep learning have enabled the development of more cost-effective and accessible solutions. This study presents a novel spatio-temporal transformer network capable of extracting crucial gait metrics from single-camera RGB video recordings. When evaluated using a publicly available dataset of patients with cerebral palsy, the proposed model outperformed existing state-of-the-art approaches, achieving substantial improvements in predicting key gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating manual feature extraction."
        ],
        [
            "Early detection of musculoskeletal disorders and cognitive impairments is crucial, as they have a significant impact on both physical mobility and mental health. A key part of this detection process involves examining an individual's gait pattern, but traditional methods that rely on expensive motion capture technology have several drawbacks. However, recent advances in computer vision and deep learning have made it possible to develop more affordable and accessible alternatives. This study introduces a new spatio-temporal transformer network that can extract essential gait metrics from single-camera RGB video recordings. When tested using a publicly available dataset of patients with cerebral palsy, the proposed model outperformed existing state-of-the-art approaches, achieving significant improvements in predicting key gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating manual feature extraction."
        ],
        [
            "Identifying musculoskeletal disorders and cognitive impairments at an early stage is vital, given their substantial effects on both physical mobility and mental wellbeing. A crucial aspect of this identification process is analyzing an individual's walking pattern, but conventional methods relying on costly motion capture systems have several limitations. Nevertheless, breakthroughs in computer vision and deep learning have enabled the development of more cost-effective and accessible solutions. This research presents a novel spatio-temporal transformer network capable of extracting critical gait metrics from single-camera RGB video recordings. When evaluated using a publicly available dataset of cerebral palsy patients, the proposed model surpassed existing state-of-the-art approaches, achieving significant enhancements in predicting key gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating manual feature extraction."
        ],
        [
            "Detecting musculoskeletal disorders and cognitive impairments at an early stage is crucial, as they can significantly impact both physical mobility and mental health. A key part of this detection process involves examining an individual's gait, but traditional methods that rely on expensive motion capture systems have several drawbacks. However, advances in computer vision and deep learning have made it possible to develop more affordable and accessible alternatives. This study introduces a new spatio-temporal transformer network that can extract vital gait metrics from single-camera RGB video recordings. When tested using a publicly available dataset of patients with cerebral palsy, the proposed model outperformed existing state-of-the-art approaches, achieving significant improvements in predicting key gait metrics such as walking speed, gait deviation index, and knee flexion angle, all while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Identifying musculoskeletal disorders and cognitive impairments in their early stages is vital, as they can have a profound impact on both physical function and mental wellbeing. A crucial aspect of this identification process involves analyzing an individual's walking pattern, but traditional methods that rely on costly motion capture technology have several limitations. Fortunately, recent breakthroughs in computer vision and deep learning have enabled the development of more cost-effective and widely available alternatives. This research presents a novel spatio-temporal transformer network capable of extracting essential gait metrics from single-camera RGB video recordings. When evaluated using a publicly available dataset of patients with cerebral palsy, the proposed model surpassed existing state-of-the-art approaches, achieving notable improvements in predicting key gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Early detection of musculoskeletal disorders and cognitive impairments is critical, as they can significantly affect physical ability and mental health. A key part of this detection process involves examining an individual's gait, but traditional methods relying on expensive motion capture technology have several drawbacks. However, recent advancements in computer vision and deep learning have made it possible to develop more affordable and accessible alternatives. This study introduces a novel spatio-temporal transformer network that can extract crucial gait metrics from single-camera RGB video recordings. When tested using a publicly available dataset of patients with cerebral palsy, the proposed model outperformed existing state-of-the-art approaches, achieving significant improvements in predicting key gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating manual feature extraction."
        ],
        [
            "Identifying musculoskeletal disorders and cognitive impairments at an early stage is crucial, as they can have a profound impact on both physical function and mental wellbeing. Assessing an individual's gait is a vital component of this identification process, but conventional methods that rely on costly motion capture technology have several limitations. However, breakthroughs in computer vision and deep learning have enabled the development of more cost-effective and accessible solutions. This research presents a novel spatio-temporal transformer network capable of extracting essential gait metrics from single-camera RGB video recordings. When evaluated using a publicly available dataset of patients with cerebral palsy, the proposed model surpassed existing state-of-the-art approaches, achieving significant enhancements in predicting key gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating manual feature extraction."
        ],
        [
            "Early detection of musculoskeletal disorders and cognitive impairments is vital, as they can significantly affect physical ability and mental health. Evaluating an individual's gait pattern is a key part of this detection process, but traditional methods that rely on expensive motion capture systems have several drawbacks. Fortunately, advances in computer vision and deep learning have made it possible to develop more affordable and accessible alternatives. This study introduces a new spatio-temporal transformer network that can accurately extract important gait metrics from simple video recordings taken with a single RGB camera. When tested using a publicly available dataset of patients with cerebral palsy, the proposed model outperformed existing state-of-the-art approaches, achieving notable improvements in predicting crucial gait metrics such as walking speed, gait deviation index, and knee flexion angle, all while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Identifying musculoskeletal disorders and cognitive impairments at an early stage is crucial, as they can have a profound impact on both physical function and mental wellbeing. Assessing an individual's gait pattern is a crucial aspect of this identification process, but conventional methods that rely on costly motion capture technology have several limitations. However, recent breakthroughs in computer vision and deep learning have enabled the development of more cost-effective and widely accessible alternatives. This research presents a novel spatio-temporal transformer network capable of accurately extracting key gait metrics from simple video footage captured using a single RGB camera. When evaluated using a publicly available dataset of patients with cerebral palsy, the proposed model surpassed existing state-of-the-art approaches, achieving significant improvements in predicting critical gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Early detection of musculoskeletal disorders and cognitive impairments is vital, as they can significantly affect an individual's physical ability and mental health. Analyzing a person's walking pattern is essential to this detection process, but traditional methods that rely on expensive motion capture technology have limitations. Fortunately, advances in computer vision and deep learning have made it possible to develop more affordable and accessible alternatives. This study introduces a novel spatio-temporal transformer network that can accurately extract important gait metrics from simple video recordings taken with a single RGB camera. When tested using a publicly available dataset of patients with cerebral palsy, the proposed model outperformed existing state-of-the-art approaches, achieving significant improvements in predicting key gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating manual feature extraction."
        ],
        [
            "Identifying musculoskeletal disorders and cognitive impairments at an early stage is crucial, as they can have a profound impact on a person's physical function and mental wellbeing. A crucial step in this identification process is the analysis of an individual's gait pattern, but conventional methods relying on costly motion capture technology have their limitations. However, recent breakthroughs in computer vision and deep learning have paved the way for the development of more cost-effective and widely accessible solutions. This research presents a novel spatio-temporal transformer network capable of accurately extracting key gait metrics from simple video footage captured using a single RGB camera. When evaluated using a publicly available dataset of patients with cerebral palsy, the proposed model surpassed existing state-of-the-art approaches, achieving notable improvements in predicting critical gait metrics such as walking speed, gait deviation index, and knee flexion angle, all while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Early detection of musculoskeletal disorders and cognitive impairments is vital, as they can significantly affect an individual's physical abilities and mental health. A key aspect of this detection process involves examining a person's gait pattern, but traditional methods that rely on expensive motion capture technology have limitations. Fortunately, advances in computer vision and deep learning have made it possible to develop more affordable and widely available solutions. This research introduces a novel spatio-temporal transformer network that can accurately extract essential gait metrics from simple video recordings taken with a single RGB camera. When tested on a publicly available dataset of patients with cerebral palsy, the proposed model outperformed existing state-of-the-art approaches, achieving significant improvements in predicting crucial gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Identifying musculoskeletal disorders and cognitive impairments at an early stage is crucial, as they can have a profound impact on both physical capability and mental wellbeing. A crucial part of this identification process involves analyzing an individual's walking pattern, but conventional methods that rely on costly motion capture technology have their limitations. However, recent breakthroughs in computer vision and deep learning have paved the way for the development of more accessible and affordable solutions. This study presents a novel spatio-temporal transformer network that can precisely extract key gait metrics from simple video footage captured using a single RGB camera. When evaluated using a publicly available dataset of patients with cerebral palsy, the proposed model surpassed existing state-of-the-art approaches, achieving notable improvements in predicting vital gait metrics such as walking speed, gait deviation index, and knee flexion angle, all while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Early detection of musculoskeletal disorders and cognitive impairments is vital, as they can significantly affect physical function and mental health. A key aspect of this detection process involves examining an individual's gait pattern, but traditional methods relying on expensive motion capture technology have limitations. Fortunately, recent advances in computer vision and deep learning have made it possible to develop more accessible and cost-effective solutions. This study introduces a novel spatio-temporal transformer network capable of accurately extracting essential gait metrics from simple video recordings taken with a single RGB camera. When tested on a publicly available dataset of patients with cerebral palsy, the proposed model outperformed existing state-of-the-art approaches, achieving significant improvements in predicting crucial gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating manual feature extraction."
        ],
        [
            "Identifying musculoskeletal disorders and cognitive impairments at an early stage is crucial, since they can have a profound impact on both physical capability and mental wellbeing. A crucial part of this identification process involves analyzing an individual's walking pattern, but conventional methods that rely on costly motion capture technology have significant limitations. However, recent breakthroughs in computer vision and deep learning have enabled the development of more affordable and accessible alternatives. This study presents a novel spatio-temporal transformer network that can precisely extract vital gait metrics from straightforward video recordings taken with a single RGB camera. When evaluated on a publicly available dataset of patients with cerebral palsy, the proposed model surpassed existing state-of-the-art approaches, achieving notable improvements in predicting key gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating manual feature extraction."
        ],
        [
            "Detecting musculoskeletal disorders and cognitive impairments at an early stage is vital, as they can significantly affect an individual's physical function and mental health. A key aspect of this detection process is the analysis of a person's gait pattern, but traditional methods relying on expensive motion capture systems have significant drawbacks. Fortunately, advances in computer vision and deep learning have paved the way for more affordable and accessible solutions. This study introduces a novel spatio-temporal transformer network that can accurately extract essential gait metrics from simple video recordings taken with a single RGB camera. When tested on a publicly available dataset of patients with cerebral palsy, the proposed model outperformed existing state-of-the-art approaches, achieving significant improvements in predicting key gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating manual feature extraction."
        ],
        [
            "Identifying musculoskeletal disorders and cognitive impairments in their early stages is crucial, as they can have a profound impact on both physical capability and mental wellbeing. A crucial element in this identification process involves examining an individual's gait pattern, but conventional methods that rely on costly motion capture systems have several limitations. However, recent breakthroughs in computer vision and deep learning have enabled the development of more cost-effective and accessible alternatives. This study presents a novel spatio-temporal transformer network capable of accurately extracting vital gait metrics from simple video recordings captured using a single RGB camera. When evaluated using a publicly available dataset of patients with cerebral palsy, the proposed model surpassed existing state-of-the-art approaches, achieving notable improvements in predicting key gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Early detection of musculoskeletal disorders and cognitive impairments is vital, as they can significantly affect both physical function and mental health. A key aspect of this detection process is analyzing an individual's walking pattern, but traditional methods relying on expensive motion capture systems have several drawbacks. Fortunately, advances in computer vision and deep learning have led to the creation of more affordable and accessible alternatives. This study introduces a novel spatio-temporal transformer network that can accurately extract essential gait metrics from simple video recordings taken with a single RGB camera. When tested on a publicly available dataset of patients with cerebral palsy, the proposed model outperformed existing state-of-the-art approaches, achieving significant improvements in predicting key gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating manual feature extraction."
        ],
        [
            "Identifying musculoskeletal disorders and cognitive impairments at an early stage is crucial, as they can have a profound impact on both physical capability and mental wellbeing. A crucial step in this identification process involves examining an individual's gait, but conventional methods that rely on costly motion capture systems have several limitations. However, breakthroughs in computer vision and deep learning have paved the way for more cost-effective and accessible solutions. This study presents a novel spatio-temporal transformer network that can precisely extract vital gait metrics from simple video recordings captured using a single RGB camera. When evaluated on a publicly available dataset of patients with cerebral palsy, the proposed model surpassed existing state-of-the-art approaches, achieving notable enhancements in predicting key gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Detecting musculoskeletal disorders and cognitive impairments at an early stage is vital, as they can significantly affect an individual's physical ability and mental health. A key part of this detection process involves analyzing a person's walking pattern, but traditional methods that use expensive motion capture systems have several drawbacks. However, advances in computer vision and deep learning have made it possible to develop more affordable and accessible alternatives. This study introduces a new spatio-temporal transformer network that can accurately identify essential gait metrics from simple video recordings taken using a single RGB camera. When tested on a publicly available dataset of patients with cerebral palsy, the proposed model outperformed existing state-of-the-art approaches, achieving significant improvements in predicting key gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Identifying musculoskeletal disorders and cognitive impairments at an early stage is crucial, as they can have a profound impact on an individual's physical capacity and mental wellbeing. A crucial aspect of this identification process involves examining an individual's gait, but conventional methods relying on costly motion capture systems have several limitations. Nevertheless, breakthroughs in computer vision and deep learning have enabled the development of more cost-effective and accessible solutions. This study presents a novel spatio-temporal transformer network capable of accurately extracting essential gait metrics from simple video footage captured using a single RGB camera. When evaluated on a publicly available dataset of patients with cerebral palsy, the proposed model surpassed existing state-of-the-art approaches, achieving notable enhancements in predicting key gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Early detection of musculoskeletal disorders and cognitive impairments is vital, as they can significantly affect a person's physical ability and mental health. A key part of this detection process is assessing an individual's gait, but traditional methods that rely on expensive motion capture systems have several drawbacks. However, advancements in computer vision and deep learning have made it possible to develop more affordable and accessible alternatives. This study introduces a new spatio-temporal transformer network that can accurately extract important gait metrics from simple video recordings taken with a single RGB camera. When tested on a publicly available dataset of patients with cerebral palsy, the proposed model outperformed existing top-performing approaches, achieving significant improvements in predicting key gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Identifying musculoskeletal disorders and cognitive impairments at an early stage is crucial, as they can have a profound impact on an individual's physical capabilities and mental wellbeing. Evaluating a person's gait pattern is a critical component of this identification process, but conventional methods relying on costly motion capture systems have several limitations. Fortunately, breakthroughs in computer vision and deep learning have enabled the development of more cost-effective and accessible alternatives. This research presents a novel spatio-temporal transformer network capable of precisely extracting vital gait metrics from simple video footage captured using a single RGB camera. When evaluated on a publicly available dataset of cerebral palsy patients, the proposed model surpassed existing top-performing approaches, achieving notable enhancements in predicting key gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating manual feature extraction."
        ],
        [
            "Detecting musculoskeletal disorders and cognitive impairments in their early stages is vital, as they can significantly affect a person's physical abilities and mental health. Assessing an individual's gait pattern is a key part of this detection process, but traditional methods that rely on expensive motion capture systems have several drawbacks. However, recent advances in computer vision and deep learning have made it possible to develop more affordable and accessible alternatives. This study introduces a new spatio-temporal transformer network that can accurately extract essential gait metrics from simple video recordings taken with a single RGB camera. When tested on a publicly available dataset of patients with cerebral palsy, the proposed model outperformed existing top-performing approaches, achieving significant improvements in predicting key gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Identifying musculoskeletal disorders and cognitive impairments at an early stage is crucial, as they can have a profound impact on an individual's physical capabilities and mental wellbeing. Analyzing a person's walking pattern plays a vital role in this identification process, but conventional methods that rely on costly motion capture systems have several limitations. Nevertheless, breakthroughs in computer vision and deep learning have enabled the development of more cost-effective and accessible solutions. This research presents a novel spatio-temporal transformer network capable of accurately extracting vital gait metrics from straightforward video recordings captured using a single RGB camera. When evaluated on a publicly available dataset of patients with cerebral palsy, the proposed model surpassed existing high-performing approaches, achieving substantial improvements in predicting crucial gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Detecting musculoskeletal disorders and cognitive impairments in their early stages is essential, as they can significantly affect an individual's physical abilities and mental health. Examining a person's gait is a critical component of this detection process, but traditional methods relying on expensive motion capture systems have notable drawbacks. However, recent advancements in computer vision and deep learning have made it possible to develop more affordable and accessible alternatives. This study introduces a novel spatio-temporal transformer network that can accurately extract key gait metrics from simple video recordings taken using a single RGB camera. When tested on a publicly available dataset of patients with cerebral palsy, the proposed model outperformed existing high-performing approaches, achieving significant improvements in predicting essential gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Identifying musculoskeletal disorders and cognitive impairments at an early stage is crucial, since they can have a profound impact on a person's physical capabilities and mental wellbeing. Assessing an individual's gait pattern is a vital part of this identification process, but conventional methods that rely on costly motion capture systems have several limitations. Nevertheless, breakthroughs in computer vision and deep learning have enabled the development of more cost-effective and widely accessible alternatives. This research presents a novel spatio-temporal transformer network that can precisely extract key gait metrics from straightforward video recordings captured using a single RGB camera. When evaluated on a publicly available dataset of patients with cerebral palsy, the proposed model surpassed existing high-performing approaches, achieving notable improvements in predicting vital gait metrics such as walking speed, gait deviation index, and knee flexion angle, all while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Early detection of musculoskeletal disorders and cognitive impairments is vital, as they can significantly affect a person's physical function and mental health. Analyzing an individual's gait pattern is a critical step in this detection process, but traditional methods relying on expensive motion capture systems have limitations. However, advances in computer vision and deep learning have led to the development of more affordable and accessible alternatives. This study introduces a novel spatio-temporal transformer network that accurately extracts key gait metrics from simple video recordings taken with a single RGB camera. When tested on a publicly available dataset of cerebral palsy patients, the proposed model outperformed existing high-performing approaches, achieving significant improvements in predicting essential gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating manual feature extraction."
        ],
        [
            "Identifying musculoskeletal disorders and cognitive impairments at an early stage is crucial, since they can have a profound impact on both physical capability and mental wellbeing. A crucial part of this identification process involves analyzing a person's gait pattern, but conventional methods that rely on costly motion capture systems are limited in their application. Fortunately, breakthroughs in computer vision and deep learning have paved the way for more affordable and widely accessible solutions. This study presents a novel spatio-temporal transformer network that can accurately identify key gait metrics from simple video footage captured using a single RGB camera. When tested on a publicly available dataset of patients with cerebral palsy, the proposed model surpassed existing high-performing approaches, achieving significant improvements in predicting vital gait metrics such as walking speed, gait deviation index, and knee flexion angle, all while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Detecting musculoskeletal disorders and cognitive impairments in their early stages is vital, as they can significantly affect an individual's physical function and mental health. A key aspect of this detection process involves examining a person's walking pattern, but traditional methods relying on expensive motion capture systems have limited real-world applicability. However, recent advancements in computer vision and deep learning have enabled the development of more cost-effective and widely available solutions. This study introduces a novel spatio-temporal transformer network capable of accurately extracting key gait metrics from simple video recordings captured using a single RGB camera. When evaluated on a publicly available dataset of patients with cerebral palsy, the proposed model outperformed existing high-performing approaches, achieving substantial improvements in predicting critical gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating manual feature extraction."
        ],
        [
            "Identifying musculoskeletal disorders and cognitive impairments at an early stage is crucial, as they can have a profound impact on a person's physical ability and mental wellbeing. A crucial part of this identification process involves analyzing an individual's gait, but traditional methods that rely on expensive motion capture technology have limited practical applications. However, breakthroughs in computer vision and deep learning have made it possible to develop more affordable and accessible solutions. This study presents a novel spatio-temporal transformer network that can accurately extract key gait metrics from simple video recordings taken with a single RGB camera. When tested on a publicly available dataset of patients with cerebral palsy, the proposed model surpassed existing high-performing approaches, achieving significant improvements in predicting critical gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Detecting musculoskeletal disorders and cognitive impairments at an early stage is vital, as they can significantly affect an individual's physical capacity and mental health. A key aspect of this detection process involves examining an individual's walking pattern, but conventional methods that rely on costly motion capture technology have limited real-world uses. Nevertheless, advances in computer vision and deep learning have enabled the development of more affordable and accessible alternatives. This study introduces a novel spatio-temporal transformer network capable of precisely extracting crucial gait metrics from simple video recordings captured with a single RGB camera. When evaluated on a publicly available dataset of patients with cerebral palsy, the proposed model outperformed existing high-achieving approaches, achieving substantial improvements in predicting critical gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating manual feature extraction."
        ]
    ]
}