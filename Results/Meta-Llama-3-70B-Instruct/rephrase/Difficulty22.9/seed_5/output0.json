{
    "adjacency_matrix": [
        [
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0
        ]
    ],
    "prompt_init": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "prompt_update": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "personality_list": [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        ""
    ],
    "format_prompt": [
        ""
    ],
    "initial_story": "musculoskeletal diseases and cognitive impairments in patients lead todifficulties in movement as well as negative effects on their psychologicalhealth. clinical gait analysis, a vital tool for early diagnosis and treatment,traditionally relies on expensive optical motion capture systems. recentadvances in computer vision and deep learning have opened the door to moreaccessible and cost-effective alternatives. this paper introduces a novelspatio-temporal transformer network to estimate critical gait parameters fromrgb videos captured by a single-view camera. empirical evaluations on a publicdataset of cerebral palsy patients indicate that the proposed frameworksurpasses current state-of-the-art approaches and show significant improvementsin predicting general gait parameters (including walking speed, gait deviationindex - gdi, and knee flexion angle at maximum extension), while utilizingfewer parameters and alleviating the need for manual feature extraction. ",
    "stories": [
        [
            "Patients with musculoskeletal diseases and cognitive impairments often experience mobility difficulties and psychological distress. Clinical gait analysis is crucial for early detection and treatment, but traditionally requires costly optical motion capture systems. However, recent breakthroughs in computer vision and deep learning have paved the way for more affordable and accessible alternatives. This study presents a novel spatio-temporal transformer network that can accurately estimate key gait parameters from single-view camera RGB videos. Evaluations on a public dataset of cerebral palsy patients demonstrate that the proposed framework outperforms current state-of-the-art methods, achieving significant improvements in predicting general gait parameters, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals suffering from musculoskeletal diseases and cognitive impairments frequently face challenges with mobility and mental well-being. Accurate diagnosis and treatment rely heavily on clinical gait analysis, which has traditionally been hindered by the high cost of optical motion capture systems. Nevertheless, advancements in computer vision and deep learning have opened up possibilities for more cost-effective and accessible solutions. This research introduces a novel spatio-temporal transformer network capable of precisely estimating crucial gait parameters from single-view camera RGB video recordings. When tested on a publicly available dataset of patients with cerebral palsy, the proposed framework surpasses existing state-of-the-art methods, yielding substantial improvements in predicting key gait parameters such as walking speed, gait deviation index, and knee flexion angle, all while requiring fewer parameters and eliminating manual feature extraction."
        ],
        [
            "People with musculoskeletal disorders and cognitive impairments often struggle with mobility and mental health issues. To diagnose and treat these conditions effectively, clinicians rely on thorough gait analysis, which has long been hampered by the prohibitive cost of optical motion capture systems. However, recent breakthroughs in computer vision and deep learning have paved the way for more affordable and accessible alternatives. This study presents a novel spatio-temporal transformer network that can accurately estimate critical gait parameters from single-view camera RGB video recordings. When evaluated using a publicly available dataset of patients with cerebral palsy, the proposed framework outperforms existing state-of-the-art methods, achieving significant improvements in predicting key gait parameters such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal disorders and cognitive impairments frequently face challenges related to mobility and mental wellbeing. To accurately identify and manage these conditions, healthcare professionals rely on in-depth gait assessments, which have historically been hindered by the high cost of optical motion capture technology. Nevertheless, recent advancements in computer vision and deep learning have enabled the development of more cost-effective and accessible solutions. This research introduces a novel spatio-temporal transformer network capable of precisely estimating essential gait metrics from single-view camera RGB video recordings. When tested using a publicly available dataset of patients with cerebral palsy, the proposed framework surpasses existing state-of-the-art methods, achieving notable improvements in predicting key gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating manual feature extraction."
        ],
        [
            "People with musculoskeletal disorders and cognitive impairments often struggle with mobility and mental health issues. Healthcare professionals need to conduct thorough gait analyses to diagnose and treat these conditions, but traditional optical motion capture technology has been too expensive. However, breakthroughs in computer vision and deep learning have made it possible to develop more affordable and accessible alternatives. This study presents a new spatio-temporal transformer network that can accurately estimate crucial gait metrics from simple camera video recordings. In tests using a publicly available dataset of cerebral palsy patients, the proposed system outperforms existing state-of-the-art methods, significantly improving predictions of key gait metrics such as walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating manual feature extraction."
        ],
        [
            "Individuals suffering from musculoskeletal disorders and cognitive impairments frequently face challenges related to mobility and mental wellbeing. In order to diagnose and treat these conditions effectively, healthcare professionals require comprehensive gait assessments, but traditional optical motion capture technology has proven to be cost-prohibitive. Fortunately, recent advancements in computer vision and deep learning have enabled the development of more affordable and accessible alternatives. This study introduces a novel spatio-temporal transformer network capable of accurately estimating essential gait metrics from straightforward camera video recordings. When tested on a publicly available dataset of cerebral palsy patients, the proposed system surpasses existing state-of-the-art methods, significantly enhancing predictions of critical gait metrics such as walking speed, gait deviation index, and knee flexion angle, while reducing the number of parameters required and eliminating the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal disorders and cognitive impairments often struggle with mobility and mental health issues. To diagnose and treat these conditions effectively, healthcare professionals need thorough gait assessments, but traditional optical motion capture technology is too expensive. However, breakthroughs in computer vision and deep learning have made it possible to develop more affordable and accessible options. This study presents a new spatio-temporal transformer network that can accurately estimate key gait metrics from simple camera video recordings. When tested on a publicly available dataset of cerebral palsy patients, the proposed system outperforms existing state-of-the-art methods, significantly improving predictions of critical gait metrics such as walking speed, gait deviation index, and knee flexion angle, while reducing the number of required parameters and eliminating manual feature extraction."
        ],
        [
            "Individuals affected by musculoskeletal disorders and cognitive impairments frequently face challenges related to mobility and mental well-being. To accurately diagnose and treat these conditions, healthcare providers require comprehensive assessments of gait patterns, but traditional optical motion capture systems are prohibitively expensive. Fortunately, advances in computer vision and deep learning have enabled the development of more cost-effective and accessible alternatives. This research introduces a novel spatio-temporal transformer network capable of precisely estimating crucial gait metrics from standard camera video recordings. When evaluated using a publicly available dataset of patients with cerebral palsy, the proposed system surpasses existing state-of-the-art methods, significantly enhancing predictions of critical gait metrics such as walking speed, gait deviation index, and knee flexion angle, while reducing the number of required parameters and eliminating manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive disorders often struggle with mobility and mental health issues. To properly identify and address these conditions, healthcare professionals need thorough evaluations of gait patterns, but traditional motion capture systems using cameras are too costly. However, recent breakthroughs in computer vision and deep learning have made it possible to develop more affordable and accessible solutions. This study presents a new spatio-temporal transformer network that can accurately estimate key gait metrics from regular video recordings taken with a camera. When tested on a publicly available dataset of patients with cerebral palsy, the proposed system outperforms existing state-of-the-art methods, significantly improving predictions of vital gait metrics such as walking speed, gait deviation index, and knee flexion angle, while reducing the number of required parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals dealing with musculoskeletal and cognitive impairments frequently face challenges related to mobility and mental wellbeing. To accurately diagnose and treat these conditions, healthcare providers require comprehensive assessments of gait patterns, but traditional camera-based motion capture systems are prohibitively expensive. Fortunately, recent advances in computer vision and deep learning have paved the way for the development of more affordable and accessible alternatives. This research introduces a novel spatio-temporal transformer network capable of precisely estimating critical gait metrics from standard video footage captured with a camera. In trials using a publicly available dataset of patients with cerebral palsy, the proposed system surpasses existing state-of-the-art methods, substantially enhancing predictions of essential gait metrics such as walking speed, gait deviation index, and knee flexion angle, while reducing the number of required parameters and eliminating the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive disabilities often struggle with mobility and mental health issues. To properly identify and address these conditions, healthcare professionals need thorough evaluations of gait patterns, but traditional camera-based motion capture systems are too costly. Luckily, breakthroughs in computer vision and deep learning have made it possible to create more affordable and accessible solutions. This study presents a new spatio-temporal transformer network that can accurately estimate key gait metrics from regular video recordings taken with a camera. In tests using a publicly available dataset of patients with cerebral palsy, the proposed system outperforms existing top-performing methods, significantly improving predictions of crucial gait metrics like walking speed, gait deviation index, and knee flexion angle, while reducing the number of required parameters and eliminating manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive impairments frequently face challenges related to mobility and mental wellbeing. In order to effectively diagnose and treat these conditions, healthcare practitioners require comprehensive assessments of gait patterns, but traditional camera-based motion capture systems are prohibitively expensive. Fortunately, advancements in computer vision and deep learning have enabled the development of more affordable and accessible alternatives. This study introduces a novel spatio-temporal transformer network capable of accurately estimating key gait metrics from standard video footage captured using a camera. In experiments utilizing a publicly available dataset of patients with cerebral palsy, the proposed system surpasses existing top-performing methods, significantly enhancing predictions of critical gait metrics such as walking speed, gait deviation index, and knee flexion angle, while reducing the number of required parameters and eliminating manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive disabilities often struggle with mobility and mental health issues. To properly identify and address these conditions, healthcare professionals need thorough evaluations of walking patterns, but traditional motion capture systems using cameras are too costly. However, recent breakthroughs in computer vision and deep learning have made it possible to create more affordable and accessible solutions. This study presents a new spatio-temporal transformer network that can accurately estimate essential gait metrics from regular video recordings taken with a camera. In tests using a publicly available dataset of cerebral palsy patients, the proposed system outperforms existing top-performing methods, significantly improving predictions of crucial gait metrics such as walking speed, gait deviation index, and knee flexion angle, while reducing the number of required parameters and eliminating manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive impairments frequently face challenges related to mobility and mental wellbeing. To accurately diagnose and treat these conditions, healthcare providers require comprehensive assessments of gait patterns, but traditional camera-based motion capture systems are prohibitively expensive. Fortunately, advancements in computer vision and deep learning have enabled the development of more affordable and accessible alternatives. This research introduces a novel spatio-temporal transformer network capable of precisely estimating critical gait metrics from standard video footage captured using a camera. In evaluations utilizing a publicly available dataset of patients with cerebral palsy, the proposed system surpasses existing state-of-the-art methods, significantly enhancing predictions of vital gait metrics such as walking speed, gait deviation index, and knee flexion angle, while reducing the number of required parameters and eliminating manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive disabilities often struggle with mobility and mental health issues. To properly identify and address these conditions, healthcare professionals need thorough evaluations of walking patterns, but conventional camera-based systems for motion capture are too costly. However, breakthroughs in computer vision and deep learning have led to the creation of more affordable and accessible options. This study presents a new spatio-temporal transformer network that can accurately calculate key walking metrics from ordinary video recordings taken with a camera. In tests using a publicly available dataset of patients with cerebral palsy, the proposed system outperforms existing top-performing methods, significantly improving predictions of crucial walking metrics such as walking speed, gait deviation index, and knee flexion angle, while reducing the number of required parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive impairments frequently face challenges related to mobility and mental wellbeing. To accurately diagnose and treat these conditions, healthcare providers require comprehensive assessments of gait patterns, but traditional camera-based motion capture systems are prohibitively expensive. Fortunately, advances in computer vision and deep learning have enabled the development of more affordable and accessible alternatives. This study introduces a novel spatio-temporal transformer network capable of precisely calculating key gait metrics from ordinary video footage captured using a camera. In experiments utilizing a publicly available dataset of patients with cerebral palsy, the proposed system surpasses existing state-of-the-art methods, significantly enhancing predictions of critical gait metrics such as walking speed, gait deviation index, and knee flexion angle, while reducing the number of required parameters and eliminating the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive disabilities often struggle with mobility and mental health issues. Healthcare professionals need thorough evaluations of gait patterns to diagnose and treat these conditions accurately, but traditional motion capture systems using cameras are too costly. However, recent breakthroughs in computer vision and deep learning have made it possible to create more affordable and accessible solutions. This study presents a new spatio-temporal transformer network that can accurately measure key gait metrics from regular video recordings taken with a camera. In tests using a publicly available dataset of patients with cerebral palsy, the proposed system outperforms existing top-performing methods, significantly improving predictions of crucial gait metrics such as walking speed, gait deviation index, and knee flexion angle, while reducing the number of required parameters and eliminating manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive impairments frequently face challenges related to mobility and mental wellbeing. To diagnose and treat these conditions effectively, healthcare professionals require comprehensive assessments of gait patterns, but conventional camera-based motion capture systems are prohibitively expensive. Fortunately, advancements in computer vision and deep learning have enabled the development of more affordable and accessible alternatives. This study introduces a novel spatio-temporal transformer network capable of accurately measuring key gait metrics from standard video footage captured using a camera. In experiments utilizing a publicly available dataset of patients with cerebral palsy, the proposed system surpasses existing top-performing methods, significantly enhancing predictions of critical gait metrics such as walking speed, gait deviation index, and knee flexion angle, while reducing the number of required parameters and eliminating manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive disabilities often struggle with mobility and mental health issues. To properly diagnose and treat these conditions, healthcare providers need thorough evaluations of walking patterns, but traditional motion capture systems using cameras are too costly. However, recent breakthroughs in computer vision and deep learning have led to the creation of more affordable and accessible solutions. This study presents a new spatio-temporal transformer network that can precisely measure key walking metrics from regular video recordings taken with a camera. In tests using a publicly available dataset of patients with cerebral palsy, the proposed system outperforms existing top-performing methods, significantly improving predictions of crucial walking metrics like walking speed, gait deviation index, and knee flexion angle, while reducing the number of required parameters and eliminating manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive impairments frequently face challenges related to mobility and mental wellbeing. Accurate diagnosis and treatment of these conditions rely on comprehensive assessments of gait patterns, but conventional motion capture systems utilizing cameras are prohibitively expensive. Fortunately, advances in computer vision and deep learning have paved the way for more affordable and accessible alternatives. This research introduces a novel spatio-temporal transformer network capable of accurately measuring essential gait metrics from standard video footage captured using a camera. In trials using a publicly available dataset of patients with cerebral palsy, the proposed system surpasses existing top-performing methods, significantly enhancing predictions of critical gait metrics such as walking speed, gait deviation index, and knee flexion angle, while reducing the number of required parameters and eliminating manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive disabilities often struggle with mobility and mental health issues. To diagnose and treat these conditions effectively, healthcare professionals need to thoroughly analyze gait patterns, but traditional camera-based motion capture systems are too costly. However, recent breakthroughs in computer vision and deep learning have made it possible to develop more affordable and accessible solutions. This study presents a new spatio-temporal transformer network that can accurately extract key gait metrics from regular video recordings taken with a camera. In tests using a publicly available dataset of patients with cerebral palsy, our system outperforms existing top-performing methods, significantly improving predictions of crucial gait metrics such as walking speed, gait deviation index, and knee flexion angle, while reducing the number of required parameters and eliminating manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive impairments frequently face challenges related to mobility and mental wellbeing. To accurately identify and address these conditions, healthcare providers require a comprehensive understanding of gait patterns, but conventional motion capture systems using cameras are prohibitively expensive. Fortunately, advances in computer vision and deep learning have enabled the development of more economical and accessible alternatives. This research introduces a novel spatio-temporal transformer network capable of precisely extracting essential gait metrics from standard video recordings captured with a camera. In experiments utilizing a publicly available dataset of patients with cerebral palsy, our system surpasses existing high-performing methods, significantly enhancing predictions of vital gait metrics such as walking speed, gait deviation index, and knee flexion angle, while reducing the number of required parameters and eliminating the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive disabilities often struggle with mobility and mental health issues. To properly diagnose and treat these conditions, healthcare professionals need to thoroughly understand gait patterns. However, traditional motion capture systems that use cameras are too costly. Luckily, breakthroughs in computer vision and deep learning have made it possible to create more affordable and accessible solutions. This study presents a new spatio-temporal transformer network that can accurately extract key gait metrics from ordinary video recordings taken with a camera. In tests using a public dataset of patients with cerebral palsy, our system outperforms existing top-performing methods, significantly improving predictions of crucial gait metrics such as walking speed, gait deviation index, and knee flexion angle, while reducing the number of required parameters and eliminating manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive impairments frequently face challenges related to mobility and mental wellbeing. To effectively identify and address these conditions, medical professionals require a comprehensive understanding of gait patterns. However, traditional camera-based motion capture systems are prohibitively expensive. Fortunately, recent advancements in computer vision and deep learning have enabled the development of more affordable and accessible alternatives. This research introduces a novel spatio-temporal transformer network capable of accurately extracting essential gait metrics from standard video recordings captured using a camera. In evaluations utilizing a publicly available dataset of patients with cerebral palsy, our system surpasses existing high-performing methods, significantly enhancing predictions of critical gait metrics such as walking speed, gait deviation index, and knee flexion angle, while minimizing the number of required parameters and eliminating manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive disabilities often struggle with mobility and mental health issues. To properly diagnose and treat these conditions, healthcare professionals need a thorough understanding of how people walk. However, traditional motion capture systems that use cameras are too costly. Luckily, recent breakthroughs in computer vision and deep learning have made it possible to develop more affordable and accessible solutions. This study presents a new spatio-temporal transformer network that can accurately extract key gait metrics from ordinary video recordings taken with a camera. In tests using a publicly available dataset of patients with cerebral palsy, our system outperforms existing top-performing methods, significantly improving predictions of critical gait metrics such as walking speed, gait deviation index, and knee flexion angle, while reducing the number of required parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals with disabilities affecting their muscles, bones, and cognitive abilities often face challenges related to mobility and mental wellbeing. To effectively identify and address these issues, healthcare providers require a comprehensive grasp of human gait patterns. Conventional motion capture systems relying on cameras are prohibitively expensive. Fortunately, advances in computer vision and deep learning have paved the way for more economical and accessible alternatives. This research introduces a novel spatio-temporal transformer network capable of precisely extracting vital gait metrics from standard video footage captured using a camera. In experiments utilizing a publicly available dataset of cerebral palsy patients, our system surpasses existing high-performing methods, significantly enhancing predictions of crucial gait metrics such as walking speed, gait deviation index, and knee flexion angle, while minimizing required parameters and eliminating manual feature extraction."
        ],
        [
            "People with disabilities that impact their muscles, bones, and cognitive function frequently encounter difficulties with mobility and mental health. To properly diagnose and treat these issues, healthcare professionals need a thorough understanding of how people walk. Traditional motion capture systems that use cameras are too costly. However, recent breakthroughs in computer vision and deep learning have made it possible to develop more affordable and accessible solutions. This research presents a new spatio-temporal transformer network that can accurately extract essential gait metrics from ordinary video recordings taken with a camera. In tests using a publicly available dataset of patients with cerebral palsy, our system outperforms existing high-achieving methods, significantly improving predictions of critical gait metrics such as walking speed, gait deviation index, and knee flexion angle, while reducing required parameters and eliminating manual feature extraction."
        ],
        [
            "Individuals with disabilities affecting their muscular, skeletal, and cognitive systems often face challenges related to mobility and mental wellbeing. Healthcare professionals require a comprehensive understanding of human gait to accurately diagnose and treat these issues. Conventional motion capture systems relying on cameras are prohibitively expensive. Fortunately, advancements in computer vision and deep learning have enabled the development of more affordable and accessible alternatives. This research introduces a novel spatio-temporal transformer network capable of extracting crucial gait metrics from ordinary video footage captured using a camera. In trials utilizing a publicly available dataset of patients with cerebral palsy, our system surpasses existing high-performing methods, significantly enhancing predictions of vital gait metrics such as walking speed, gait deviation index, and knee flexion angle, while reducing required parameters and eliminating manual feature extraction."
        ],
        [
            "People with disabilities that impact their muscles, bones, and brain often struggle with moving around and maintaining good mental health. To properly identify and address these issues, healthcare professionals need a thorough grasp of how humans walk. Traditional systems that use cameras to track movement are too costly. However, recent breakthroughs in computer vision and deep learning have made it possible to create more affordable and accessible solutions. This research presents a new type of neural network that can extract essential information about walking patterns from regular video recordings taken with a camera. In tests using a publicly available dataset of patients with cerebral palsy, our system outperforms existing top-performing methods, significantly improving predictions of key walking metrics such as pace, gait irregularity, and knee bend, while reducing the number of required parameters and eliminating the need for manual data analysis."
        ],
        [
            "Individuals with disabilities affecting their musculoskeletal and nervous systems often face challenges with mobility and mental wellbeing. To effectively diagnose and treat these issues, healthcare providers require a comprehensive understanding of human locomotion. Conventional motion-tracking systems relying on cameras are prohibitively expensive. However, advancements in computer vision and deep learning have enabled the development of more affordable and accessible alternatives. This study introduces a novel neural network capable of extracting crucial information about gait patterns from standard video footage captured using a camera. When tested on a publicly available dataset of patients with cerebral palsy, our system surpasses existing top-performing methods, significantly enhancing predictions of key gait metrics such as speed, stride irregularity, and knee flexion, while reducing the number of required parameters and eliminating the need for manual data interpretation."
        ],
        [
            "People with musculoskeletal and nervous system disabilities often struggle with mobility and mental health. Healthcare professionals need to thoroughly understand human movement to accurately diagnose and treat these issues. Traditional camera-based motion-tracking systems are too costly. Fortunately, advances in computer vision and deep learning have led to more affordable and accessible solutions. This research presents a new neural network that can extract vital information about walking patterns from ordinary video recordings taken with a camera. When tested on a publicly available dataset of patients with cerebral palsy, our system outperforms existing top-performing methods, significantly improving predictions of key walking metrics such as speed, stride irregularity, and knee flexion, while reducing the number of required parameters and eliminating the need for manual data analysis."
        ],
        [
            "Individuals living with musculoskeletal and nervous system disorders frequently face challenges related to mobility and mental wellbeing. A comprehensive understanding of human movement is essential for healthcare professionals to accurately identify and address these issues. While traditional motion-tracking systems using cameras are prohibitively expensive, recent breakthroughs in computer vision and deep learning have given rise to more economical and accessible alternatives. This study introduces a novel neural network capable of extracting crucial information about gait patterns from standard video footage captured using a camera. When evaluated on a publicly available dataset of patients with cerebral palsy, our system surpasses existing state-of-the-art methods, substantially enhancing predictions of key gait metrics such as velocity, stride consistency, and knee flexion, while minimizing the number of required parameters and eliminating the need for manual data interpretation."
        ],
        [
            "People with musculoskeletal and nervous system disorders often struggle with mobility and mental health issues. To effectively diagnose and treat these problems, healthcare professionals need a thorough understanding of human movement. Although traditional camera-based motion-tracking systems are too costly, advances in computer vision and deep learning have led to more affordable and accessible options. This study presents a new neural network that can extract important information about walking patterns from regular video recordings taken with a camera. Tested on a publicly available dataset of cerebral palsy patients, our system outperforms existing state-of-the-art methods, significantly improving predictions of key gait metrics like speed, stride consistency, and knee flexion, while reducing the number of required parameters and eliminating the need for manual data analysis."
        ],
        [
            "Individuals suffering from musculoskeletal and nervous system disorders frequently face challenges related to mobility and mental wellbeing. To accurately identify and address these issues, medical professionals require a comprehensive grasp of human movement patterns. While traditional camera-based motion-capture systems are prohibitively expensive, recent breakthroughs in computer vision and deep learning have made it possible to develop more economical and accessible alternatives. This research introduces a novel neural network capable of extracting crucial information about walking patterns from ordinary video footage captured using a camera. When tested on a publicly available dataset of patients with cerebral palsy, our system surpasses existing cutting-edge methods, significantly enhancing predictions of key gait metrics such as velocity, stride uniformity, and knee flexion, while reducing the number of required parameters and eliminating the need for manual data interpretation."
        ],
        [
            "People with musculoskeletal and nervous system disorders often struggle with mobility and mental health issues. To diagnose and treat these problems effectively, healthcare professionals need to thoroughly understand how people move. Although traditional motion-capture systems using cameras are too costly, advances in computer vision and deep learning have enabled the development of more affordable and accessible solutions. This study presents a new neural network that can extract vital information about walking patterns from regular video recordings taken with a camera. In tests using a public dataset of patients with cerebral palsy, our system outperforms current state-of-the-art methods, significantly improving predictions of important gait metrics such as speed, stride consistency, and knee bending, while requiring fewer parameters and eliminating the need for manual data analysis."
        ],
        [
            "Individuals afflicted with musculoskeletal and nervous system disorders frequently face challenges related to mobility and mental wellbeing. To accurately diagnose and treat these issues, healthcare providers must have a comprehensive understanding of human movement patterns. While traditional camera-based motion-capture systems are prohibitively expensive, recent breakthroughs in computer vision and deep learning have led to the creation of more cost-effective and accessible alternatives. This research introduces a novel neural network capable of extracting crucial information about walking patterns from ordinary video footage captured using a camera. In trials utilizing a publicly available dataset of patients with cerebral palsy, our system surpasses existing state-of-the-art methods, substantially enhancing predictions of key gait metrics such as velocity, stride regularity, and knee flexion, while requiring fewer parameters and eliminating the need for manual data interpretation."
        ],
        [
            "People with musculoskeletal and nervous system disorders often struggle with mobility and mental health issues. To properly identify and address these problems, healthcare professionals need to thoroughly understand how people move. While traditional motion-capture systems using cameras are too costly, recent advances in computer vision and deep learning have made it possible to develop more affordable and accessible solutions. This study presents a new neural network that can extract important details about walking patterns from regular video recordings taken with a camera. In tests using a publicly available dataset of patients with cerebral palsy, our system outperforms current top methods, significantly improving predictions of key gait metrics such as speed, stride consistency, and knee bending, while requiring fewer parameters and eliminating the need for manual data analysis."
        ],
        [
            "Individuals affected by musculoskeletal and nervous system disorders frequently experience difficulties with mobility and mental well-being. To accurately diagnose and treat these issues, healthcare providers must have a comprehensive understanding of human movement. Although traditional camera-based motion-capture systems are prohibitively expensive, recent breakthroughs in computer vision and deep learning have enabled the development of more affordable and accessible alternatives. This research introduces a novel neural network capable of extracting crucial information about walking patterns from standard video footage captured using a camera. In experiments utilizing a publicly available dataset of patients with cerebral palsy, our system surpasses current leading methods, significantly enhancing predictions of key gait metrics such as velocity, stride consistency, and knee flexion, while requiring fewer parameters and eliminating the need for manual data processing."
        ],
        [
            "People with musculoskeletal and nervous system disorders often struggle with mobility and mental health. To properly identify and address these problems, healthcare professionals need a thorough grasp of human movement patterns. While traditional motion-capture systems using cameras are too costly, advancements in computer vision and deep learning have led to more affordable and accessible options. This study presents a new neural network that can extract vital information about walking patterns from regular video recordings taken with a camera. In tests using a publicly available dataset of cerebral palsy patients, our system outperforms current leading methods, significantly improving predictions of important gait metrics like speed, stride consistency, and knee bending, all while requiring fewer parameters and eliminating manual data processing."
        ],
        [
            "Individuals affected by musculoskeletal and nervous system disorders frequently experience difficulties with mobility and mental wellbeing. In order to accurately diagnose and treat these issues, healthcare providers require a comprehensive understanding of human movement patterns. Although traditional camera-based motion-capture systems are prohibitively expensive, recent breakthroughs in computer vision and deep learning have made more affordable and accessible alternatives available. This research introduces a novel neural network capable of extracting crucial information about walking patterns from ordinary video recordings captured with a camera. When tested on a publicly available dataset of cerebral palsy patients, our system surpasses current leading methods, significantly enhancing predictions of key gait metrics such as speed, stride consistency, and knee bending, all while reducing the number of parameters required and eliminating manual data processing."
        ],
        [
            "People with musculoskeletal and nervous system disorders often struggle with mobility and mental health. To diagnose and treat these conditions effectively, healthcare professionals need to thoroughly understand human movement patterns. While traditional motion-capture systems using cameras are too costly, advances in computer vision and deep learning have made more affordable options available. This study presents a new neural network that can extract vital information about walking patterns from regular video recordings taken with a camera. When tested on a publicly available dataset of patients with cerebral palsy, our system outperforms current leading methods, significantly improving predictions of key gait metrics such as speed, stride consistency, and knee bending, while requiring fewer parameters and eliminating manual data processing."
        ],
        [
            "Individuals affected by musculoskeletal and nervous system disorders frequently face challenges related to mobility and mental wellbeing. In order to accurately diagnose and treat these conditions, healthcare professionals must have a comprehensive understanding of human movement patterns. Although traditional camera-based motion-capture systems are prohibitively expensive, recent breakthroughs in computer vision and deep learning have made more economical alternatives possible. This study introduces a novel neural network capable of extracting crucial information about walking patterns from ordinary video footage captured using a camera. When evaluated against a publicly available dataset of patients with cerebral palsy, our system surpasses current leading methods, substantially enhancing predictions of critical gait metrics such as velocity, stride consistency, and knee flexion, while requiring fewer parameters and eliminating manual data processing."
        ],
        [
            "People with musculoskeletal and nervous system disorders often struggle with mobility and mental health issues. To effectively diagnose and treat these conditions, healthcare providers need a thorough grasp of human movement patterns. While traditional motion-capture systems using cameras are too costly, advances in computer vision and deep learning have made more affordable options available. This study presents a new neural network that can extract key information about walking patterns from regular video recordings taken with a camera. When tested against a publicly available dataset of patients with cerebral palsy, our system outperforms current top methods, significantly improving predictions of vital gait metrics such as speed, stride consistency, and knee bend, while requiring fewer parameters and no manual data processing."
        ],
        [
            "Individuals afflicted with musculoskeletal and nervous system disorders frequently face challenges related to mobility and mental wellbeing. To accurately identify and address these conditions, healthcare professionals require a comprehensive understanding of human movement patterns. Although traditional camera-based motion-capture systems are prohibitively expensive, recent breakthroughs in computer vision and deep learning have led to the development of more cost-effective alternatives. This study introduces a novel neural network capable of extracting crucial information about walking patterns from ordinary video footage captured using a camera. When evaluated against a publicly available dataset of patients with cerebral palsy, our system surpasses current leading methods, significantly enhancing predictions of vital gait metrics such as velocity, stride consistency, and knee flexion, while necessitating fewer parameters and eliminating manual data processing."
        ],
        [
            "People suffering from musculoskeletal and nervous system disorders often struggle with mobility and mental health issues. To properly diagnose and treat these conditions, healthcare providers need a thorough grasp of human movement patterns. While traditional motion-capture systems using cameras are too costly, recent advances in computer vision and deep learning have made way for more affordable solutions. This study presents a new neural network that can extract essential information about walking patterns from regular video recordings taken with a camera. When tested against a publicly available dataset of patients with cerebral palsy, our system outperforms current leading methods, significantly improving predictions of critical gait metrics such as speed, stride consistency, and knee flexion, while requiring fewer parameters and eliminating manual data processing."
        ],
        [
            "Individuals afflicted with musculoskeletal and nervous system disorders frequently face challenges related to mobility and mental wellbeing. Accurate diagnosis and treatment of these conditions require healthcare professionals to have a comprehensive understanding of human movement patterns. Although traditional camera-based motion-capture systems are prohibitively expensive, recent breakthroughs in computer vision and deep learning have paved the way for more economical alternatives. This research introduces a novel neural network capable of extracting crucial information about walking patterns from ordinary video footage captured using a camera. When evaluated against a publicly available dataset of patients with cerebral palsy, our system surpasses existing leading methods, significantly enhancing predictions of critical gait metrics such as velocity, stride consistency, and knee flexion, while necessitating fewer parameters and eliminating manual data processing."
        ],
        [
            "People suffering from musculoskeletal and nervous system disorders often struggle with mobility and mental health issues. To diagnose and treat these conditions effectively, healthcare professionals need to have a thorough understanding of how humans move. While traditional motion-capture systems using cameras are too costly, recent advances in computer vision and deep learning have made more affordable options possible. This research presents a new neural network that can extract vital information about walking patterns from regular video recordings taken with a camera. When tested on a publicly available dataset of patients with cerebral palsy, our system outperforms existing leading methods, significantly improving predictions of key gait metrics such as speed, stride consistency, and knee bend, while requiring fewer parameters and eliminating manual data processing."
        ],
        [
            "Individuals afflicted with musculoskeletal and nervous system disorders frequently face challenges related to mobility and mental wellbeing. In order to accurately diagnose and treat these conditions, healthcare providers must possess a comprehensive understanding of human movement patterns. Although traditional camera-based motion-capture systems are prohibitively expensive, recent breakthroughs in computer vision and deep learning have enabled the development of more affordable alternatives. This study introduces a novel neural network capable of extracting crucial information regarding walking patterns from standard video recordings captured using a camera. When evaluated using a publicly available dataset of patients with cerebral palsy, our system surpasses existing leading methods, substantially enhancing predictions of key gait metrics such as velocity, stride uniformity, and knee flexion, while requiring fewer parameters and eliminating manual data processing."
        ],
        [
            "People with musculoskeletal and nervous system disorders often struggle with mobility and mental health issues. To properly identify and manage these conditions, healthcare professionals need to have a thorough understanding of how humans move. While traditional motion-capture systems that use cameras are too expensive, recent advances in computer vision and deep learning have made it possible to create more affordable options. This study presents a new neural network that can extract important information about walking patterns from regular video recordings taken with a camera. When tested using a publicly available dataset of patients with cerebral palsy, our system outperforms existing leading methods, significantly improving predictions of key gait metrics like speed, stride consistency, and knee bend, while requiring fewer parameters and eliminating manual data processing."
        ],
        [
            "Individuals afflicted with musculoskeletal and nervous system disorders frequently face challenges related to mobility and mental wellbeing. To accurately diagnose and treat these conditions, medical professionals must possess a comprehensive grasp of human movement patterns. Although traditional camera-based motion-capture systems are prohibitively costly, breakthroughs in computer vision and deep learning have enabled the development of more affordable alternatives. This research introduces a novel neural network capable of extracting crucial information about walking patterns from standard video footage captured using a camera. When evaluated using a publicly available dataset of patients with cerebral palsy, our system surpasses existing leading methods, significantly enhancing predictions of key gait metrics such as velocity, stride consistency, and knee flexion, while necessitating fewer parameters and eliminating manual data processing."
        ]
    ]
}