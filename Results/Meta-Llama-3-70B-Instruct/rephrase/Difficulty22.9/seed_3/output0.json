{
    "adjacency_matrix": [
        [
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0
        ]
    ],
    "prompt_init": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "prompt_update": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "personality_list": [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        ""
    ],
    "format_prompt": [
        ""
    ],
    "initial_story": "musculoskeletal diseases and cognitive impairments in patients lead todifficulties in movement as well as negative effects on their psychologicalhealth. clinical gait analysis, a vital tool for early diagnosis and treatment,traditionally relies on expensive optical motion capture systems. recentadvances in computer vision and deep learning have opened the door to moreaccessible and cost-effective alternatives. this paper introduces a novelspatio-temporal transformer network to estimate critical gait parameters fromrgb videos captured by a single-view camera. empirical evaluations on a publicdataset of cerebral palsy patients indicate that the proposed frameworksurpasses current state-of-the-art approaches and show significant improvementsin predicting general gait parameters (including walking speed, gait deviationindex - gdi, and knee flexion angle at maximum extension), while utilizingfewer parameters and alleviating the need for manual feature extraction. ",
    "stories": [
        [
            "Patients suffering from musculoskeletal diseases and cognitive impairments often experience mobility issues and psychological distress. Clinical gait analysis, a crucial diagnostic and therapeutic tool, has traditionally depended on costly optical motion capture systems. However, breakthroughs in computer vision and deep learning have paved the way for more affordable and accessible solutions. This study presents a novel spatio-temporal transformer network that can estimate key gait parameters from single-view camera RGB videos. Evaluations on a publicly available dataset of cerebral palsy patients demonstrate that the proposed framework outperforms current state-of-the-art methods, achieving significant improvements in predicting general gait parameters (including walking speed, gait deviation index, and knee flexion angle at maximum extension), while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal diseases and cognitive impairments often face difficulties with movement and emotional distress. A vital diagnostic and therapeutic technique, clinical gait analysis, has long relied on expensive optical motion capture systems. Nevertheless, advancements in computer vision and deep learning have made it possible to develop more affordable and accessible alternatives. This research introduces a novel spatio-temporal transformer network capable of estimating essential gait parameters from single-view camera RGB videos. Testing on a publicly available dataset of cerebral palsy patients shows that the proposed framework surpasses current state-of-the-art methods, achieving notable improvements in predicting general gait parameters (such as walking speed, gait deviation index, and knee flexion angle at maximum extension), while requiring fewer parameters and eliminating manual feature extraction."
        ],
        [
            "Individuals suffering from musculoskeletal diseases and cognitive impairments often struggle with mobility issues and emotional distress. For a long time, clinical gait analysis, a crucial diagnostic and therapeutic tool, has depended on costly optical motion capture systems. However, breakthroughs in computer vision and deep learning have enabled the development of more cost-effective and accessible solutions. This study presents a novel spatio-temporal transformer network that can accurately estimate key gait parameters from single-view camera RGB videos. When tested on a publicly available dataset of patients with cerebral palsy, the proposed framework outperforms current state-of-the-art methods, achieving significant improvements in predicting general gait parameters (including walking speed, gait deviation index, and knee flexion angle at maximum extension), while requiring fewer parameters and eliminating manual feature extraction."
        ],
        [
            "People with musculoskeletal diseases and cognitive impairments often face difficulties with moving around and experience emotional distress. Clinical gait analysis, a vital tool for diagnosis and treatment, has traditionally relied on expensive optical motion capture systems. However, advances in computer vision and deep learning have led to the creation of more affordable and accessible alternatives. This research introduces a novel spatio-temporal transformer network capable of accurately estimating key gait parameters from single-view camera RGB videos. When evaluated using a publicly available dataset of patients with cerebral palsy, the proposed framework surpasses current state-of-the-art methods, achieving notable improvements in predicting general gait parameters (including walking speed, gait deviation index, and knee flexion angle at maximum extension), while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals suffering from musculoskeletal disorders and cognitive impairments frequently struggle with mobility and emotional well-being. The diagnosis and treatment of such conditions have long relied on clinical gait analysis, which has traditionally been limited by the high cost of optical motion capture systems. Recent breakthroughs in computer vision and deep learning have made it possible to develop more affordable and accessible alternatives. This study presents a novel spatio-temporal transformer network that can accurately predict key gait metrics from single-view camera RGB videos. When tested using a publicly available dataset of patients with cerebral palsy, the proposed framework outperforms current state-of-the-art methods, achieving significant improvements in predicting general gait metrics (including walking speed, gait deviation index, and knee flexion angle at maximum extension), while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal disorders and cognitive impairments often face challenges with mobility and emotional wellness. Traditionally, diagnosing and treating these conditions has relied heavily on clinical gait analysis, which has been hindered by the expense of optical motion capture systems. However, recent advancements in computer vision and deep learning have enabled the development of more cost-effective and accessible solutions. This study introduces a novel spatio-temporal transformer network that can accurately predict key gait metrics from single-view camera RGB videos. When evaluated using a publicly available dataset of patients with cerebral palsy, the proposed framework surpasses current state-of-the-art methods, achieving notable improvements in predicting general gait metrics (including walking speed, gait deviation index, and knee flexion angle at maximum extension), while requiring fewer parameters and eliminating manual feature extraction."
        ],
        [
            "Individuals suffering from musculoskeletal disorders and cognitive impairments frequently encounter difficulties with mobility and emotional well-being. The diagnosis and treatment of these conditions have historically relied on clinical gait analysis, which has been impeded by the high cost of optical motion capture systems. However, breakthroughs in computer vision and deep learning have paved the way for the development of more affordable and accessible alternatives. This research presents a novel spatio-temporal transformer network capable of accurately predicting essential gait metrics from single-view camera RGB videos. When tested using a publicly available dataset of patients with cerebral palsy, the proposed framework outperforms current state-of-the-art methods, achieving significant improvements in predicting general gait metrics (including walking speed, gait deviation index, and knee flexion angle at maximum extension), while requiring fewer parameters and eliminating manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive impairments often struggle with mobility and emotional well-being. Traditionally, diagnosing and treating these conditions has involved clinical gait analysis, but this has been hindered by the expense of optical motion capture systems. Recent advances in computer vision and deep learning have made it possible to develop more affordable and accessible alternatives. This study introduces a novel spatio-temporal transformer network that can accurately predict key gait metrics from single-view camera RGB videos. When tested on a publicly available dataset of patients with cerebral palsy, the proposed framework surpasses current state-of-the-art methods, achieving significant improvements in predicting general gait metrics (including walking speed, gait deviation index, and knee flexion angle at maximum extension), while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive disabilities frequently face challenges related to mobility and emotional wellness. The diagnosis and treatment of these conditions have traditionally relied on clinical gait analysis, but the high cost of optical motion capture systems has limited its adoption. However, breakthroughs in computer vision and deep learning have enabled the development of more cost-effective and accessible solutions. This research presents a novel spatio-temporal transformer network capable of accurately predicting crucial gait metrics from single-view camera RGB videos. When evaluated using a publicly available dataset of patients with cerebral palsy, the proposed framework outperforms current state-of-the-art methods, achieving notable improvements in predicting general gait metrics (including walking speed, gait deviation index, and knee flexion angle at maximum extension), while requiring fewer parameters and eliminating manual feature extraction."
        ],
        [
            "People with musculoskeletal and cognitive impairments often struggle with mobility issues and emotional wellbeing. Historically, clinicians have used gait analysis to diagnose and treat these conditions, but the expense of motion capture systems has hindered widespread adoption. Recent advances in computer vision and deep learning have made it possible to create more affordable and accessible alternatives. This study introduces a novel spatio-temporal transformer network that can accurately predict key gait metrics from single-camera RGB video footage. When tested on a publicly available dataset of patients with cerebral palsy, the proposed framework surpasses existing state-of-the-art methods, achieving significant improvements in predicting general gait metrics (such as walking speed, gait deviation index, and knee flexion angle at maximum extension) while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal and cognitive disabilities frequently face challenges related to mobility and emotional wellness. Traditionally, healthcare professionals have employed gait analysis to identify and address these conditions, but the high cost of motion capture technology has limited its broad implementation. However, breakthroughs in computer vision and deep learning have enabled the development of more cost-effective and accessible solutions. This research presents a novel spatio-temporal transformer network capable of accurately predicting crucial gait metrics from single-camera RGB video recordings. When evaluated using a publicly available dataset of patients with cerebral palsy, the proposed framework outperforms existing state-of-the-art methods, achieving notable improvements in predicting general gait metrics (including walking speed, gait deviation index, and knee flexion angle at maximum extension) while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "People with disabilities affecting their muscles and brain often struggle with moving around and feeling emotionally well. In the past, healthcare professionals have used gait analysis to diagnose and treat these conditions, but the high price of motion capture technology has limited its widespread use. However, advances in computer vision and deep learning have made it possible to develop more affordable and accessible solutions. This study introduces a new spatio-temporal transformer network that can accurately predict important gait metrics from single-camera video recordings. When tested using a publicly available dataset of patients with cerebral palsy, the proposed framework performs better than existing state-of-the-art methods, achieving significant improvements in predicting general gait metrics (including walking speed, gait deviation index, and knee flexion angle at maximum extension) while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals with muscular and neurological disabilities frequently face challenges with mobility and emotional wellbeing. Historically, healthcare providers have utilized gait analysis to identify and address these conditions, but the high cost of motion capture technology has hindered its broader application. Nonetheless, breakthroughs in computer vision and deep learning have enabled the development of more affordable and accessible alternatives. This study presents a novel spatio-temporal transformer network capable of accurately forecasting key gait metrics from single-camera video recordings. When evaluated using a publicly available dataset of patients with cerebral palsy, the proposed framework outperforms existing state-of-the-art methods, achieving substantial improvements in predicting general gait metrics (including walking speed, gait deviation index, and knee flexion angle at maximum extension) while necessitating fewer parameters and eliminating manual feature extraction."
        ],
        [
            "People with muscle and nerve disorders often struggle with moving around and their mental health. Doctors have used gait analysis to diagnose and treat these conditions, but the expensive equipment needed has limited its use. However, advances in computer vision and deep learning have made it possible to create more affordable and accessible options. This study introduces a new spatio-temporal transformer network that can accurately predict important gait metrics from videos recorded with a single camera. When tested on a publicly available dataset of patients with cerebral palsy, the proposed framework performed better than existing top-performing methods, significantly improving predictions of overall gait metrics (such as walking speed, gait deviation index, and knee flexion angle at maximum extension) while requiring fewer parameters and no manual feature extraction."
        ],
        [
            "Individuals afflicted with muscular and neurological disorders frequently face challenges with mobility and mental wellbeing. Gait analysis has been utilized by medical professionals to diagnose and treat these conditions, but the high cost of necessary equipment has restricted its application. Nevertheless, breakthroughs in computer vision and deep learning have enabled the development of more affordable and accessible alternatives. This research presents a novel spatio-temporal transformer network capable of precisely forecasting key gait metrics from videos captured with a single camera. When evaluated on a publicly available dataset of patients with cerebral palsy, the proposed framework outperformed existing top-performing methods, substantially enhancing predictions of overall gait metrics (including walking speed, gait deviation index, and knee flexion angle at maximum extension) while requiring fewer parameters and eliminating manual feature extraction."
        ],
        [
            "People with muscle and nerve disorders often struggle with moving around and their mental health. Doctors have used gait analysis to identify and treat these conditions, but the expensive equipment needed has limited its use. However, advances in computer vision and deep learning have made it possible to create more affordable and accessible options. This study introduces a new spatio-temporal transformer network that can accurately predict important gait metrics from videos recorded with just one camera. Tested on a public dataset of patients with cerebral palsy, the proposed framework performed better than current top methods, significantly improving predictions of overall gait metrics (including walking speed, gait deviation index, and knee flexion angle at maximum extension) while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals affected by muscle and nerve disorders frequently face challenges related to mobility and their mental wellbeing. Gait analysis has been utilized by medical professionals to diagnose and treat these conditions, but the high cost of required equipment has restricted its application. Nevertheless, recent breakthroughs in computer vision and deep learning have enabled the development of more affordable and widely accessible solutions. This research presents a novel spatio-temporal transformer network capable of accurately forecasting key gait metrics from videos captured using a single camera. When tested on a publicly available dataset of patients with cerebral palsy, the proposed framework outperformed current leading methods, significantly enhancing predictions of overall gait metrics (including walking speed, gait deviation index, and knee flexion angle at maximum extension) while requiring fewer parameters and eliminating manual feature extraction."
        ],
        [
            "People with muscle and nerve disorders often struggle with mobility issues and mental health concerns. Healthcare professionals have used gait analysis to identify and manage these conditions, but the expensive equipment required has limited its use. However, advances in computer vision and deep learning have made it possible to create more affordable and accessible solutions. This study introduces a new spatio-temporal transformer network that can accurately predict key gait metrics from videos taken with a single camera. When tested on a publicly available dataset of patients with cerebral palsy, the proposed framework outperformed existing leading methods, significantly improving predictions of overall gait metrics (including walking speed, gait deviation index, and knee flexion angle at maximum extension) while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals affected by muscle and nerve disorders frequently face difficulties with mobility and mental wellbeing. While healthcare providers have utilized gait analysis to diagnose and treat these conditions, the high cost of necessary equipment has restricted its application. Nevertheless, breakthroughs in computer vision and deep learning have enabled the development of more economical and accessible alternatives. This research presents a novel spatio-temporal transformer network capable of accurately forecasting crucial gait metrics from videos captured with a single camera. In testing on a publicly available dataset of patients with cerebral palsy, the proposed framework surpassed existing leading methods, substantially enhancing predictions of overall gait metrics (including walking speed, gait deviation index, and knee flexion angle at maximum extension) while requiring fewer parameters and eliminating manual feature extraction."
        ],
        [
            "People with muscle and nerve disorders often struggle with moving around and maintaining good mental health. Although healthcare professionals have used gait analysis to diagnose and treat these conditions, the expensive equipment needed has limited its use. However, advances in computer vision and deep learning have made it possible to create more affordable and accessible options. This study introduces a new spatio-temporal transformer network that can accurately predict important gait metrics from videos taken with just one camera. When tested on a publicly available dataset of patients with cerebral palsy, the proposed framework outperformed existing top methods, significantly improving predictions of overall gait metrics (such as walking speed, gait deviation index, and knee flexion angle at maximum extension) while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals affected by muscle and nerve disorders frequently face challenges in mobility and mental wellbeing. While gait analysis has been employed by healthcare professionals to diagnose and manage these conditions, the high cost of required equipment has restricted its application. Nevertheless, breakthroughs in computer vision and deep learning have enabled the development of more affordable and accessible alternatives. This research presents a novel spatio-temporal transformer network capable of precisely predicting key gait metrics from single-camera videos. When evaluated using a publicly available dataset of patients with cerebral palsy, the proposed framework surpassed existing top-performing methods, substantially enhancing predictions of overall gait metrics (including walking speed, gait deviation index, and knee flexion angle at maximum extension) while requiring fewer parameters and eliminating manual feature extraction."
        ],
        [
            "People with muscle and nerve disorders often struggle with mobility and mental health issues. Although healthcare professionals have used gait analysis to diagnose and treat these conditions, the expensive equipment required has limited its use. However, advances in computer vision and deep learning have made it possible to create more affordable and accessible alternatives. This research introduces a new spatio-temporal transformer network that can accurately predict important gait metrics from single-camera videos. When tested on a publicly available dataset of patients with cerebral palsy, the proposed framework outperformed existing top-performing methods, significantly improving predictions of overall gait metrics (including walking speed, gait deviation index, and knee flexion angle at maximum extension) while using fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals affected by muscle and nerve disorders frequently face challenges related to mobility and mental wellbeing. Despite the fact that healthcare professionals have employed gait analysis for diagnosis and treatment, the high cost of required equipment has restricted its application. Nevertheless, breakthroughs in computer vision and deep learning have enabled the development of more affordable and accessible solutions. This study presents a novel spatio-temporal transformer network capable of accurately estimating key gait metrics from single-camera video recordings. When evaluated on a publicly available dataset of patients with cerebral palsy, the proposed framework surpassed existing high-performing methods, substantially enhancing predictions of overall gait metrics (including walking speed, gait deviation index, and knee flexion angle at maximum extension) while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "People with muscle and nerve disorders often struggle with mobility and mental health issues. Although healthcare professionals have used gait analysis to diagnose and treat these conditions, the expense of the necessary equipment has limited its use. However, advances in computer vision and deep learning have made it possible to develop more affordable and accessible alternatives. This study introduces a new spatio-temporal transformer network that can accurately estimate important gait metrics from video recordings taken with a single camera. Tested on a public dataset of patients with cerebral palsy, the proposed framework outperformed existing high-performing methods, significantly improving predictions of overall gait metrics (such as walking speed, gait deviation index, and knee flexion angle at maximum extension) while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals affected by muscle and nerve disorders frequently face challenges related to mobility and mental wellbeing. Despite the diagnostic and therapeutic value of gait analysis in addressing these conditions, the high cost of required equipment has restricted its adoption. Nevertheless, breakthroughs in computer vision and deep learning have enabled the development of more economical and accessible solutions. This research presents a novel spatio-temporal transformer network capable of accurately assessing key gait metrics from video recordings captured using a single camera. When evaluated on a publicly available dataset of patients with cerebral palsy, the proposed framework surpassed existing state-of-the-art methods, substantially enhancing predictions of overall gait metrics (including walking speed, gait deviation index, and knee flexion angle at maximum extension) while reducing parameter requirements and eliminating the need for manual feature extraction."
        ],
        [
            "People with muscle and nerve disorders often struggle with mobility and mental health issues. While analyzing a person's gait can be very helpful in diagnosing and treating these conditions, the expensive equipment required has limited its use. However, advances in computer vision and deep learning have made it possible to create more affordable and accessible solutions. This research introduces a new type of neural network that can accurately measure important aspects of a person's gait using video recordings from a single camera. When tested on a dataset of patients with cerebral palsy, this framework outperformed existing methods, significantly improving predictions of overall gait metrics (such as walking speed, gait deviation index, and knee flexion angle at maximum extension) while reducing the need for parameters and manual feature extraction."
        ],
        [
            "Individuals affected by muscle and nerve disorders frequently face challenges related to mobility and mental wellbeing. The analysis of an individual's gait pattern can be a valuable tool in diagnosing and managing these conditions, but the high cost of required equipment has limited its application. Nevertheless, recent breakthroughs in computer vision and deep learning have enabled the development of more cost-effective and accessible solutions. This study presents a novel neural network capable of accurately assessing key aspects of an individual's gait using video footage captured by a single camera. When applied to a dataset of patients with cerebral palsy, this framework demonstrated superior performance to existing methods, significantly enhancing predictions of overall gait metrics (including walking speed, gait deviation index, and knee flexion angle at maximum extension) while minimizing the need for manual input and parameter adjustments."
        ],
        [
            "People with muscle and nerve disorders often struggle with mobility and mental health issues. Analyzing a person's walking pattern can be a helpful diagnostic and management tool, but the expense of the necessary equipment has restricted its use. However, advances in computer vision and deep learning have made it possible to create more affordable and accessible solutions. This study introduces a new neural network that can accurately evaluate important aspects of a person's gait using video recordings from a single camera. When tested on a group of patients with cerebral palsy, this approach outperformed existing methods, significantly improving predictions of overall gait metrics (including walking speed, gait deviation index, and knee flexion angle at maximum extension) while reducing the need for manual input and adjustments."
        ],
        [
            "Individuals afflicted with muscular and neurological disorders frequently face challenges related to mobility and mental wellbeing. The examination of a person's walking pattern can serve as a valuable diagnostic and management aid, but the high cost of the required equipment has limited its application. Nevertheless, breakthroughs in computer vision and deep learning have enabled the development of more cost-effective and accessible alternatives. This research presents a novel neural network capable of precisely assessing key aspects of an individual's gait using video footage captured by a single camera. When applied to a cohort of patients with cerebral palsy, this approach surpassed existing methods, significantly enhancing predictions of overall gait metrics (including walking speed, gait deviation index, and knee flexion angle at maximum extension) while minimizing the need for manual intervention and adjustments."
        ],
        [
            "People with muscular and neurological conditions often struggle with mobility and mental health issues. Analyzing a person's walking pattern can be a valuable tool for diagnosis and treatment, but the expensive equipment required has limited its use. However, advances in computer vision and deep learning have made it possible to develop more affordable and accessible alternatives. This study introduces a new neural network that can accurately evaluate key elements of a person's gait using video footage from a single camera. When tested on patients with cerebral palsy, this approach outperformed existing methods, significantly improving predictions of overall gait metrics (such as walking speed, gait deviation index, and knee flexion angle at maximum extension) while reducing the need for manual adjustments."
        ],
        [
            "Individuals afflicted with muscular and neurological disorders frequently face challenges related to mobility and mental wellbeing. The analysis of an individual's gait pattern serves as a valuable diagnostic and therapeutic tool, but the high cost of necessary equipment has restricted its application. Nevertheless, breakthroughs in computer vision and deep learning have enabled the development of more cost-effective and accessible alternatives. This research presents a novel neural network capable of precisely assessing crucial aspects of an individual's gait through video footage captured by a single camera. When applied to patients with cerebral palsy, this approach surpassed existing methods, substantially enhancing predictions of overall gait metrics (including walking velocity, gait deviation index, and knee flexion angle at maximum extension) while minimizing the need for manual calibrations."
        ],
        [
            "People with muscle and nerve disorders often struggle with mobility and mental health issues. Examining a person's walking pattern is a valuable way to diagnose and treat these conditions, but the expensive equipment needed has limited its use. However, advances in computer vision and deep learning have made it possible to create more affordable and accessible options. This study introduces a new neural network that can accurately analyze key aspects of a person's gait using video recordings from a single camera. When tested on patients with cerebral palsy, this approach outperformed existing methods, significantly improving predictions of overall gait metrics (such as walking speed, gait deviation, and knee bend) while reducing the need for manual adjustments."
        ],
        [
            "Individuals afflicted with muscle and nerve disorders frequently face challenges related to mobility and mental wellbeing. Analyzing an individual's gait pattern is a valuable diagnostic and therapeutic tool for these conditions, but the high cost of necessary equipment has hindered its widespread adoption. Nevertheless, breakthroughs in computer vision and deep learning have enabled the development of more cost-effective and accessible alternatives. This research presents a novel neural network capable of precisely assessing crucial elements of a person's gait via video footage captured by a single camera. When evaluated on patients with cerebral palsy, this approach surpassed existing methods, significantly enhancing predictions of overall gait metrics (including walking speed, gait deviation, and knee bend) while minimizing the need for manual corrections."
        ],
        [
            "People struggling with muscle and nerve disorders often encounter difficulties with movement and mental health. Examining a person's walking pattern is a valuable method for diagnosing and treating these conditions, but the expense of required equipment has limited its use. However, advances in computer vision and deep learning have led to the creation of more affordable and accessible options. This study introduces a new neural network that can accurately analyze key aspects of a person's gait using video recordings from a single camera. When tested on patients with cerebral palsy, this approach outperformed existing methods, significantly improving predictions of overall gait metrics (including walking speed, gait deviation, and knee bend) while reducing the need for manual adjustments."
        ],
        [
            "Individuals coping with muscular and neurological disorders frequently face challenges related to mobility and mental wellbeing. Assessing an individual's walking pattern is a valuable diagnostic and therapeutic tool for these conditions, but the high cost of necessary equipment has restricted its application. Nevertheless, breakthroughs in computer vision and deep learning have given rise to more economical and accessible alternatives. This research presents a novel neural network capable of precisely analyzing essential features of a person's gait using video footage from a single camera. When applied to patients with cerebral palsy, this approach surpassed existing methods, substantially enhancing predictions of overall gait metrics (including walking speed, gait deviation, and knee bend) while minimizing the need for manual interventions."
        ],
        [
            "People dealing with muscle and nerve disorders often struggle with moving around and mental health. Examining how someone walks is a valuable way to diagnose and treat these conditions, but the expensive equipment needed has limited its use. However, recent advances in computer vision and deep learning have led to more affordable and accessible options. This study introduces a new neural network that can accurately analyze key aspects of a person's walking pattern using video from just one camera. When tested on patients with cerebral palsy, this approach outperformed existing methods, significantly improving predictions of overall walking abilities (such as speed, balance, and knee movement) while reducing the need for human involvement."
        ],
        [
            "Individuals suffering from muscle and nerve disorders often face challenges with mobility and mental wellbeing. Gait analysis has proven to be a valuable diagnostic and treatment tool for these conditions, but its widespread adoption has been hindered by the high cost of required equipment. Fortunately, breakthroughs in computer vision and deep learning have paved the way for more affordable and accessible solutions. This research presents a novel neural network capable of accurately assessing key elements of an individual's gait pattern using video footage from a single camera. When applied to patients with cerebral palsy, this approach surpassed existing methods, significantly enhancing predictions of overall mobility (including speed, balance, and knee movement) while minimizing the need for human intervention."
        ],
        [
            "People with muscle and nerve disorders often struggle with mobility issues and poor mental health. While gait analysis has shown promise in diagnosing and treating these conditions, its use has been limited due to the high expense of the necessary equipment. However, recent advances in computer vision and deep learning have made it possible to develop more affordable and accessible alternatives. This study introduces a new neural network that can accurately evaluate key aspects of an individual's gait using video recordings from a single camera. When tested on patients with cerebral palsy, this approach outperformed existing methods, significantly improving predictions of overall mobility (including speed, balance, and knee movement) while reducing the need for human involvement."
        ],
        [
            "Individuals afflicted with muscle and nerve disorders frequently face challenges related to mobility and mental wellbeing. Although gait analysis has demonstrated potential in diagnosing and managing these conditions, its adoption has been hindered by the prohibitively high cost of required equipment. Nevertheless, breakthroughs in computer vision and deep learning have enabled the development of more cost-effective and accessible solutions. This research presents a novel neural network capable of precisely assessing crucial gait parameters using video footage from a single camera. In trials involving patients with cerebral palsy, this approach surpassed existing methods, markedly enhancing predictions of overall mobility (encompassing speed, balance, and knee movement) while minimizing the need for human intervention."
        ],
        [
            "People with muscle and nerve disorders often struggle with mobility and mental health issues. While gait analysis has shown promise in diagnosing and treating these conditions, its widespread adoption has been limited by the expensive equipment required. However, advances in computer vision and deep learning have paved the way for more affordable and accessible alternatives. This study introduces a new neural network that accurately measures key gait parameters using video recordings from a single camera. In clinical trials with patients with cerebral palsy, this approach outperformed existing methods, significantly improving predictions of overall mobility (including speed, balance, and knee movement) while reducing the need for human involvement."
        ],
        [
            "Individuals affected by muscle and nerve disorders frequently face challenges related to mobility and mental wellbeing. Although gait analysis has demonstrated potential in identifying and addressing these conditions, its broader implementation has been hindered by the high cost of required equipment. Nevertheless, breakthroughs in computer vision and deep learning have enabled the development of more cost-effective and accessible solutions. This research presents a novel neural network capable of accurately assessing crucial gait metrics using video footage from a single camera. In clinical trials involving patients with cerebral palsy, this approach surpassed existing methods, substantially enhancing predictions of overall mobility (encompassing speed, balance, and knee movement) while minimizing the need for human intervention."
        ],
        [
            "People with muscle and nerve disorders often struggle with mobility and mental health issues. While gait analysis has shown promise in diagnosing and treating these conditions, its widespread adoption has been limited by the expensive equipment required. However, advances in computer vision and deep learning have made it possible to create more affordable and accessible alternatives. This study introduces a new neural network that can accurately measure key gait indicators using video footage from a single camera. In clinical tests with cerebral palsy patients, this approach outperformed existing methods, significantly improving predictions of overall mobility (including speed, balance, and knee movement) while reducing the need for human involvement."
        ],
        [
            "Individuals afflicted with muscular and nervous system disorders frequently face challenges related to mobility and mental wellbeing. Although gait analysis has demonstrated potential in identifying and addressing these conditions, its broad implementation has been hindered by the costly equipment necessary for its operation. Nevertheless, breakthroughs in computer vision and deep learning have enabled the development of more economical and accessible alternatives. This research presents a novel neural network capable of accurately assessing crucial gait metrics using video recordings from a single camera. In clinical trials involving patients with cerebral palsy, this approach surpassed existing methods, markedly enhancing predictions of overall mobility (encompassing speed, balance, and knee movement) while minimizing the requirement for human intervention."
        ],
        [
            "People with muscular and nervous system disorders often struggle with mobility and mental health issues. Gait analysis has shown promise in diagnosing and treating these conditions, but its widespread adoption has been limited by the high cost of the necessary equipment. However, advances in computer vision and deep learning have made it possible to create more affordable and accessible alternatives. This study introduces a new neural network that can accurately measure key gait metrics using video footage from a single camera. In clinical trials with cerebral palsy patients, this approach outperformed existing methods, significantly improving predictions of overall mobility (including speed, balance, and knee movement) while reducing the need for human involvement."
        ],
        [
            "Individuals affected by muscular and nervous system disorders frequently face challenges related to mobility and mental wellbeing. Although gait analysis has demonstrated potential in identifying and addressing these conditions, its broad implementation has been hindered by the prohibitive cost of required equipment. Nevertheless, breakthroughs in computer vision and deep learning have enabled the development of more economical and accessible solutions. This research presents a novel neural network capable of precisely assessing crucial gait parameters using video recordings from a single camera. In clinical tests involving patients with cerebral palsy, this approach surpassed existing methods, substantially enhancing predictions of overall mobility (encompassing speed, balance, and knee movement) while minimizing the need for human intervention."
        ],
        [
            "People with muscle and nerve disorders often struggle with mobility and mental health issues. Gait analysis has shown promise in diagnosing and treating these conditions, but its widespread adoption has been limited by the high cost of the necessary equipment. However, advances in computer vision and deep learning have made it possible to develop more affordable and accessible alternatives. This study introduces a new neural network that can accurately measure key gait metrics using video footage from a single camera. In clinical trials with cerebral palsy patients, this approach outperformed existing methods, significantly improving predictions of overall mobility (including speed, balance, and knee movement) while reducing the need for human involvement."
        ],
        [
            "Individuals affected by muscle and nerve disorders frequently face challenges related to mobility and mental wellbeing. While gait analysis has demonstrated potential in identifying and addressing these conditions, its broad implementation has been hindered by the prohibitive expense of the required technology. Nevertheless, breakthroughs in computer vision and deep learning have enabled the creation of more cost-effective and accessible solutions. This research presents a novel neural network capable of precisely measuring crucial gait parameters using video recordings from a single camera. In clinical trials involving patients with cerebral palsy, this approach surpassed existing methods, substantially enhancing predictions of overall mobility (encompassing speed, balance, and knee movement) while minimizing the need for human intervention."
        ],
        [
            "People with muscle and nerve disorders often struggle with mobility and mental health issues. Although gait analysis has shown promise in diagnosing and treating these conditions, its widespread adoption has been limited by the high cost of the necessary equipment. However, advances in computer vision and deep learning have made it possible to develop more affordable and accessible alternatives. This study introduces a new neural network that can accurately measure key gait metrics using video footage from a single camera. In clinical tests with patients with cerebral palsy, this approach outperformed existing methods, significantly improving predictions of overall mobility (including speed, balance, and knee movement) while reducing the need for human involvement."
        ],
        [
            "Individuals afflicted with muscle and nerve disorders frequently face challenges related to mobility and mental wellbeing. Despite the potential of gait analysis in identifying and managing these conditions, its broader implementation has been hindered by the prohibitively expensive equipment required. Nevertheless, breakthroughs in computer vision and deep learning have enabled the development of more economical and accessible solutions. This research presents a novel neural network capable of precisely measuring crucial gait indicators using video recordings from a single camera. In clinical trials involving patients with cerebral palsy, this approach surpassed existing methods, substantially enhancing predictions of overall mobility (encompassing speed, balance, and knee movement) while minimizing the need for human intervention."
        ],
        [
            "People with muscle and nerve disorders often struggle with mobility and mental health issues. Although gait analysis has the potential to diagnose and manage these conditions, its widespread adoption has been limited by the high cost of the necessary equipment. However, recent advances in computer vision and deep learning have made it possible to develop more affordable and accessible alternatives. This study introduces a new neural network that can accurately measure key gait metrics using video footage from a single camera. In clinical trials with patients with cerebral palsy, this approach outperformed existing methods, significantly improving predictions of overall mobility (including speed, balance, and knee movement) while reducing the need for human involvement."
        ]
    ]
}