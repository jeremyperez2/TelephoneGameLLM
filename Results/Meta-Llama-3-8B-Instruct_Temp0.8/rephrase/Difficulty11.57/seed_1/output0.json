{
    "adjacency_matrix": [
        [
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0
        ]
    ],
    "prompt_init": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "prompt_update": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "personality_list": [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        ""
    ],
    "format_prompt": [
        ""
    ],
    "initial_story": "having the potential for high speed, high throughput, and low energy cost,optical neural networks (onns) have emerged as a promising candidate foraccelerating deep learning tasks. in conventional onns, light amplitudes aremodulated at the input and detected at the output. however, the light phasesare still ignored in conventional structures, although they can also carryinformation for computing. to address this issue, in this paper, we propose aframework called oplixnet to compress the areas of onns by modulating inputimage data into the amplitudes and phase parts of light signals. the input andoutput parts of the onns are redesigned to make full use of both amplitude andphase information. moreover, mutual learning across different onn structures isintroduced to maintain the accuracy. experimental results demonstrate that theproposed framework significantly reduces the areas of onns with the accuracywithin an acceptable range. for instance, 75.03% area is reduced with a 0.33%accuracy decrease on fully connected neural network (fcnn) and 74.88% area isreduced with a 2.38% accuracy decrease on resnet-32. ",
    "stories": [
        [
            "Optical neural networks, boasting high speed, high throughput, and low energy costs, have become a promising approach to accelerate deep learning tasks. Traditional ONNs modulate light amplitudes at the input and detect them at the output, but neglect light phases, which can also convey information for computation. To address this limitation, we introduce Oplixnet, a framework that compresses ONN areas by modulating input image data into amplitude and phase parts of light signals. By redesigning the input and output parts to utilize both amplitude and phase information, and introducing mutual learning across different ONN structures to maintain accuracy, our framework significantly reduces ONN areas while preserving acceptable accuracy. Experimental results demonstrate this, with, for instance, a 75.03% area reduction and 0.33% accuracy decrease for fully connected neural networks, and a 74.88% area reduction and 2.38% accuracy decrease for ResNet-32."
        ],
        [
            "We propose Oplixnet, a novel framework for optical neural networks that leverages both amplitude and phase information of light signals to accelerate deep learning tasks while minimizing energy consumption and area usage. By splitting input image data into amplitude and phase components, and redesigning the input and output layers to utilize both, Oplixnet achieves significant area reductions without compromising accuracy. Experimental results show a 75.03% area reduction with a 0.33% accuracy decrease for fully connected neural networks, and a 74.88% area reduction with a 2.38% accuracy decrease for ResNet-32."
        ],
        [
            "We introduce Oplixnet, a pioneering framework for optical neural networks that harnesses the amplitude and phase properties of light signals to expedite deep learning processes while minimizing energy expenditure and physical space. By decomposing input image data into amplitude and phase components, and reconfiguring the input and output layers to incorporate both, Oplixnet yields substantial reductions in area without compromising precision. Experimental findings demonstrate a 75.03% area decrease with a 0.33% loss in accuracy for fully connected neural networks, and a 74.88% area decrease with a 2.38% loss in accuracy for ResNet-32."
        ],
        [
            "Here is the rephrased text:\n\nWe present Oplixnet, a groundbreaking framework for optical neural networks that leverages the amplitude and phase properties of light signals to accelerate deep learning processes, reduce energy consumption, and minimize physical space requirements. By breaking down input image data into amplitude and phase components, and redesigning the input and output layers to incorporate both, Oplixnet achieves significant reductions in area without sacrificing precision. Experimental results show a 75.03% decrease in area with a 0.33% loss in accuracy for fully connected neural networks, and a 74.88% area decrease with a 2.38% loss in accuracy for ResNet-32."
        ],
        [
            "Here is the rephrased text:\n\nWe introduce Oplixnet, a pioneering framework for optical neural networks that harnesses the amplitude and phase properties of light signals to accelerate deep learning processes, minimize energy consumption, and optimize physical space usage. By decomposing input image data into amplitude and phase components and reconfiguring the input and output layers to incorporate both, Oplixnet yields substantial area reductions without compromising precision. Experimental findings indicate a 75.03% decrease in area with a 0.33% loss in accuracy for fully connected neural networks, and a 74.88% area decrease with a 2.38% loss in accuracy for ResNet-32."
        ],
        [
            "Introducing Oplixnet, a groundbreaking framework for optical neural networks, which leverages the amplitude and phase characteristics of light signals to speed up deep learning processes, reduce energy consumption, and optimize physical space utilization. By separating input image data into amplitude and phase components and reorganizing the input and output layers to incorporate both, Oplixnet achieves significant area reductions without compromising accuracy. Experimental results demonstrate a 75.03% area reduction with a 0.33% loss in accuracy for fully connected neural networks, and a 74.88% area decrease with a 2.38% loss in accuracy for ResNet-32."
        ],
        [
            "Here is the rephrased text:\n\nMeet Oplixnet, a pioneering framework that revolutionizes optical neural networks by exploiting the amplitude and phase properties of light signals to accelerate deep learning processes, minimize energy usage, and optimize spatial allocation. By segmenting input image data into amplitude and phase components and rearranging input and output layers to accommodate both, Oplixnet achieves substantial area reductions without sacrificing precision. Experimental findings show a 75.03% area reduction with a 0.33% decrease in accuracy for fully connected neural networks, and a 74.88% area decrease with a 2.38% drop in accuracy for ResNet-32."
        ],
        [
            "Here is the rephrased text:\n\nIntroducing Oplixnet, a groundbreaking framework that harnesses the power of light signals' amplitude and phase properties to accelerate deep learning, reduce energy consumption, and optimize spatial distribution. By dividing input image data into amplitude and phase components and restructuring input and output layers to accommodate both, Oplixnet achieves significant area reductions without compromising precision. Experimental results demonstrate a 75.03% area reduction with a 0.33% decrease in accuracy for fully connected neural networks and a 74.88% area decrease with a 2.38% drop in accuracy for ResNet-32."
        ],
        [
            "Here is the rephrased text: \n\nOplixnet is a pioneering framework that leverages the characteristics of light signals to expedite deep learning, minimize energy consumption, and optimize spatial arrangement. By separating input image data into amplitude and phase components and modifying the input and output layers to accommodate both, Oplixnet achieves substantial reductions in area without sacrificing precision. Experimental outcomes show a 75.03% area reduction with a 0.33% decline in accuracy for fully connected neural networks and a 74.88% area decrease with a 2.38% drop in accuracy for ResNet-32."
        ],
        [
            "Oplixnet is a groundbreaking framework that utilizes the properties of light signals to accelerate deep learning, reduce energy consumption, and optimize spatial organization. By splitting input image data into amplitude and phase components and adapting the input and output layers to accommodate both, Oplixnet achieves significant area reductions without compromising precision. Experimental results demonstrate a 75.03% area reduction with a 0.33% decrease in accuracy for fully connected neural networks and a 74.88% area decrease with a 2.38% drop in accuracy for ResNet-32."
        ],
        [
            "A revolutionary framework, Oplixnet, harnesses the power of light signals to expedite deep learning, minimize energy consumption, and enhance spatial arrangement. By dividing input image data into amplitude and phase components, and adjusting input and output layers to accommodate both, Oplixnet achieves substantial area reductions without sacrificing precision. Experimental outcomes show a 75.03% area reduction accompanied by a 0.33% decline in accuracy for fully connected neural networks, and a 74.88% area decrease accompanied by a 2.38% drop in accuracy for ResNet-32."
        ],
        [
            "A groundbreaking architecture, Oplixnet, leverages light signal processing to accelerate deep learning, reduce energy expenditure, and optimize spatial organization. By separating input image data into amplitude and phase elements, and modifying input and output layers to incorporate both, Oplixnet achieves significant area reductions without compromising precision. Experimental results demonstrate a 75.03% area reduction alongside a 0.33% accuracy loss for fully connected neural networks, and a 74.88% area decrease accompanied by a 2.38% accuracy decline for ResNet-32."
        ],
        [
            "Oplixnet, a pioneering architecture, harnesses light signal processing to accelerate deep learning, minimize energy consumption, and optimize spatial arrangement. By splitting input image data into amplitude and phase components, and adapting input and output layers to accommodate both, Oplixnet achieves substantial reductions in area without sacrificing precision. Experimental findings show a 75.03% area reduction with a 0.33% loss in accuracy for fully connected neural networks, and a 74.88% area decrease accompanied by a 2.38% decline in accuracy for ResNet-32."
        ],
        [
            "Oplixnet, a groundbreaking architecture, leverages light signal processing to expedite deep learning, reduce energy expenditure, and optimize spatial organization. By separating input image data into amplitude and phase components, and tailoring input and output layers to accommodate both, Oplixnet yields significant reductions in area without compromising precision. Experimental results demonstrate a 75.03% area reduction with a 0.33% loss in accuracy for fully connected neural networks, as well as a 74.88% area decrease accompanied by a 2.38% decline in accuracy for ResNet-32."
        ],
        [
            "Oplixnet, a pioneering architecture, utilizes light signal processing to accelerate deep learning, minimize energy consumption, and enhance spatial organization. By splitting input image data into amplitude and phase components, and customizing input and output layers to accommodate both, Oplixnet achieves substantial reductions in area without sacrificing precision. Experimental findings show a 75.03% area reduction with a 0.33% loss in accuracy for fully connected neural networks, as well as a 74.88% area decrease accompanied by a 2.38% decline in accuracy for ResNet-32."
        ],
        [
            "Here is the rephrased text:\n\nOplixnet, a groundbreaking architecture, employs light signal processing to expedite deep learning, reduce energy expenditure, and improve spatial organization. By dividing input image data into amplitude and phase components, and tailoring input and output layers to accommodate both, Oplixnet achieves significant reductions in area without compromising precision. Experimental results demonstrate a 75.03% area reduction with a minimal 0.33% loss in accuracy for fully connected neural networks, and a 74.88% area decrease accompanied by a 2.38% decline in accuracy for ResNet-32."
        ],
        [
            "Here is the rephrased text:\n\nOplixnet, a pioneering architecture, leverages light signal processing to accelerate deep learning, minimize energy consumption, and optimize spatial arrangement. By separating input image data into amplitude and phase components, and customizing input and output layers to accommodate both, Oplixnet achieves substantial reductions in area without sacrificing precision. Experimental findings reveal a 75.03% area decrease alongside a 0.33% loss in accuracy for fully connected neural networks, as well as a 74.88% area reduction accompanied by a 2.38% decline in accuracy for ResNet-32."
        ],
        [
            "Oplixnet, a groundbreaking architecture, utilizes light signal processing to hasten deep learning, reduce energy expenditure, and optimize spatial organization. By dividing input image data into amplitude and phase components, and tailoring input and output layers to accommodate both, Oplixnet achieves significant reductions in area without compromising precision. Experimental results show a 75.03% decrease in area alongside a 0.33% loss in accuracy for fully connected neural networks, as well as a 74.88% area reduction accompanied by a 2.38% decline in accuracy for ResNet-32."
        ],
        [
            "Oplixnet, a pioneering innovation, leverages light signal processing to accelerate deep learning, minimize energy consumption, and optimize spatial arrangement. By separating input image data into amplitude and phase components, and customizing input and output layers to accommodate both, Oplixnet achieves substantial area reductions without sacrificing precision. Experimental findings demonstrate a 75.03% decrease in area alongside a 0.33% loss in accuracy for fully connected neural networks, as well as a 74.88% area reduction accompanied by a 2.38% decline in accuracy for ResNet-32."
        ],
        [
            "Oplixnet, a groundbreaking innovation, uses light signal processing to hasten deep learning, reduce energy expenditure, and optimize spatial configuration. By dividing input image data into amplitude and phase components, and tailoring input and output layers to accommodate both, Oplixnet achieves significant area reductions without compromising precision. Experimental results show a 75.03% decrease in area accompanied by a 0.33% loss in accuracy for fully connected neural networks, as well as a 74.88% area reduction coupled with a 2.38% decline in accuracy for ResNet-32."
        ],
        [
            "Oplixnet, a pioneering innovation, employs light signal processing to accelerate deep learning, minimize energy consumption, and optimize spatial arrangements. By separating input image data into amplitude and phase components, and adapting both input and output layers to accommodate these components, Oplixnet achieves substantial reductions in area without sacrificing precision. Experimental results demonstrate a 75.03% area reduction accompanied by a 0.33% loss in accuracy for fully connected neural networks, and a 74.88% area reduction coupled with a 2.38% decline in accuracy for ResNet-32."
        ],
        [
            "Oplixnet, a groundbreaking innovation, leverages light signal processing to accelerate deep learning, reduce energy consumption, and optimize spatial arrangements. By decomposing input image data into amplitude and phase components, and adjusting both input and output layers to accommodate these components, Oplixnet achieves significant area reductions without compromising precision. Experimental findings show a 75.03% area reduction accompanied by a 0.33% loss in accuracy for fully connected neural networks, as well as a 74.88% area reduction coupled with a 2.38% decline in accuracy for ResNet-32."
        ],
        [
            "Oplixnet, a revolutionary technology, uses light signal processing to accelerate deep learning, minimize energy consumption, and optimize spatial arrangements. By breaking down input image data into amplitude and phase components and adjusting both input and output layers to accommodate these components, Oplixnet achieves substantial area reductions without sacrificing precision. Experimental results demonstrate a 75.03% area reduction accompanied by a 0.33% loss in accuracy for fully connected neural networks, as well as a 74.88% area reduction coupled with a 2.38% decline in accuracy for ResNet-32."
        ],
        [
            "Oplixnet, a groundbreaking innovation, employs light signal processing to expedite deep learning, reduce energy expenditure, and streamline spatial layouts. By decomposing input image data into amplitude and phase components, and adjusting both input and output layers to accommodate these components, Oplixnet achieves significant area reductions without compromising precision. Experimental outcomes show a 75.03% area reduction with a 0.33% loss in accuracy for fully connected neural networks, as well as a 74.88% area reduction accompanied by a 2.38% decline in accuracy for ResNet-32."
        ],
        [
            "Oplixnet, a revolutionary technology, utilizes light signal processing to accelerate deep learning, minimize energy consumption, and simplify spatial arrangements. By breaking down input image data into amplitude and phase elements, and adjusting both input and output layers to incorporate these elements, Oplixnet achieves substantial area reductions without sacrificing precision. Experimental results demonstrate a 75.03% area reduction with a 0.33% decrease in accuracy for fully connected neural networks, as well as a 74.88% area reduction accompanied by a 2.38% decline in accuracy for ResNet-32."
        ],
        [
            "Oplixnet, a groundbreaking innovation, harnesses light signal processing to speed up deep learning, reduce energy consumption, and streamline spatial configurations. By dissecting input image data into amplitude and phase components, and adjusting both input and output layers to incorporate these components, Oplixnet achieves significant area reductions without compromising precision. Experimental findings show a 75.03% area reduction with a 0.33% decrease in accuracy for fully connected neural networks, as well as a 74.88% area reduction accompanied by a 2.38% decline in accuracy for ResNet-32."
        ],
        [
            "Oplixnet, a pioneering technology, leverages light signal processing to accelerate deep learning, minimize energy consumption, and simplify spatial arrangements. By separating input image data into amplitude and phase elements, and modifying both input and output layers to incorporate these elements, Oplixnet achieves substantial area reductions without sacrificing precision. Experimental results demonstrate a 75.03% area reduction with a 0.33% decrease in accuracy for fully connected neural networks, as well as a 74.88% area reduction accompanied by a 2.38% decline in accuracy for ResNet-32."
        ],
        [
            "Oplixnet, a groundbreaking technology, utilizes light signal processing to expedite deep learning, reduce energy usage, and streamline spatial configurations. By compartmentalizing input image data into amplitude and phase components, and adjusting both input and output layers to integrate these components, Oplixnet achieves substantial area reductions without compromising precision. Experimental outcomes reveal a 75.03% area reduction accompanied by a 0.33% decrease in accuracy for fully connected neural networks, as well as a 74.88% area reduction accompanied by a 2.38% decline in accuracy for ResNet-32."
        ],
        [
            "Oplixnet, a pioneering technology, leverages light signal processing to accelerate deep learning, minimize energy consumption, and simplify spatial arrangements. By separating input image data into amplitude and phase components, and adapting both input and output layers to combine these components, Oplixnet achieves significant area reductions without sacrificing precision. Test results show a 75.03% area reduction with a 0.33% drop in accuracy for fully connected neural networks, as well as a 74.88% area reduction with a 2.38% decrease in accuracy for ResNet-32."
        ],
        [
            "Oplixnet, a groundbreaking innovation, uses light signal processing to speed up deep learning, reduce energy usage, and streamline spatial configurations. By breaking down input image data into amplitude and phase components, and adjusting both input and output layers to combine these components, Oplixnet achieves substantial area reductions without compromising precision. Experimental findings reveal a 75.03% area reduction with a 0.33% decline in accuracy for fully connected neural networks, as well as a 74.88% area reduction with a 2.38% decrease in accuracy for ResNet-32."
        ],
        [
            "Oplixnet, a pioneering innovation, employs light signal processing to accelerate deep learning, decrease energy consumption, and optimize spatial arrangements. By decomposing input image data into amplitude and phase components, and adjusting both input and output layers to integrate these components, Oplixnet achieves significant area reductions without sacrificing precision. Experimental results show a 75.03% area reduction with a 0.33% decrease in accuracy for fully connected neural networks, as well as a 74.88% area reduction with a 2.38% decrease in accuracy for ResNet-32."
        ],
        [
            "Oplixnet, a groundbreaking technology, uses light signal processing to hasten deep learning, reduce energy expenditure, and streamline spatial layouts. By breaking down input image data into amplitude and phase components, and fine-tuning both input and output layers to combine these components, Oplixnet achieves substantial area reductions without compromising precision. Experimental findings indicate a 75.03% area reduction with a 0.33% decrease in accuracy for fully connected neural networks, as well as a 74.88% area reduction with a 2.38% decrease in accuracy for ResNet-32."
        ],
        [
            "Oplixnet, a pioneering technology, leverages light signal processing to accelerate deep learning, minimize energy consumption, and simplify spatial arrangements. By dissecting input image data into amplitude and phase components, and optimizing both input and output layers to combine these components, Oplixnet realizes significant area savings without sacrificing precision. Experimental results demonstrate a 75.03% area reduction accompanied by a 0.33% decrease in accuracy for fully connected neural networks, as well as a 74.88% area reduction with a 2.38% decrease in accuracy for ResNet-32."
        ],
        [
            "Oplixnet, a groundbreaking innovation, uses light signal processing to speed up deep learning, reduce energy usage, and simplify spatial configurations. By splitting input image data into amplitude and phase components, and optimizing both input and output layers to combine these components, Oplixnet achieves substantial area reductions without compromising precision. Experimental outcomes show a 75.03% area decrease accompanied by a 0.33% drop in accuracy for fully connected neural networks, as well as a 74.88% area reduction with a 2.38% drop in accuracy for ResNet-32."
        ],
        [
            "Oplixnet, a revolutionary technology, leverages light signal processing to accelerate deep learning, minimize energy consumption, and simplify spatial arrangements. By separating input image data into amplitude and phase components, and optimizing both input and output layers to combine these components, Oplixnet achieves significant area reductions without sacrificing precision. Experimental results demonstrate a 75.03% area decrease accompanied by a 0.33% decline in accuracy for fully connected neural networks, as well as a 74.88% area reduction with a 2.38% drop in accuracy for ResNet-32."
        ],
        [
            "Oplixnet, a groundbreaking innovation, harnesses light signal processing to expedite deep learning, reduce energy expenditure, and simplify spatial configurations. By decomposing input image data into amplitude and phase components, and fine-tuning both input and output layers to combine these components effectively, Oplixnet achieves substantial area reductions without compromising precision. Experimental findings show a 75.03% decrease in area with a 0.33% drop in accuracy for fully connected neural networks, as well as a 74.88% area reduction accompanied by a 2.38% decline in accuracy for ResNet-32."
        ],
        [
            "Oplixnet, a pioneering technology, leverages light signal processing to accelerate deep learning, minimize energy consumption, and streamline spatial arrangements. By splitting input image data into amplitude and phase components, and adjusting both input and output layers to seamlessly integrate these components, Oplixnet achieves significant area reductions without sacrificing precision. Experimental results indicate a 75.03% area decrease with a 0.33% drop in accuracy for fully connected neural networks, as well as a 74.88% area reduction accompanied by a 2.38% decline in accuracy for ResNet-32."
        ],
        [
            "Oplixnet, a groundbreaking innovation, utilizes light signal processing to expedite deep learning, reduce energy expenditure, and optimize spatial configurations. By dissecting input image data into amplitude and phase components, and harmonizing both input and output layers to seamlessly combine these components, Oplixnet achieves substantial area reductions without compromising precision. Experimental findings demonstrate a 75.03% area decrease accompanied by a 0.33% decline in accuracy for fully connected neural networks, as well as a 74.88% area reduction accompanied by a 2.38% drop in accuracy for ResNet-32."
        ],
        [
            "Oplixnet, a pioneering technology, harnesses light signal processing to accelerate deep learning, minimize energy consumption, and refine spatial arrangements. By breaking down input image data into amplitude and phase components, and synchronizing both input and output layers to seamlessly integrate these components, Oplixnet achieves significant area reductions without sacrificing precision. Experimental results show a 75.03% area decrease accompanied by a 0.33% decline in accuracy for fully connected neural networks, as well as a 74.88% area reduction accompanied by a 2.38% drop in accuracy for ResNet-32."
        ],
        [
            "Oplixnet, a groundbreaking technology, utilizes light signal processing to expedite deep learning, reduce energy expenditure, and optimize spatial organization. By decomposing input image data into amplitude and phase components, and synchronizing both input and output layers to merge these components harmoniously, Oplixnet achieves substantial area reductions without compromising precision. Experimental findings demonstrate a 75.03% area decrease accompanied by a 0.33% decline in accuracy for fully connected neural networks, as well as a 74.88% area reduction accompanied by a 2.38% drop in accuracy for ResNet-32."
        ],
        [
            "Oplixnet, a pioneering technology, employs light signal processing to accelerate deep learning, minimize energy consumption, and streamline spatial arrangements. By separating input image data into amplitude and phase components and synchronizing both input and output layers to harmonize these components, Oplixnet achieves significant area reductions without sacrificing precision. Experimental results show a 75.03% area decrease and a 0.33% decrease in accuracy for fully connected neural networks, as well as a 74.88% area reduction and a 2.38% drop in accuracy for ResNet-32."
        ],
        [
            "Oplixnet, a groundbreaking innovation, harnesses light signal processing to accelerate deep learning, reduce energy consumption, and optimize spatial layouts. By splitting input image data into amplitude and phase components and synchronizing both input and output layers to harmonize these components, Oplixnet achieves substantial area reductions without compromising accuracy. Experimental findings reveal a 75.03% area decrease and a 0.33% decrease in accuracy for fully connected neural networks, as well as a 74.88% area reduction and a 2.38% drop in accuracy for ResNet-32."
        ],
        [
            "A revolutionary technology, Oplixnet, utilizes light signal processing to expedite deep learning, minimize energy consumption, and optimize spatial arrangements. By separating input image data into amplitude and phase parts and synchronizing input and output layers to harmonize these components, Oplixnet achieves significant area reductions without sacrificing precision. Experimental results show a 75.03% area decrease and a 0.33% decline in accuracy for fully connected neural networks, as well as a 74.88% area reduction and a 2.38% drop in accuracy for ResNet-32."
        ],
        [
            "Oplixnet, a groundbreaking innovation, employs light signal processing to accelerate deep learning, reduce energy consumption, and optimize spatial layouts. By dividing input image data into amplitude and phase components and synchronizing input and output layers to harmonize these parts, Oplixnet achieves substantial area reductions without compromising precision. Experimental findings demonstrate a 75.03% area decrease and a 0.33% decline in accuracy for fully connected neural networks, as well as a 74.88% area reduction and a 2.38% drop in accuracy for ResNet-32."
        ],
        [
            "Oplixnet, a pioneering technology, utilizes light signal processing to expedite deep learning, minimize energy consumption, and refine spatial arrangements. By segmenting input image data into amplitude and phase components and synchronizing input and output layers to align these parts, Oplixnet achieves substantial area reductions without compromising precision. Experimental results show a 75.03% decrease in area and a 0.33% decrease in accuracy for fully connected neural networks, as well as a 74.88% reduction in area and a 2.38% decline in accuracy for ResNet-32."
        ],
        [
            "Oplixnet, a groundbreaking innovation, leverages light signal processing to accelerate deep learning, reduce energy consumption, and optimize spatial layouts. By separating input image data into amplitude and phase components and synchronizing input and output layers to align these parts, Oplixnet achieves significant area reductions without sacrificing precision. Experimental findings reveal a 75.03% area decrease and a 0.33% accuracy decrease for fully connected neural networks, as well as a 74.88% area reduction and a 2.38% accuracy decline for ResNet-32."
        ],
        [
            "Oplixnet, a pioneering technology, harnesses light signal processing to expedite deep learning, minimize energy expenditure, and refine spatial arrangements. By partitioning input image data into amplitude and phase components, and synchronizing input and output layers to harmonize these parts, Oplixnet achieves substantial area reductions without compromising precision. Experimental results show a 75.03% area decrease and a 0.33% accuracy decrease for fully connected neural networks, as well as a 74.88% area reduction and a 2.38% accuracy decline for ResNet-32."
        ],
        [
            "Oplixnet, a groundbreaking innovation, leverages light signal processing to accelerate deep learning, reduce energy consumption, and optimize spatial layouts. By dividing input image data into amplitude and phase components, and synchronizing input and output layers to align these parts, Oplixnet achieves significant area reductions without sacrificing precision. Experimental outcomes demonstrate a 75.03% area decrease and a 0.33% accuracy decrease for fully connected neural networks, as well as a 74.88% area reduction and a 2.38% accuracy decline for ResNet-32."
        ],
        [
            "Oplixnet, a pioneering innovation, harnesses light signal processing to speed up deep learning, minimize energy usage, and optimize spatial arrangements. By separating input image data into amplitude and phase components, and synchronizing input and output layers to harmonize these parts, Oplixnet achieves substantial area reductions without compromising precision. Experimental results show a 75.03% area decrease and a 0.33% decrease in accuracy for fully connected neural networks, as well as a 74.88% area reduction and a 2.38% decline in accuracy for ResNet-32."
        ],
        [
            "Oplixnet, a groundbreaking innovation, leverages light signal processing to accelerate deep learning, reduce energy consumption, and optimize spatial layouts. By splitting input image data into amplitude and phase components, and synchronizing input and output layers to harmonize these parts, Oplixnet achieves significant area reductions without compromising precision. Experimental results demonstrate a 75.03% area decrease and a 0.33% decrease in accuracy for fully connected neural networks, as well as a 74.88% area reduction and a 2.38% decline in accuracy for ResNet-32."
        ]
    ]
}