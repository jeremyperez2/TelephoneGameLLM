{
    "adjacency_matrix": [
        [
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0
        ]
    ],
    "prompt_init": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "prompt_update": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "personality_list": [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        ""
    ],
    "format_prompt": [
        ""
    ],
    "initial_story": "musculoskeletal diseases and cognitive impairments in patients lead todifficulties in movement as well as negative effects on their psychologicalhealth. clinical gait analysis, a vital tool for early diagnosis and treatment,traditionally relies on expensive optical motion capture systems. recentadvances in computer vision and deep learning have opened the door to moreaccessible and cost-effective alternatives. this paper introduces a novelspatio-temporal transformer network to estimate critical gait parameters fromrgb videos captured by a single-view camera. empirical evaluations on a publicdataset of cerebral palsy patients indicate that the proposed frameworksurpasses current state-of-the-art approaches and show significant improvementsin predicting general gait parameters (including walking speed, gait deviationindex - gdi, and knee flexion angle at maximum extension), while utilizingfewer parameters and alleviating the need for manual feature extraction. ",
    "stories": [
        [
            "Here is the rephrased text:\n\nPatients with musculoskeletal diseases and cognitive impairments often experience difficulties in movement and negative impacts on their mental well-being. Traditional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on expensive optical motion capture systems. However, recent breakthroughs in computer vision and deep learning have enabled the development of more affordable and effective alternatives. This paper presents a novel approach, using a spatial-temporal transformer network to estimate key gait parameters from RGB videos captured by a single camera. Experimental results on a public dataset of cerebral palsy patients demonstrate that our framework outperforms existing methods, accurately predicting essential gait metrics (including walking speed, gait deviation index, and knee flexion angle) while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal diseases and cognitive impairments frequently encounter mobility challenges and mental health concerns. Conventional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on costly optical motion capture systems. However, recent advancements in computer vision and deep learning have enabled the creation of more affordable and effective alternatives. This paper introduces a novel approach, utilizing a spatial-temporal transformer network to estimate key gait parameters from RGB videos captured by a single camera. Experimental results on a public dataset of cerebral palsy patients show that our framework outperforms existing methods, accurately predicting essential gait metrics (including walking speed, gait deviation index, and knee flexion angle) while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal diseases and cognitive impairments often face mobility issues and mental health concerns. Traditional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on expensive optical motion capture systems. However, recent breakthroughs in computer vision and deep learning have enabled the development of more affordable and effective alternatives. This paper presents a new approach that uses a spatial-temporal transformer network to estimate key gait parameters from RGB videos captured by a single camera. Experimental results on a public dataset of cerebral palsy patients demonstrate that our framework outperforms existing methods, accurately predicting essential gait metrics (including walking speed, gait deviation index, and knee flexion angle) while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal conditions and cognitive impairments frequently encounter mobility difficulties and mental health concerns. Conventional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on costly optical motion capture systems. However, recent advancements in computer vision and deep learning have enabled the creation of more affordable and effective alternatives. This paper introduces a novel approach that employs a spatial-temporal transformer network to estimate key gait parameters from RGB videos captured by a single camera. Experimental results on a public dataset of cerebral palsy patients show that our framework surpasses existing methods, accurately predicting vital gait metrics (including walking speed, gait deviation index, and knee flexion angle) while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal conditions and cognitive impairments often face mobility challenges and mental health issues. Traditional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on expensive optical motion capture systems. However, recent advancements in computer vision and deep learning have enabled the development of more affordable and effective alternatives. This paper presents a novel approach that utilizes a spatial-temporal transformer network to estimate key gait parameters from RGB videos captured by a single camera. Experimental results on a public dataset of cerebral palsy patients demonstrate that our framework outperforms existing methods, accurately predicting essential gait metrics (including walking speed, gait deviation index, and knee flexion angle) while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal conditions and cognitive impairments frequently encounter mobility difficulties and mental health concerns. Conventional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on costly optical motion capture systems. However, recent breakthroughs in computer vision and deep learning have enabled the creation of more affordable and effective alternatives. This paper introduces a novel approach that employs a spatial-temporal transformer network to estimate key gait parameters from RGB videos captured by a single camera. Experimental results on a public dataset of cerebral palsy patients show that our framework surpasses existing methods, accurately predicting vital gait metrics (including walking speed, gait deviation index, and knee flexion angle) while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal conditions and cognitive impairments often face mobility challenges and mental health issues. Traditional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on expensive optical motion capture systems. However, recent advancements in computer vision and deep learning have enabled the development of more affordable and effective alternatives. This paper presents a novel approach that utilizes a spatial-temporal transformer network to estimate key gait parameters from RGB videos captured by a single camera. Experimental results on a public dataset of cerebral palsy patients demonstrate that our framework outperforms existing methods, accurately predicting essential gait metrics (including walking speed, gait deviation index, and knee flexion angle) while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal conditions and cognitive impairments frequently encounter mobility difficulties and mental health concerns. Conventional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on costly optical motion capture systems. However, recent breakthroughs in computer vision and deep learning have enabled the creation of more affordable and effective alternatives. This paper introduces a novel approach that employs a spatial-temporal transformer network to estimate key gait parameters from RGB videos captured by a single camera. Experimental results on a public dataset of cerebral palsy patients show that our framework outperforms existing methods, accurately predicting essential gait metrics (including walking speed, gait deviation index, and knee flexion angle) while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal conditions and cognitive impairments often struggle with mobility issues and mental health concerns. Traditional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on expensive optical motion capture systems. However, recent advancements in computer vision and deep learning have led to the development of more affordable and effective alternatives. This paper presents a new approach that utilizes a spatial-temporal transformer network to estimate key gait parameters from RGB videos captured by a single camera. Experimental results on a publicly available dataset of cerebral palsy patients demonstrate that our framework outperforms existing methods, accurately predicting essential gait metrics (including walking speed, gait deviation index, and knee flexion angle) while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal conditions and cognitive impairments often face difficulties with mobility and mental health. Conventional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on costly optical motion capture systems. However, recent breakthroughs in computer vision and deep learning have led to the development of more affordable and effective alternatives. This paper introduces a novel approach that employs a spatial-temporal transformer network to estimate key gait parameters from RGB videos captured by a single camera. Experimental results on a publicly available dataset of cerebral palsy patients show that our framework outperforms existing methods, accurately predicting essential gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal conditions and cognitive impairments frequently encounter mobility and mental health challenges. Traditional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on expensive optical motion capture systems. However, advancements in computer vision and deep learning have led to the development of more affordable and effective alternatives. This study presents a new approach that utilizes a spatial-temporal transformer network to estimate key gait parameters from RGB videos captured by a single camera. Experimental results on a publicly available dataset of cerebral palsy patients demonstrate that our framework outperforms existing methods, accurately predicting essential gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal conditions and cognitive impairments often face difficulties with mobility and mental well-being. Conventional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on costly optical motion capture systems. Nevertheless, breakthroughs in computer vision and deep learning have led to the creation of more affordable and efficient alternatives. This study introduces a novel approach that employs a spatial-temporal transformer network to estimate crucial gait parameters from RGB videos captured by a single camera. Experimental results on a publicly available dataset of cerebral palsy patients show that our framework surpasses existing methods, accurately predicting essential gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal conditions and cognitive impairments frequently encounter challenges with mobility and mental health. Traditional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on expensive optical motion capture systems. However, advancements in computer vision and deep learning have led to the development of more affordable and efficient alternatives. This study presents a new approach that utilizes a spatial-temporal transformer network to estimate key gait parameters from RGB videos captured by a single camera. Experimental results on a publicly available dataset of cerebral palsy patients demonstrate that our framework outperforms existing methods, accurately predicting essential gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal conditions and cognitive impairments often struggle with mobility and mental well-being. Conventional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on expensive technology. However, recent advancements in computer vision and artificial intelligence have led to the development of more affordable and efficient alternatives. This study introduces a new approach that uses a spatial-temporal transformer network to estimate key gait parameters from videos captured by a single camera. Experimental results on a publicly available dataset of cerebral palsy patients show that our framework outperforms existing methods, accurately predicting essential gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal conditions and cognitive impairments frequently face challenges with mobility and mental health. Traditional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on costly technology. Nevertheless, recent breakthroughs in computer vision and artificial intelligence have led to the creation of more accessible and efficient alternatives. This study presents a novel approach that employs a spatial-temporal transformer network to estimate crucial gait parameters from single-camera video recordings. Experimental findings on a publicly available dataset of cerebral palsy patients demonstrate that our framework surpasses existing methods, accurately predicting vital gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal conditions and cognitive impairments often struggle with mobility and mental well-being. Conventional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on expensive technology. However, recent advancements in computer vision and artificial intelligence have led to the development of more accessible and efficient alternatives. This research introduces a new approach that utilizes a spatial-temporal transformer network to estimate essential gait parameters from single-camera video recordings. Experimental results on a publicly available dataset of cerebral palsy patients show that our framework outperforms existing methods, accurately predicting key gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal conditions and cognitive impairments frequently face challenges with mobility and mental health. Traditional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on costly technology. However, recent breakthroughs in computer vision and artificial intelligence have led to the development of more accessible and efficient alternatives. This study presents a novel approach that employs a spatial-temporal transformer network to estimate crucial gait parameters from single-camera video recordings. Experimental results on a publicly available dataset of cerebral palsy patients demonstrate that our framework surpasses existing methods, accurately predicting key gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal conditions and cognitive impairments often struggle with mobility and mental well-being. Conventional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on expensive equipment. However, recent advancements in computer vision and artificial intelligence have led to the development of more accessible and efficient alternatives. This study introduces a new approach that utilizes a spatial-temporal transformer network to estimate essential gait parameters from single-camera video recordings. Experimental results on a publicly available dataset of cerebral palsy patients show that our framework outperforms existing methods, accurately predicting key gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal conditions and cognitive impairments frequently face challenges with mobility and mental health. Traditional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on costly equipment. However, breakthroughs in computer vision and artificial intelligence have led to the creation of more accessible and efficient alternatives. This study presents a novel approach that employs a spatial-temporal transformer network to estimate crucial gait parameters from single-camera video recordings. Experimental findings on a publicly available dataset of cerebral palsy patients demonstrate that our framework surpasses existing methods, accurately predicting key gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal conditions and cognitive impairments often struggle with mobility and mental well-being. Conventional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on expensive equipment. However, advancements in computer vision and artificial intelligence have led to the development of more accessible and efficient alternatives. This study introduces a new approach that utilizes a spatial-temporal transformer network to estimate essential gait parameters from single-camera video recordings. Experimental results on a publicly available dataset of cerebral palsy patients show that our framework outperforms existing methods, accurately predicting key gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal conditions and cognitive impairments frequently face challenges with mobility and mental health. Traditional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on costly equipment. Nevertheless, breakthroughs in computer vision and artificial intelligence have led to the creation of more accessible and efficient alternatives. This study presents a novel approach that employs a spatial-temporal transformer network to estimate crucial gait parameters from single-camera video recordings. Experimental findings on a publicly available dataset of cerebral palsy patients demonstrate that our framework surpasses existing methods, accurately predicting key gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal conditions and cognitive impairments often struggle with mobility and mental well-being. Conventional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on expensive equipment. However, advances in computer vision and artificial intelligence have led to the development of more accessible and efficient alternatives. This study introduces a new approach that uses a spatial-temporal transformer network to estimate essential gait parameters from single-camera video recordings. Experimental results on a publicly available dataset of cerebral palsy patients show that our framework outperforms existing methods, accurately predicting key gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal conditions and cognitive impairments frequently face challenges with mobility and mental health. Traditional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on costly equipment. Nevertheless, breakthroughs in computer vision and artificial intelligence have led to the creation of more accessible and efficient alternatives. This study presents a novel approach that employs a spatial-temporal transformer network to estimate crucial gait parameters from single-camera video recordings. Experimental results on a publicly available dataset of cerebral palsy patients demonstrate that our framework surpasses existing methods, accurately predicting key gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal conditions and cognitive impairments often struggle with mobility and mental health. Conventional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on expensive equipment. However, advancements in computer vision and artificial intelligence have led to the development of more accessible and efficient alternatives. This study introduces a new approach that uses a spatial-temporal transformer network to estimate essential gait parameters from single-camera video recordings. Experimental results on a publicly available dataset of cerebral palsy patients show that our framework outperforms existing methods, accurately predicting key gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal conditions and cognitive impairments frequently face challenges with mobility and mental well-being. Traditional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on costly equipment. Nevertheless, breakthroughs in computer vision and artificial intelligence have led to the creation of more accessible and efficient alternatives. This research presents a novel approach that employs a spatial-temporal transformer network to estimate crucial gait parameters from single-camera video recordings. Experimental results on a publicly available dataset of cerebral palsy patients demonstrate that our framework surpasses existing methods, accurately predicting key gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal conditions and cognitive impairments often struggle with mobility and mental health. Conventional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on expensive equipment. However, advances in computer vision and artificial intelligence have led to the development of more accessible and efficient alternatives. This study introduces a new approach that uses a spatial-temporal transformer network to estimate essential gait parameters from single-camera video recordings. Experimental results on a publicly available dataset of cerebral palsy patients show that our framework outperforms existing methods, accurately predicting key gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal conditions and cognitive impairments frequently face challenges with mobility and mental well-being. Traditional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on costly equipment. However, recent advancements in computer vision and artificial intelligence have led to the development of more accessible and efficient alternatives. This study presents a novel approach that employs a spatial-temporal transformer network to estimate crucial gait parameters from single-camera video recordings. Experimental results on a publicly available dataset of cerebral palsy patients demonstrate that our framework outperforms existing methods, accurately predicting key gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal conditions and cognitive impairments often struggle with mobility and mental health. Conventional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on expensive equipment. However, recent breakthroughs in computer vision and artificial intelligence have led to the development of more accessible and efficient alternatives. This study introduces a new approach that uses a spatial-temporal transformer network to estimate essential gait parameters from single-camera video recordings. Experimental results on a publicly available dataset of cerebral palsy patients show that our framework outperforms existing methods, accurately predicting key gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal conditions and cognitive impairments frequently face challenges with mobility and mental well-being. Traditional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on costly equipment. Nevertheless, advancements in computer vision and artificial intelligence have led to the creation of more accessible and efficient alternatives. This research presents a novel approach that employs a spatial-temporal transformer network to estimate crucial gait parameters from single-camera video recordings. Experimental findings on a publicly available dataset of cerebral palsy patients demonstrate that our framework surpasses existing methods, accurately predicting key gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal conditions and cognitive impairments often struggle with mobility and mental health. Conventional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on expensive equipment. However, recent advancements in computer vision and artificial intelligence have led to the development of more accessible and efficient alternatives. This study introduces a new approach that uses a spatial-temporal transformer network to estimate essential gait parameters from single-camera video recordings. Experimental results on a publicly available dataset of cerebral palsy patients show that our framework outperforms existing methods, accurately predicting key gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal conditions and cognitive impairments frequently face challenges with mobility and mental well-being. Traditional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on costly equipment. Nevertheless, recent breakthroughs in computer vision and artificial intelligence have led to the creation of more accessible and efficient alternatives. This study presents a novel approach that employs a spatial-temporal transformer network to estimate crucial gait parameters from single-camera video recordings. Experimental findings on a publicly available dataset of cerebral palsy patients demonstrate that our framework surpasses existing methods, accurately predicting key gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal conditions and cognitive impairments often struggle with mobility and mental health. Conventional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on expensive equipment. However, recent advancements in computer vision and artificial intelligence have led to the development of more accessible and efficient alternatives. This study introduces a new approach that utilizes a spatial-temporal transformer network to estimate essential gait parameters from single-camera video recordings. Experimental results on a publicly available dataset of cerebral palsy patients show that our framework outperforms existing methods, accurately predicting key gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal conditions and cognitive impairments frequently face challenges with mobility and mental well-being. Traditional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on costly equipment. However, recent breakthroughs in computer vision and artificial intelligence have led to the development of more accessible and efficient alternatives. This study presents a novel approach that employs a spatial-temporal transformer network to estimate crucial gait parameters from single-camera video recordings. Experimental results on a publicly available dataset of cerebral palsy patients demonstrate that our framework outperforms existing methods, accurately predicting key gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal conditions and cognitive impairments often struggle with mobility and mental health. Conventional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on expensive equipment. However, recent advancements in computer vision and artificial intelligence have led to the development of more accessible and efficient alternatives. This study introduces a new approach that uses a spatial-temporal transformer network to estimate essential gait parameters from single-camera video recordings. Experimental results on a publicly available dataset of cerebral palsy patients show that our framework outperforms existing methods, accurately predicting key gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal conditions and cognitive impairments frequently face challenges with mobility and mental well-being. Traditional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on costly equipment. However, recent breakthroughs in computer vision and artificial intelligence have led to the creation of more accessible and efficient alternatives. This research introduces a novel approach that employs a spatial-temporal transformer network to estimate crucial gait parameters from single-camera video recordings. Experimental findings on a publicly available dataset of cerebral palsy patients demonstrate that our framework surpasses existing methods, accurately predicting key gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal conditions and cognitive impairments often struggle with mobility and mental health. Conventional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on expensive equipment. However, recent advancements in computer vision and artificial intelligence have led to the development of more accessible and efficient alternatives. This study presents a new approach that uses a spatial-temporal transformer network to estimate essential gait parameters from single-camera video recordings. Experimental results on a publicly available dataset of cerebral palsy patients show that our framework outperforms existing methods, accurately predicting key gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal conditions and cognitive impairments frequently face challenges with mobility and mental well-being. Traditional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on costly equipment. Nevertheless, recent breakthroughs in computer vision and artificial intelligence have led to the creation of more accessible and efficient alternatives. This study introduces a novel approach that employs a spatial-temporal transformer network to estimate crucial gait parameters from single-camera video recordings. Experimental findings on a publicly available dataset of cerebral palsy patients demonstrate that our framework surpasses existing methods, accurately predicting vital gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal conditions and cognitive impairments often struggle with mobility and mental health. Conventional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on expensive equipment. However, recent advancements in computer vision and artificial intelligence have led to the development of more accessible and efficient alternatives. This study presents a new approach that uses a spatial-temporal transformer network to estimate essential gait parameters from single-camera video recordings. Experimental results on a publicly available dataset of cerebral palsy patients show that our framework outperforms existing methods, accurately predicting key gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal conditions and cognitive impairments frequently face challenges with mobility and mental well-being. Traditional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on costly equipment. Nevertheless, recent breakthroughs in computer vision and artificial intelligence have led to the creation of more accessible and efficient alternatives. This study introduces a novel approach that employs a spatial-temporal transformer network to estimate crucial gait parameters from single-camera video recordings. Experimental findings on a publicly available dataset of cerebral palsy patients demonstrate that our framework surpasses existing methods, accurately predicting key gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal conditions and cognitive impairments often struggle with mobility and mental health. Conventional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on expensive equipment. However, recent advancements in computer vision and artificial intelligence have led to the development of more accessible and efficient alternatives. This study presents a new approach that uses a spatial-temporal transformer network to estimate essential gait parameters from single-camera video recordings. Experimental results on a publicly available dataset of cerebral palsy patients show that our framework outperforms existing methods, accurately predicting key gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal conditions and cognitive impairments frequently face challenges with mobility and mental well-being. Traditional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on costly equipment. However, recent breakthroughs in computer vision and artificial intelligence have led to the development of more accessible and efficient alternatives. This study introduces a novel approach that utilizes a spatial-temporal transformer network to estimate crucial gait parameters from single-camera video recordings. Experimental results on a publicly available dataset of cerebral palsy patients demonstrate that our framework surpasses existing methods, accurately predicting key gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal conditions and cognitive impairments often struggle with mobility and mental health. Conventional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on expensive equipment. However, recent advancements in computer vision and artificial intelligence have led to the development of more accessible and efficient alternatives. This study presents a new approach that uses a spatial-temporal transformer network to estimate essential gait parameters from single-camera video recordings. Experimental results on a publicly available dataset of cerebral palsy patients show that our framework outperforms existing methods, accurately predicting key gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal conditions and cognitive impairments frequently face challenges with mobility and mental well-being. Traditional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on costly equipment. However, recent breakthroughs in computer vision and artificial intelligence have led to the development of more accessible and efficient alternatives. This study introduces a novel approach that employs a spatial-temporal transformer network to estimate crucial gait parameters from single-camera video recordings. Experimental results on a publicly available dataset of cerebral palsy patients demonstrate that our framework surpasses existing methods, accurately predicting key gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal conditions and cognitive impairments often struggle with mobility and mental health. Conventional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on expensive equipment. However, advancements in computer vision and artificial intelligence have led to the creation of more accessible and efficient alternatives. This study presents a new approach that uses a spatial-temporal transformer network to estimate essential gait parameters from single-camera video recordings. Experimental results on a publicly available dataset of cerebral palsy patients show that our framework outperforms existing methods, accurately predicting key gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal conditions and cognitive impairments frequently face challenges with mobility and mental well-being. Traditional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on costly equipment. Nevertheless, breakthroughs in computer vision and artificial intelligence have led to the development of more accessible and efficient alternatives. This study introduces a novel approach that employs a spatial-temporal transformer network to estimate vital gait parameters from single-camera video recordings. Experimental findings on a publicly available dataset of cerebral palsy patients demonstrate that our framework surpasses existing methods, accurately predicting key gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal conditions and cognitive impairments often struggle with mobility and mental health. Conventional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on expensive equipment. However, advances in computer vision and artificial intelligence have led to the creation of more accessible and efficient solutions. This research presents a new approach that uses a spatial-temporal transformer network to estimate vital gait metrics from single-camera video recordings. Experimental results on a publicly available dataset of cerebral palsy patients show that our framework outperforms existing methods, accurately predicting key gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal conditions and cognitive impairments frequently face challenges with mobility and mental well-being. Traditional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on costly equipment. Nevertheless, breakthroughs in computer vision and artificial intelligence have led to the development of more accessible and efficient solutions. This research introduces a novel approach that employs a spatial-temporal transformer network to estimate crucial gait metrics from single-camera video recordings. Experimental findings on a publicly available dataset of cerebral palsy patients demonstrate that our framework surpasses existing methods, accurately predicting key gait metrics, including walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal conditions and cognitive impairments often struggle with mobility and mental health. Conventional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on expensive equipment. However, advancements in computer vision and artificial intelligence have led to the creation of more accessible and efficient solutions. This study presents a new approach that utilizes a spatial-temporal transformer network to estimate essential gait metrics from single-camera video recordings. Experimental results on a publicly available dataset of cerebral palsy patients show that our framework outperforms existing methods, accurately predicting key gait metrics like walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal conditions and cognitive impairments frequently face challenges with mobility and mental well-being. Traditional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on costly equipment. Nevertheless, breakthroughs in computer vision and artificial intelligence have led to the development of more accessible and efficient solutions. This study introduces a novel approach that employs a spatial-temporal transformer network to estimate crucial gait metrics from single-camera video recordings. Experimental findings on a publicly available dataset of cerebral palsy patients demonstrate that our framework surpasses existing methods, accurately predicting key gait metrics like walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal conditions and cognitive impairments often struggle with mobility and mental health. Conventional methods for diagnosing and treating gait disorders, such as clinical gait analysis, rely on expensive equipment. However, advancements in computer vision and artificial intelligence have led to the creation of more accessible and efficient solutions. This study presents a new approach that uses a spatial-temporal transformer network to estimate essential gait metrics from single-camera video recordings. Experimental results on a publicly available dataset of cerebral palsy patients show that our framework outperforms existing methods, accurately predicting key gait metrics like walking speed, gait deviation index, and knee flexion angle, while requiring fewer parameters and eliminating the need for manual feature extraction."
        ]
    ]
}