{
    "adjacency_matrix": [
        [
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0
        ]
    ],
    "prompt_init": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "prompt_update": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "personality_list": [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        ""
    ],
    "format_prompt": [
        ""
    ],
    "initial_story": "musculoskeletal diseases and cognitive impairments in patients lead todifficulties in movement as well as negative effects on their psychologicalhealth. clinical gait analysis, a vital tool for early diagnosis and treatment,traditionally relies on expensive optical motion capture systems. recentadvances in computer vision and deep learning have opened the door to moreaccessible and cost-effective alternatives. this paper introduces a novelspatio-temporal transformer network to estimate critical gait parameters fromrgb videos captured by a single-view camera. empirical evaluations on a publicdataset of cerebral palsy patients indicate that the proposed frameworksurpasses current state-of-the-art approaches and show significant improvementsin predicting general gait parameters (including walking speed, gait deviationindex - gdi, and knee flexion angle at maximum extension), while utilizingfewer parameters and alleviating the need for manual feature extraction. ",
    "stories": [
        [
            "Patients suffering from musculoskeletal diseases and cognitive impairments experience challenges in movement and adverse impacts on their psychological well-being. Clinical gait analysis plays a crucial role in early diagnosis and treatment; however, it typically relies on costly optical motion capture systems. The latest advancements in computer vision and deep learning offer more affordable and practical alternatives. This study presents a new spatio-temporal transformer network that estimates vital gait parameters from RGB videos captured using a single-view camera. Results from a public dataset of cerebral palsy patients demonstrate that this framework outperforms current methods, achieving substantial improvements in predicting fundamental gait characteristics (such as walking speed, gait deviation index - GDI, and knee flexion angle at maximum extension) with fewer parameters and eliminating the necessity for manual feature extraction."
        ],
        [
            "Individuals with musculoskeletal conditions and cognitive impairments encounter difficulties in mobility and negative effects on their mental health. Precise identification and intervention for these issues are essential, which is where clinical gait analysis comes in. However, this process often depends on expensive optical motion capture systems. Recent progress in computer vision and deep learning technologies provides more cost-effective and convenient solutions. In this research, we introduce a novel spatio-temporal transformer network that determines essential gait features from RGB videos obtained using a single-view camera. Our study reveals that this method surpasses existing techniques when applied to a publicly available dataset of cerebral palsy patients. It yields significant enhancements in predicting fundamental gait characteristics (such as walking speed, gait deviation index - GDI, and maximum knee extension angle) using fewer parameters and obviating the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal disorders and cognitive impairments face challenges in moving around and experience adverse mental health consequences. Proper identification and treatment of these issues are crucial, and that's where clinical gait analysis comes into play. However, this process typically relies on costly optical motion capture systems. Recent advances in computer vision and deep learning technologies offer more economical and accessible alternatives. In our research, we present a new spatio-temporal transformer network that isolates essential gait features from RGB videos captured using a single-view camera. Our investigation demonstrates that this method outperforms existing techniques when applied to a publicly accessible dataset of cerebral palsy patients. It delivers substantial improvements in determining fundamental gait characteristics (including walking speed, gait deviation index - GDI, and maximum knee extension angle) using fewer resources and eliminating the requirement for manual feature extraction."
        ],
        [
            "Individuals dealing with musculoskeletal disorders and cognitive impairments encounter difficulties in mobility and suffer from negative mental health effects. Accurate recognition and care for these conditions are imperative, and clinical gait analysis serves this purpose. Traditionally, this approach utilizes expensive optical motion capture systems. Nevertheless, advances in computer vision and deep learning technologies provide more affordable and convenient options. In our study, we introduce a novel spatio-temporal transformer network designed to distinguish vital gait elements from RGB videos obtained via a standard single-view camera. Our experiments reveal that this approach surpasses existing methods when applied to a publicly available dataset of cerebral palsy cases. This innovation brings about significant advancements in identifying fundamental gait characteristics (such as walking speed, gait deviation index - GDI, and maximum knee extension angle) using minimal resources and obviating the necessity for manual feature extraction."
        ],
        [
            "People with musculoskeletal disorders and cognitive impairments face challenges in moving around and experience adverse mental health consequences. Proper identification and treatment of these conditions are crucial. Clinical gait analysis is a valuable tool for achieving this goal. Historically, this method has relied on costly optical motion capture systems. However, advancements in computer vision and deep learning technologies offer more affordable and practical alternatives. In our research, we present a new spatio-temporal transformer network aimed at distinguishing essential gait elements from RGB videos obtained using a regular single-view camera. Our findings demonstrate that this approach outperforms existing methods in dealing with a publicly accessible dataset of cerebral palsy instances. This development paves the way for substantial progress in detecting essential gait attributes (such as walking speed, gait deviation index - GDI, and maximum knee extension angle) with minimal resources and without the need for manual feature extraction."
        ],
        [
            "Individuals dealing with musculoskeletal disorders and cognitive impairments encounter difficulties in mobility and suffer from negative mental health effects. Early identification and effective treatment are essential. Clinical gait analysis plays a significant role in addressing this need. Traditionally, this method has utilized expensive optical motion capture systems. However, recent advancements in computer vision and deep learning technologies provide more economical and convenient solutions. In our study, we introduce a new spatio-temporal transformer network designed to identify critical gait features from RGB videos obtained using a standard single-view camera. Our results indicate that this method surpasses existing techniques when applied to a publicly accessible dataset of cerebral palsy cases. This innovation advances the field by enabling the detection of crucial gait characteristics (including walking speed, gait deviation index, and maximum knee extension angle) with minimal resources and without the requirement for manual feature extraction."
        ],
        [
            "People with musculoskeletal issues and cognitive impairments face challenges in mobility and experience adverse mental health consequences. Timely recognition and proper management are crucial. Clinical gait analysis is vital in addressing this challenge. Historically, this approach has relied on costly optical motion capture systems. However, progress in computer vision and deep learning technologies offers more affordable and accessible alternatives. In our research, we present a novel spatio-temporal transformer network aimed at recognizing essential gait traits from RGB videos captured using a standard single-lens camera. Our findings demonstrate that this technique outperforms existing solutions when put to the test on a publicly available dataset of cerebral palsy cases. This development propels the field forward by making it possible to detect critical gait features (including walking pace, gait deviation index, and maximum knee extension angle) with minimal resources and without the necessity for manual trait extraction."
        ],
        [
            "Individuals dealing with musculoskeletal problems and cognitive impairments encounter difficulties in moving around and suffer from negative mental health effects. Early identification and effective management are essential. Clinical gait analysis plays a significant role in tackling this issue. Traditionally, this method has depended on expensive optical motion capture systems. However, advancements in computer vision and deep learning technologies provide more affordable and accessible options. In our study, we introduce a new spatio-temporal transformer network designed to identify key gait characteristics from RGB videos captured using a standard single-lens camera. Our results show that this method surpasses existing solutions when evaluated on a publicly accessible dataset of cerebral palsy cases. This breakthrough advances the field by enabling the detection of crucial gait attributes (such as walking speed, gait deviation index, and maximum knee extension angle) with minimal requirements and without the need for manual trait extraction."
        ],
        [
            "People with musculoskeletal issues and cognitive impairments face challenges in mobility and experience adverse mental health consequences. Early recognition and appropriate management are crucial. Clinical gait analysis is vital in addressing this challenge. Historically, this approach has relied on costly optical motion capture systems. However, progress in computer vision and deep learning technologies offers more economical and accessible alternatives. In our research, we present a novel spatio-temporal transformer network aimed at recognizing vital gait features from standard RGB videos captured using a single-lens camera. Our findings indicate that this method outperforms existing solutions when assessed on a publicly available dataset of cerebral palsy instances. This development propels the field forward by identifying crucial gait traits (including walking speed, gait deviation index, and maximum knee extension angle) with minimal resources and without the necessity for manual trait extraction."
        ],
        [
            "Individuals dealing with musculoskeletal problems and cognitive impairments encounter difficulties in mobility and suffer from negative mental health effects. Prompt identification and effective management are essential. Clinical gait analysis plays a significant role in tackling this issue. Traditionally, this strategy has depended on expensive optical motion capture systems. However, advancements in computer vision and deep learning technologies provide more affordable and convenient options. In our study, we introduce a new spatio-temporal transformer network designed to identify essential gait characteristics from regular RGB videos taken using a single-lens camera. Our results demonstrate that this method surpasses current solutions in terms of performance when evaluated against a publicly accessible dataset of cerebral palsy cases. This advancement advances the field by recognizing critical gait features (such as walking pace, gait deviation index, and maximum knee extension angle) with minimal resources and without requiring manual trait extraction."
        ],
        [
            "People experiencing mobility issues due to musculoskeletal problems and cognitive impairments face challenges in movement and experience adverse mental health consequences. Early recognition and efficient management are crucial. Clinical gait analysis is a valuable approach for addressing this challenge. Historically, this approach relied on pricey optical motion capture systems. However, progress in computer vision and deep learning technologies presents more economical and accessible alternatives. In our research, we present a novel spatio-temporal transformer network that extracts vital gait features from standard RGB videos taken with a single-lens camera. Our findings suggest that this method outperforms existing solutions when compared to a publicly available dataset of cerebral palsy cases. This innovation advances the field by detecting key gait characteristics (such as walking speed, gait deviation index, and maximum knee extension angle) with limited resources and without needing manual trait extraction."
        ],
        [
            "Individuals dealing with mobility challenges caused by musculoskeletal conditions and cognitive impairments encounter difficulties in movement and suffer from negative mental health effects. Timely identification and effective management are essential. Clinical gait analysis serves as a useful strategy for tackling this issue. In the past, this method primarily utilized expensive optical motion capture systems. However, advancements in computer vision and deep learning technologies now offer more affordable and accessible alternatives. In our study, we introduce a new spatio-temporal transformer network that isolates essential gait attributes from standard RGB videos captured using a single-lens camera. Our results indicate that this approach surpasses existing solutions based on a publicly accessible dataset of cerebral palsy cases. This development paves the way by recognizing crucial gait traits (like walking speed, gait deviation index, and maximum knee extension angle) with minimal resources and without requiring manual trait extraction."
        ],
        [
            "People facing mobility issues due to musculoskeletal disorders and cognitive impairments experience challenges in movement and experience adverse mental health consequences. Early identification and appropriate management are crucial. Clinical gait analysis is an effective method for addressing this problem. Traditionally, this approach relied on costly optical motion capture systems. However, advances in computer vision and deep learning technologies now provide more economical and accessible alternatives. In our research, we present a novel spatio-temporal transformer network that distinguishes critical gait characteristics from standard RGB videos recorded using a single-lens camera. Our findings suggest that this technique surpasses existing solutions using a publicly available dataset of cerebral palsy cases. This progress signifies an important step in recognizing essential gait features (such as walking speed, gait deviation index, and maximum knee extension angle) with minimal resources and without the need for manual trait extraction."
        ],
        [
            "Individuals with musculoskeletal disorders and cognitive impairments encounter difficulties in moving and suffer from negative mental health effects. Prompt identification and proper treatment are essential. Clinical gait analysis is an efficient solution to this problem. Initially, this method utilized expensive optical motion capture systems. Yet, advancements in computer vision and deep learning technologies now offer more affordable and convenient options. In our study, we introduce a new spatio-temporal transformer network, which separates key gait attributes from standard RGB videos captured using a single-lens camera. According to our results, this approach outperforms previous solutions on a publicly accessible dataset of cerebral palsy instances. This development represents a significant leap in detecting vital gait characteristics (such as walking pace, gait deviation index, and maximum knee extension angle) with minimal resources and without manual trait extraction."
        ],
        [
            "People with musculoskeletal disorders and cognitive impairments face challenges in mobility and experience adverse mental health consequences. Early recognition and suitable treatment are crucial. Clinical gait analysis is an effective way to address this issue. Originally, this technique relied on costly optical motion capture systems. However, improvements in computer vision and deep learning technologies now provide more economical and practical alternatives. In our research, we present a novel spatio-temporal transformer network, capable of isolating crucial gait features from regular RGB videos recorded using a single-lens camera. Based on our findings, this method surpasses earlier approaches on a publicly available dataset of cerebral palsy cases. This advancement marks a substantial progress in identifying critical gait characteristics (like walking speed, gait deviation index, and maximum knee flexion angle) using limited resources and without manual trait extraction."
        ],
        [
            "Individuals dealing with musculoskeletal disorders and cognitive impairments encounter difficulties in mobility and suffer from negative mental health effects. Prompt identification and proper treatment are essential. Clinical gait analysis is a valuable solution to this problem. Initially, this method utilized expensive optical motion capture systems. Yet, advancements in computer vision and deep learning technologies now offer more affordable and practical alternatives. In our study, we introduce a groundbreaking spatio-temporal transformer network, which can extract vital gait characteristics from standard RGB videos captured using a single-lens camera. According to our results, this approach outperforms previous methods on a publicly accessible dataset of cerebral palsy instances. This development signifies a significant leap forward in identifying essential gait features (such as walking speed, gait deviation index, and maximum knee flexion angle) with minimal resources and without requiring manual feature extraction."
        ],
        [
            "People experiencing musculoskeletal issues and cognitive impairments face challenges in moving around and endure adverse mental health consequences. Early recognition and effective treatment are crucial. Clinical gait analysis presents a viable response to this challenge. Initially, this approach relied on costly optical motion capture systems. However, recent advancements in computer vision and deep learning technologies now provide more economical and convenient options. In our research, we present a novel spatio-temporal transformer network, which can identify critical gait features from standard RGB videos recorded using a single-lens camera. Based on our findings, this technique surpasses previous methods on a publicly available dataset of cerebral palsy cases. This progress represents a substantial advancement in recognizing essential gait characteristics (such as walking speed, gait deviation index, and maximum knee flexion angle) with minimal resources and without the need for manual feature extraction."
        ],
        [
            "Individuals dealing with musculoskeletal problems and cognitive impairments encounter difficulties in mobilizing and may experience detrimental mental health effects. Recognizing and addressing these issues early through appropriate treatment is imperative. Clinical gait analysis offers a viable solution to this hurdle. Initially, this methodology leaned heavily on expensive optical motion capture systems. However, recent innovations in computer vision and deep learning technologies now offer more affordable and convenient alternatives. In our study, we introduce a new spatio-temporal transformer network, which can extract crucial gait characteristics from standard RGB videos filmed using a single-lens camera. According to our results, this method outperforms previous approaches on a publicly accessible dataset of cerebral palsy instances. This development signifies a significant stride in identifying key gait attributes (including walking pace, gait deviation index, and maximum knee flexion angle) with minimal resources and without the necessity for manual feature extraction."
        ],
        [
            "People facing musculoskeletal issues and cognitive impairments may experience challenges in moving around and could suffer from negative mental health consequences. Early identification and treatment of these challenges are crucial. Clinical gait analysis provides a useful solution to this challenge. Initially, this approach relied heavily on costly optical motion capture systems. However, advancements in computer vision and deep learning technologies now provide more cost-effective and convenient options. In our research, we present a new spatio-temporal transformer network that can identify essential gait features from regular RGB videos recorded using a single-lens camera. Based on our findings, this method surpasses prior techniques on a publicly available dataset of cerebral palsy cases. This progress marks a substantial advancement in detecting critical gait attributes (such as walking speed, gait deviation index, and maximum knee flexion angle) with minimal resources and without requiring manual feature extraction."
        ],
        [
            "Individuals dealing with musculoskeletal problems and cognitive impairments might encounter difficulties in navigating and could be at risk for unfavorable mental health outcomes. Recognizing and addressing these obstacles promptly is essential. Clinical gait analysis serves as an effective response to this predicament. Initially, this technique primarily depended on expensive optical motion capture systems. Nevertheless, advancements in computer vision and deep learning technologies now offer more budget-friendly and practical alternatives. In our study, we introduce a novel spatio-temporal transformer network that can distinguish vital gait characteristics from standard RGB videos captured using a single-lens camera. According to our results, this approach surpasses earlier methods on a publicly accessible dataset of cerebral palsy instances. This development represents a significant improvement in identifying essential gait attributes (like walking speed, gait deviation index, and maximum knee flexion angle) with minimal resources and without necessitating manual feature extraction."
        ],
        [
            "People experiencing musculoskeletal issues and cognitive impairments may encounter challenges in navigating and could be prone to adverse mental health consequences. Swift identification and resolution of these barriers are crucial. Clinical gait analysis offers an efficient solution to this predicament. Originally, this method relied heavily on costly optical motion capture systems. However, recent advancements in computer vision and deep learning technologies present more economical and practical options. In our research, we introduce a new spatio-temporal transformer network that can distinguish significant gait features from standard RGB videos taken using a single-lens camera. Based on our findings, this method outperforms previous techniques on a publicly available dataset of cerebral palsy cases. This advancement signifies a substantial improvement in detecting vital gait attributes (such as walking speed, gait deviation index, and maximum knee flexion angle) with minimal resources and without requiring manual feature extraction."
        ],
        [
            "Individuals dealing with musculoskeletal problems and cognitive impairments might face difficulties in moving around and could be at risk for negative mental health outcomes. Prompt recognition and resolution of these obstacles are essential. Clinical gait analysis serves as an effective response to this predicament. Initially, this approach depended on expensive optical motion capture systems. However, modern developments in computer vision and deep learning technologies provide more affordable and convenient alternatives. In our study, we propose a novel spatio-temporal transformer network, capable of identifying key gait characteristics from standard RGB videos captured using a single-lens camera. According to our results, this approach surpasses earlier methods in a publicly accessible dataset of cerebral palsy cases. This progress represents a significant enhancement in recognizing critical gait features (including walking speed, gait deviation index, and maximum knee flexion angle) with minimal resources and without the need for manual feature extraction."
        ],
        [
            "People encountering musculoskeletal issues and cognitive impairments may find it challenging to move around and could be prone to unfavorable mental health consequences. Swift identification and management of these challenges are vital. Clinical gait analysis offers a viable solution to this predicament. Originally, this strategy relied on costly optical motion capture systems. However, recent advancements in computer vision and deep learning technologies offer more economical and user-friendly options. In our investigation, we suggest a cutting-edge spatio-temporal transformer network for detecting essential gait traits from standard RGB videos captured using a single-lens camera. Based on our findings, this method outperforms previous techniques in a publicly accessible dataset of cerebral palsy instances. This innovation marks a substantial improvement in pinpointing crucial gait characteristics (such as walking speed, gait deviation index, and maximum knee flexion angle) with minimal resources and without requiring manual feature extraction."
        ],
        [
            "Individuals dealing with musculoskeletal problems and cognitive impairments might find it difficult to maneuver and could be at risk for negative mental health outcomes. Prompt recognition and treatment of these difficulties are crucial. Clinical gait analysis presents a promising solution to this predicament. Initially, this methodology depended on expensive optical motion capture systems. However, recent progress in computer vision and deep learning technologies provides more affordable and user-friendly alternatives. In our study, we propose a state-of-the-art spatio-temporal transformer network for identifying critical gait features from standard RGB videos captured using a single-lens camera. According to our results, this technique surpasses prior methods in a publicly available dataset of cerebral palsy cases. This advancement represents a significant advancement in identifying essential gait attributes (like walking speed, gait deviation index, and maximum knee flexion angle) with minimal resources and without the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal issues and cognitive impairments may struggle with mobility and face potential negative mental health consequences. Early identification and intervention are essential. Clinical gait analysis offers a viable solution to this challenge. Originally, this approach relied on costly optical motion capture systems. However, advancements in computer vision and deep learning technologies now provide more accessible and user-friendly options. In our research, we suggest a cutting-edge spatio-temporal transformer network for extracting critical gait characteristics from standard RGB videos captured using a single-lens camera. Based on our findings, this method outperforms previous techniques in a publicly available dataset of cerebral palsy cases. This progress signifies a substantial leap in detecting essential gait features (such as walking speed, gait deviation index, and maximum knee flexion angle) with limited resources and without requiring manual feature extraction."
        ],
        [
            "Individuals dealing with musculoskeletal problems and cognitive impairments might encounter challenges with mobility, potentially leading to unfavorable mental health outcomes. Timely recognition and treatment are crucial. Clinical gait analysis presents a promising solution to this predicament. Initially, this strategy depended on expensive optical motion capture systems. Yet, advancements in computer vision and deep learning technologies have introduced more affordable and user-friendly alternatives. In our investigation, we propose an advanced spatio-temporal transformer network for isolating vital gait traits from typical RGB videos obtained using a single-lens camera. According to our results, this approach surpasses prior methods in a publicly accessible dataset of cerebral palsy instances. This development represents a significant stride in detecting essential gait characteristics (for example, walking speed, gait deviation index, and maximum knee flexion angle) with minimal resources and without manual trait extraction."
        ],
        [
            "People experiencing musculoskeletal issues and cognitive impairments may face mobility obstacles, which could negatively impact mental health. Early identification and intervention are essential. Clinical gait analysis offers a viable solution to this issue. At first, this method relied on costly optical motion capture systems. However, advancements in computer vision and deep learning technologies have introduced more economical and accessible options. In our study, we suggest employing a sophisticated spatio-temporal transformer network to distinguish crucial gait characteristics from standard RGB videos captured by a single-lens camera. Our findings suggest that this method outperforms previous techniques in a publicly accessible database of cerebral palsy cases. This progress marks a significant leap in detecting essential gait features (like walking speed, gait deviation index, and maximum knee flexion angle) with limited resources and without manual trait extraction."
        ],
        [
            "Individuals dealing with musculoskeletal problems and cognitive challenges may encounter mobility hurdles, potentially harming their mental well-being. Proactive identification and treatment are crucial. Clinical gait analysis presents a promising approach to address this concern. Initially, this method depended on expensive optical motion capture systems. However, advancements in computer vision and deep learning have led to more budget-friendly and accessible alternatives. In our research, we propose using a complex spatio-temporal transformer network to isolate vital gait characteristics from typical RGB videos recorded by a single-lens camera. Our results indicate that this method surpasses past methods in a publicly available database of cerebral palsy instances. This development signifies a substantial advancement in recognizing crucial gait traits (such as walking speed, gait deviation index, and maximum knee flexion angle) with minimal resources and without requiring manual trait extraction."
        ],
        [
            "People with musculoskeletal issues and cognitive difficulties may face mobility obstacles, which could negatively impact their mental health. Early recognition and treatment are essential. Clinical gait analysis is a potential solution to tackle this issue. Initially, this technique relied on pricey optical motion capture systems. However, recent advancements in computer vision and deep learning have led to more affordable and accessible options. In our study, we suggest employing a complex spatio-temporal transformer network to extract critical gait features from standard RGB videos captured by a single-lens camera. Our findings demonstrate that this approach outperforms previous methods in a publicly accessible database of cerebral palsy cases. This breakthrough marks a significant step forward in identifying vital gait characteristics (such as walking speed, gait deviation index, and maximum knee flexion angle) with limited resources and without manual trait extraction."
        ],
        [
            "Individuals dealing with musculoskeletal problems and cognitive challenges may encounter challenges in mobility, which could potentially harm their mental well-being. Proactively identifying and addressing these issues is crucial. Clinical gait analysis is a viable solution to tackle mobility barriers. Initially, this technique utilized costly optical motion capture systems. However, advancements in computer vision and deep learning have led to more economical and accessible alternatives. In our research, we propose utilizing a sophisticated spatio-temporal transformer network to isolate vital gait characteristics from standard RGB videos captured using a single-lens camera. Our results indicate that this method surpasses previous techniques in accurately identifying key gait features (such as walking speed, gait deviation index, and maximum knee flexion angle) in a publicly accessible database of cerebral palsy cases, without the need for manual extraction or significant resources."
        ],
        [
            "People experiencing musculoskeletal difficulties and cognitive issues might face mobility hurdles, which could negatively impact their mental health. Addressing these complications beforehand is essential. Clinical gait analysis offers a promising approach to overcoming mobility obstacles. Originally, this method relied on expensive optical motion capture systems. However, advancements in computer vision and deep learning have given rise to more affordable and accessible options. In our investigation, we advocate employing an intricate spatio-temporal transformer network to distinguish essential gait traits from standard RGB videos taken using a single-lens camera. Our findings suggest that this approach outperforms earlier methods in precisely detecting critical gait features (such as walking pace, gait deviation index, and maximum knee bend angle) in a publicly available database of cerebral palsy cases, without the requirement for manual intervention or substantial resources."
        ],
        [
            "Individuals dealing with musculoskeletal problems and cognitive challenges may encounter mobility challenges, which could potentially harm their mental well-being. It is crucial to tackle these complications prior to their occurrence. Clinical gait analysis presents a viable solution for surmounting mobility barriers. Historically, this method depended on costly optical motion capture systems. However, innovations in computer vision and deep learning have led to more economical and accessible alternatives. In our research, we propose implementing a complex spatio-temporal transformer network to discern key gait characteristics from standard RGB videos captured using a single-lens camera. Our study indicates that this method surpasses previous techniques in accurately identifying vital gait features (including walking speed, gait deviation index, and maximum knee bend angle) in a publicly accessible database of cerebral palsy cases, without the necessity for human intervention or significant investment."
        ],
        [
            "People with musculoskeletal issues and cognitive difficulties may face mobility hurdles that could negatively impact their mental health. Preventing these complications before they arise is essential. Clinical gait analysis offers a promising approach to overcoming mobility obstacles. Traditionally, this technique relied on expensive optical motion capture systems. However, advances in computer vision and deep learning have brought about more affordable and accessible alternatives. In our study, we suggest employing a sophisticated spatio-temporal transformer network to distinguish essential gait traits from standard RGB videos taken with a single-lens camera. Our findings suggest that this method outperforms earlier techniques in precisely detecting critical gait features (like walking speed, gait deviation index, and maximum knee bend angle) in a publicly available database of cerebral palsy cases, without requiring human intervention or substantial investment."
        ],
        [
            "Individuals dealing with musculoskeletal problems and cognitive challenges might encounter mobility barriers that could adversely affect their psychological well-being. It's crucial to prevent these complications from developing. Clinical gait analysis presents a viable solution for surmounting mobility challenges. Historically, this methodology utilized expensive optical motion capture systems. However, advancements in computer vision and deep learning have led to more budget-friendly and accessible alternatives. In our investigation, we propose utilizing a complex spatio-temporal transformer network to distinguish significant gait characteristics from standard RGB videos captured using a single-lens camera. Our research indicates that this technique excels over earlier methods in accurately identifying crucial gait attributes (such as walking speed, gait deviation index, and maximum knee bend angle) in a publicly accessible database of cerebral palsy cases, without necessitating human intervention or significant funding."
        ],
        [
            "People with musculoskeletal issues and cognitive difficulties may face mobility obstacles that negatively impact their mental health. It's important to prevent these complications from arising. Clinical gait analysis offers a potential solution for overcoming mobility hurdles. Traditionally, this approach relied on expensive optical motion capture systems. However, advancements in computer vision and deep learning have resulted in more affordable and accessible alternatives. In our study, we suggest employing a sophisticated spatio-temporal transformer network to identify significant gait features from standard RGB videos recorded using a single-lens camera. Our findings suggest that this method outperforms previous techniques in accurately detecting key gait characteristics (including walking speed, gait deviation index, and maximum knee bend angle) in a publicly available database of cerebral palsy cases, without requiring human involvement or substantial financial resources."
        ],
        [
            "Individuals dealing with musculoskeletal problems and cognitive challenges might encounter mobility barriers that adversely affect their psychological well-being. To prevent such complications, clinical gait analysis could be a viable option for surmounting mobility challenges. Historically, this method utilized costly optical motion capture systems. However, advancements in computer vision and deep learning have led to more budget-friendly and accessible alternatives. In our research, we propose using a sophisticated spatio-temporal transformer network to extract significant gait traits from standard RGB videos recorded using a single-lens camera. Our results indicate that this approach surpasses prior methods in accurately identifying essential gait attributes (such as walking speed, gait deviation index, and maximum knee bend angle) in a publicly accessible database of cerebral palsy cases, without the need for human intervention or substantial financial investment."
        ],
        [
            "People experiencing musculoskeletal issues and cognitive difficulties may face mobility hurdles that negatively impact their psychological health. To address these complications, clinical gait analysis could be an effective solution for overcoming mobility obstacles. Traditionally, this technique relied on expensive optical motion capture systems. However, technological advances in computer vision and deep learning have produced more affordable and accessible alternatives. In our study, we suggest employing a complex spatio-temporal transformer network to extract key gait features from standard RGB videos captured using a single-lens camera. Our findings suggest that this method outperforms previous techniques in precisely identifying crucial gait characteristics (such as walking speed, gait deviation index, and maximum knee flexion angle) in a publicly accessible database of cerebral palsy cases, without requiring human involvement or significant financial resources."
        ],
        [
            "Individuals dealing with musculoskeletal problems and cognitive challenges might encounter mobility challenges that can adversely affect their mental well-being. To tackle these complexities, clinical gait analysis may prove beneficial in surmounting mobility barriers. Originally, this methodology depended on pricey optical motion capture systems. However, advancements in computer vision and deep learning technology have generated more budget-friendly and accessible alternatives. In our research, we propose utilizing a sophisticated spatio-temporal transformer network to isolate essential gait characteristics from regular RGB videos obtained via a single-lens camera. Our results indicate that this approach surpasses earlier techniques in accurately identifying essential gait attributes (for instance, walking speed, gait deviation index, and maximum knee flexion angle) in a publicly available database of cerebral palsy cases, without necessitating human intervention or substantial financial investment."
        ],
        [
            "People experiencing musculoskeletal issues and cognitive difficulties may face mobility complications that negatively impact their mental health. Clinical gait analysis can help overcome these intricacies by providing insights into mobility barriers. Initially, this technique relied on expensive optical motion capture systems. However, advancements in computer vision and deep learning technology have produced more affordable and accessible options. In our study, we suggest employing a sophisticated spatio-temporal transformer network to extract vital gait features from standard RGB videos captured using a single-lens camera. Our findings suggest that this method outperforms previous techniques in accurately detecting essential gait features (such as walking speed, gait deviation index, and maximum knee flexion angle) from a publicly available database of cerebral palsy cases, without requiring human intervention or significant financial investment."
        ],
        [
            "Individuals dealing with musculoskeletal problems and cognitive challenges may encounter complexities in mobility that can adversely affect their psychological well-being. Clinical gait analysis serves as a valuable tool in addressing these intricacies by shedding light on mobility restrictions. Initially, this method was dependent on costly optical motion capture systems. However, advancements in computer vision and deep learning technology have led to the development of more budget-friendly and accessible alternatives. In our research, we propose using an advanced spatio-temporal transformer network to extract crucial gait characteristics from regular RGB videos captured using a single-lens camera. Our study indicates that this approach surpasses earlier techniques in precisely identifying critical gait features (like walking speed, gait deviation index, and maximum knee flexion angle) from a publicly accessible database of cerebral palsy cases, all without the need for human involvement or substantial financial resources."
        ],
        [
            "People with musculoskeletal issues and cognitive difficulties may experience complications in mobility that negatively impact their mental health. Clinical gait analysis is a valuable solution for understanding these complexities by revealing limitations in mobility. Initially, this approach relied on expensive optical motion capture systems. However, advancements in computer vision and deep learning technology have brought about more affordable and accessible alternatives. In our investigation, we suggest employing a sophisticated spatio-temporal transformer network to isolate essential gait traits from standard RGB videos taken using a single-lens camera. Our findings suggest that this technique outperforms previous methods in accurately identifying essential gait features (such as walking speed, gait deviation index, and maximum knee flexion angle) from a publicly accessible database of cerebral palsy cases, without requiring human intervention or significant financial investment."
        ],
        [
            "Individuals dealing with musculoskeletal problems and cognitive challenges may encounter challenges in mobility that can adversely affect their mental well-being. Clinical gait analysis offers valuable insights into these intricacies by highlighting restrictions in mobility. Historically, this strategy depended on pricey optical motion capture systems. However, advancements in computer vision and deep learning technology have resulted in more cost-effective and accessible options. In our research, we propose utilizing an advanced spatio-temporal transformer network to distinguish vital gait characteristics from regular RGB videos captured with a single-lens camera. Our study indicates that this method surpasses earlier techniques in precisely identifying essential gait features (including walking speed, gait deviation index, and maximum knee flexion angle) from a publicly available database of cerebral palsy instances, without necessitating human input or substantial financial resources."
        ],
        [
            "People experiencing musculoskeletal issues and cognitive difficulties may face mobility complications that negatively impact their mental health. Gait analysis in a clinical setting provides essential information regarding these complexities by identifying restrictions in movement. Traditionally, this method relied on expensive optical motion capture systems. However, recent advances in computer vision and deep learning technology have led to more affordable and accessible alternatives. In our investigation, we suggest employing a sophisticated spatio-temporal transformer network to distinguish crucial gait traits from standard RGB videos recorded with a single-lens camera. Our findings suggest that this approach outperforms previous techniques in accurately detecting key gait features (such as walking speed, gait deviation index, and maximum knee flexion angle) from a publicly accessible database of cerebral palsy cases, without requiring human intervention or significant financial investment."
        ],
        [
            "Individuals dealing with musculoskeletal problems and cognitive challenges may encounter mobility complications that have detrimental effects on their psychological well-being. Gait analysis conducted in a clinical setting is vital in understanding these intricacies, as it highlights restrictions in motion. Historically, this approach relied on costly optical motion capture systems. However, advancements in computer vision and deep learning technology have given rise to more economical and accessible alternatives. In our study, we propose implementing a sophisticated spatio-temporal transformer network to discern critical gait characteristics from standard RGB videos captured using a single-lens camera. Our results indicate that this method surpasses past techniques in accurately recognizing key gait attributes (such as walking pace, gait deviation index, and maximum knee bend angle) from a publicly accessible database of cerebral palsy cases, without necessitating human involvement or substantial financial commitment."
        ],
        [
            "People with musculoskeletal issues and cognitive difficulties may experience mobility complications that negatively impact their psychological health. Gait analysis carried out in a medical setting is essential for identifying these complexities, as it reveals limitations in movement. Traditionally, this technique depended on expensive optical motion capture systems. However, recent advancements in computer vision and deep learning technology have led to more affordable and accessible alternatives. In our research, we suggest employing a complex spatio-temporal transformer network to distinguish crucial gait features from regular RGB videos recorded using a single-lens camera. Our findings suggest that this approach outperforms previous methods in precisely identifying essential gait traits (like walking speed, gait deviation index, and maximum knee bend angle) from a publicly available database of cerebral palsy instances, without requiring human intervention or significant financial investment."
        ],
        [
            "Individuals dealing with musculoskeletal problems and cognitive challenges may encounter complications in mobility that can adversely affect their psychological well-being. Thorough assessment of gait is crucial in medical settings to identify these intricacies, as it uncovers restrictions in movement. In the past, this assessment relied heavily on pricey optical motion capture systems. However, recent innovations in computer vision and deep learning technology have paved the way for more cost-effective and accessible alternatives. In our study, we propose utilizing a sophisticated spatio-temporal transformer network to distinguish vital gait characteristics from standard RGB videos captured by a single-lens camera. Our results indicate that this method surpasses earlier techniques in accurately pinpointing critical gait attributes (such as walking speed, gait deviation index, and maximum knee bend angle) from a publicly accessible database of cerebral palsy cases, without necessitating human involvement or substantial financial commitment."
        ],
        [
            "People with musculoskeletal issues and cognitive difficulties may experience mobility complications that negatively impact their psychological health. Accurately evaluating gait is essential in healthcare settings to detect these intricacies, as it reveals limitations in movement. Traditionally, this assessment depended on costly optical motion capture systems. However, advancements in computer vision and deep learning technology have led to more affordable and accessible options. Our research suggests employing a complex spatio-temporal transformer network to identify key gait features from standard RGB videos taken by a single-lens camera. Our findings show that this technique outperforms earlier methods in precisely identifying essential gait characteristics (like walking speed, gait deviation index, and maximum knee bend angle) from a publicly available database of cerebral palsy cases, without requiring human intervention or significant financial investment."
        ],
        [
            "Individuals dealing with musculoskeletal problems and cognitive challenges may encounter complexities in mobility that can adversely affect their psychological well-being. Assessing gait accurately is crucial in healthcare environments to uncover these subtle complexities, as it highlights restrictions in movement. In the past, this evaluation relied on expensive optical motion capture systems. However, advancements in computer vision and deep learning technology have brought about more economical and accessible alternatives. Based on our research, we propose using a sophisticated spatio-temporal transformer network to extract critical gait traits from standard RGB videos recorded using a single-lens camera. Our study indicates that this method surpasses earlier approaches in accurately identifying vital gait features (such as walking speed, gait deviation index, and maximum knee bend angle) from a publicly accessible database of cerebral palsy instances, without the need for human intervention or substantial financial resources."
        ],
        [
            "People with musculoskeletal issues and cognitive difficulties may experience complications in mobility that negatively impact their mental health. Precisely measuring gait is essential in healthcare settings to reveal these intricacies, as it reveals limitations in movement. Previously, this analysis depended on costly optical motion capture systems. Nevertheless, advancements in computer vision and deep learning technology have given rise to more affordable and accessible alternatives. According to our investigation, employing an advanced spatio-temporal transformer network could extract essential gait characteristics from common RGB videos taken using a single-lens camera. Our findings suggest that this approach surpasses earlier methods in accurately detecting significant gait features (like walking speed, gait deviation index, and maximum knee flexion angle) from a publicly accessible database of cerebral palsy cases, without the necessity for human intervention or substantial financial resources."
        ],
        [
            "Individuals dealing with musculoskeletal problems and cognitive challenges may encounter challenges in mobility that can adversely affect their mental wellbeing. Assessing gait accurately is crucial in healthcare settings as it highlights intricacies in movement that might be overlooked otherwise. Traditionally, this assessment relied on expensive optical motion capture systems. However, recent advancements in computer vision and deep learning technology have brought more cost-effective and accessible alternatives. Based on our research, utilizing an advanced spatio-temporal transformer network could extract vital gait features from standard RGB videos captured using a single-lens camera. Our study indicates that this method outperforms earlier techniques in accurately identifying significant gait features (such as walking speed, gait deviation index, and maximum knee flexion angle) from a publicly available database of cerebral palsy cases, without requiring human intervention or substantial investments."
        ]
    ]
}