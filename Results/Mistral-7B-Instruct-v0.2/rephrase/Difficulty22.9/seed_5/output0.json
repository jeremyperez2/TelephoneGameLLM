{
    "adjacency_matrix": [
        [
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0,
            0.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0,
            1.0
        ],
        [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.0
        ]
    ],
    "prompt_init": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "prompt_update": [
        "You will receive a text. Your task is to rephrase this text without modifying its meaning. Just output your new text, nothing else. Here is the text:"
    ],
    "personality_list": [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        ""
    ],
    "format_prompt": [
        ""
    ],
    "initial_story": "musculoskeletal diseases and cognitive impairments in patients lead todifficulties in movement as well as negative effects on their psychologicalhealth. clinical gait analysis, a vital tool for early diagnosis and treatment,traditionally relies on expensive optical motion capture systems. recentadvances in computer vision and deep learning have opened the door to moreaccessible and cost-effective alternatives. this paper introduces a novelspatio-temporal transformer network to estimate critical gait parameters fromrgb videos captured by a single-view camera. empirical evaluations on a publicdataset of cerebral palsy patients indicate that the proposed frameworksurpasses current state-of-the-art approaches and show significant improvementsin predicting general gait parameters (including walking speed, gait deviationindex - gdi, and knee flexion angle at maximum extension), while utilizingfewer parameters and alleviating the need for manual feature extraction. ",
    "stories": [
        [
            "Patients dealing with musculoskeletal conditions and cognitive impairments face challenges in movement, resulting in both physical and psychological issues. Accurately diagnosing and treating these conditions early is crucial. Traditionally, clinical gait analysis, an essential diagnostic tool, has relied on high-cost optical motion capture systems. However, advancements in computer vision and deep learning offer more accessible and affordable alternatives. This study presents a new spatio-temporal transformer network to assess essential gait characteristics from RGB videos captured using a single-view camera. Preliminary tests on a publicly available dataset of cerebral palsy patients suggest that this framework outperforms current methods and delivers substantial enhancements in estimating general gait parameters (such as walking speed, gait deviation index - GDI, and maximum knee extension angle), all while requiring fewer parameters and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals grappling with musculoskeletal disorders and cognitive impairments encounter difficulties in mobility, leading to a host of physical and emotional problems. Early and precise diagnosis and treatment of these conditions are vital. Conventional clinical gait analysis, a critical diagnostic method, has depended on costly optical motion capture systems. However, advancements in computer vision and deep learning provide more economical and user-friendly alternatives. This research introduces a novel spatio-temporal transformer network to evaluate fundamental gait attributes from RGB videos captured using a standard camera. Preliminary findings on a publicly accessible dataset of cerebral palsy patients indicate that this model surpasses existing methods and significantly enhances the estimation of fundamental gait parameters (like walking speed, gait deviation index - GDI, and maximum knee extension angle), with fewer parameters and without the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal disorders and cognitive impairments face challenges in moving around, resulting in a range of physical and emotional issues. Accurate and timely diagnosis and treatment of these conditions are essential. Traditional clinical gait analysis, an essential diagnostic tool, has relied on expensive optical motion capture systems. However, innovations in computer vision and deep learning offer more affordable and convenient options. This study presents a new spatio-temporal transformer network to assess fundamental gait characteristics from RGB videos taken with a standard camera. Preliminary results on a publicly available dataset of cerebral palsy patients suggest that this model outperforms current methods and significantly improves the evaluation of fundamental gait attributes (such as walking speed, gait deviation index - GDI, and maximum knee extension angle), using fewer parameters and without requiring manual feature extraction."
        ],
        [
            "Individuals dealing with musculoskeletal disorders and cognitive impairments encounter difficulties in mobility, leading to a array of physical and emotional problems. Early and precise identification and management of these conditions are crucial. Conventional clinical gait analysis, a vital diagnostic method, has depended on costly optical motion capture systems. Nevertheless, advancements in computer vision and deep learning present more economical and accessible alternatives. The following research introduces a novel spatio-temporal transformer network to evaluate basic gait traits from RGB videos captured using a standard camera. Preliminary findings based on a publicly accessible dataset of cerebral palsy patients indicate that this model surpasses existing techniques and enhances the assessment of fundamental gait attributes (for instance, walking speed, gait deviation index - GDI, and maximum knee extension angle), utilizing fewer parameters and excluding manual feature extraction."
        ],
        [
            "People with musculoskeletal disorders and cognitive impairments face challenges in moving around, resulting in a range of physical and emotional issues. It is essential to identify and manage these conditions as early and accurately as possible. Traditional clinical gait analysis, a crucial diagnostic method, has relied on expensive optical motion capture systems. However, advancements in computer vision and deep learning offer more affordable and accessible alternatives. The following study presents a new spatio-temporal transformer network to assess fundamental gait characteristics from RGB videos captured using a regular camera. Preliminary results from a publicly available dataset of cerebral palsy patients suggest that this model outperforms existing methods and improves the evaluation of fundamental gait features (such as walking speed, gait deviation index - GDI, and maximum knee extension angle), using fewer parameters and eliminating manual feature extraction."
        ],
        [
            "Individuals dealing with musculoskeletal disorders and cognitive impairments encounter difficulties in mobility, leading to various physical and emotional complications. Early and precise identification and management of these conditions are crucial. Conventional clinical gait analysis, an essential diagnostic tool, has relied on costly optical motion capture systems. However, progress in computer vision and deep learning provides more cost-effective and accessible alternatives. The ensuing research introduces a new spatio-temporal transformer network to assess essential gait attributes from RGB videos recorded using a standard camera. Preliminary findings from a publicly accessible dataset of cerebral palsy patients indicate that this model surpasses existing methods and enhances the assessment of fundamental gait features (including walking speed, gait deviation index - GDI, and maximum knee extension angle), with fewer parameters and no need for manual feature extraction."
        ],
        [
            "People with musculoskeletal disorders and cognitive impairments face challenges in moving around, resulting in multiple physical and emotional problems. It is important to identify and manage these conditions as early and accurately as possible. Traditional clinical gait analysis, a valuable diagnostic method, has primarily utilized expensive optical motion capture systems. However, advancements in computer vision and deep learning offer more affordable and convenient alternatives. This study presents a novel spatio-temporal transformer network to evaluate essential gait characteristics from RGB videos obtained using a standard camera. Preliminary data from a publicly available dataset of cerebral palsy patients suggest that this model outperforms existing techniques and improves the evaluation of fundamental gait aspects (such as walking speed, gait deviation index - GDI, and maximum knee extension angle), with fewer model parameters and no requirement for manual feature extraction."
        ],
        [
            "Individuals dealing with musculoskeletal disorders and cognitive impairments encounter difficulties in mobilizing, leading to a range of physical and emotional issues. Early and precise identification and management of these conditions are crucial. Conventional clinical gait analysis, a valuable diagnostic tool, has relied predominantly on costly optical motion capture systems. However, the progress in computer vision and deep learning provides more economical and accessible alternatives. This research introduces a new spatio-temporal transformer network to assess essential gait features from RGB videos captured using a regular camera. Preliminary findings from a publicly accessible dataset of cerebral palsy patients indicate that this model surpasses current methods and enhances the assessment of essential gait features (such as walking speed, gait deviation index - GDI, and maximum knee extension angle), with fewer model parameters and no need for manual feature extraction."
        ],
        [
            "People with musculoskeletal disorders and cognitive impairments face challenges in moving around, resulting in a variety of physical and emotional problems. Timely and accurate recognition and treatment of these conditions are essential. Traditional clinical gait analysis, an essential diagnostic method, has largely depended on expensive optical motion capture systems. However, advancements in computer vision and deep learning offer more affordable and accessible alternatives. This study presents a novel spatio-temporal transformer network to evaluate crucial gait characteristics from RGB videos recorded with a standard camera. Preliminary data from a publicly available dataset of cerebral palsy patients suggest that this model outperforms existing techniques and improves the evaluation of essential gait features (like walking speed, gait deviation index - GDI, and maximum knee extension angle), with fewer model components and no requirement for manual feature extraction."
        ],
        [
            "Individuals dealing with musculoskeletal disorders and cognitive impairments encounter difficulties in mobility, leading to a range of physical and emotional issues. Early and precise identification and treatment of these conditions are vital. Conventional clinical gait analysis, a crucial diagnostic method, has relied heavily on costly optical motion capture systems. Nevertheless, advancements in computer vision and deep learning provide more affordable and accessible alternatives. The following study introduces a new spatio-temporal transformer network to assess vital gait characteristics from RGB videos captured using a standard camera. Preliminary findings from a publicly available dataset of cerebral palsy patients indicate that this model surpasses existing methods and enhances the assessment of essential gait features (such as walking speed, gait deviation index - GDI, and maximum knee extension angle), with fewer model elements and no need for manual feature extraction."
        ],
        [
            "People with musculoskeletal disorders and cognitive impairments face challenges in moving around, resulting in various physical and emotional problems. Accurately identifying and addressing these conditions at an early stage is crucial. Traditional clinical gait analysis, an essential diagnostic tool, has depended mainly on expensive optical motion capture systems. However, advancements in computer vision and deep learning offer more affordable and accessible solutions. In this study, a novel spatio-temporal transformer network is presented for evaluating crucial gait features from standard RGB videos taken with a regular camera. Preliminary results from a publicly accessible dataset of cerebral palsy patients suggest that this model outperforms existing techniques and improves the analysis of vital gait characteristics (like walking speed, gait deviation index - GDI, and maximum knee extension angle), using fewer model components and eliminating the requirement for manual feature extraction."
        ],
        [
            "Individuals dealing with musculoskeletal disorders and cognitive impairments encounter difficulties in mobility, leading to a range of physical and emotional issues. Early identification and treatment of these conditions are vital. Conventional clinical gait analysis, a critical diagnostic method, has relied predominantly on costly optical motion capture systems. However, advancements in computer vision and deep learning provide more affordable and accessible alternatives. In this research, a new spatio-temporal transformer network is proposed for assessing crucial gait characteristics from standard RGB videos recorded with a common camera. Preliminary findings from a publicly available dataset of cerebral palsy patients indicate that this model surpasses existing methods and enhances the evaluation of essential gait features (such as walking speed, gait deviation index - GDI, and maximum knee extension angle), utilizing fewer model components and obviating the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal disorders and cognitive impairments face challenges in moving around, resulting in various physical and emotional problems. prompt identification and treatment of these conditions are essential. Traditional clinical gait analysis, an important diagnostic tool, has largely depended on expensive optical motion capture systems. However, recent progress in computer vision and deep learning offers more economical and convenient options. In this study, we suggest a novel spatio-temporal transformer network for analyzing vital gait features from standard RGB videos recorded with an ordinary camera. Preliminary results from a publicly accessible dataset of cerebral palsy patients suggest that this model outperforms existing approaches and improves the assessment of crucial gait characteristics (like walking speed, gait deviation index - GDI, and maximum knee extension angle), using fewer model elements and eliminating the requirement for manual feature extraction."
        ],
        [
            "Individuals dealing with musculoskeletal disorders and cognitive impairments encounter difficulties in mobility, leading to diverse physical and emotional issues. Early recognition and care for these conditions are crucial. Conventional clinical gait analysis, a valuable diagnostic method, has mainly relied on costly optical motion capture systems. However, advances in computer vision and deep learning present more affordable and practical alternatives. In our study, we propose a new spatio-temporal transformer network for evaluating essential gait traits from regular RGB videos taken with a standard camera. Preliminary findings from a publicly available dataset of cerebral palsy patients indicate that this model surpasses current techniques and enhances the evaluation of significant gait attributes (such as walking speed, Gait Deviation Index - GDI, and maximum knee extension angle), using fewer model components and eliminating the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal disorders and cognitive impairments face challenges in moving around, resulting in various physical and emotional complications. Recognizing and addressing these conditions at an early stage is essential. Traditional clinical gait analysis, an essential diagnostic tool, has primarily depended on expensive optical motion capture systems. However, advancements in computer vision and deep learning offer more budget-friendly and convenient options. In our research, we suggest employing a novel spatio-temporal transformer network to assess vital gait characteristics from standard RGB videos captured using a regular camera. Preliminary results from a publicly accessible dataset of cerebral palsy patients suggest that this model surpasses existing methods and improves the assessment of essential gait attributes (e.g., walking speed, Gait Deviation Index - GDI, and maximum knee extension angle), utilizing fewer model elements and eliminating the necessity for manual feature extraction."
        ],
        [
            "Individuals dealing with musculoskeletal disorders and cognitive impairments encounter difficulties in mobility, leading to diverse physical and emotional consequences. Early identification and treatment of these conditions are crucial. Traditional gait analysis, a key diagnostic method, has relied heavily on pricey optical motion capture systems. However, recent developments in computer vision and deep learning present more affordable and convenient alternatives. In our study, we propose utilizing a new spatio-temporal transformer network to evaluate significant gait features from standard RGB videos obtained using a standard camera. Preliminary findings from a publicly available dataset of cerebral palsy patients indicate that this model outperforms existing techniques and enhances the evaluation of essential gait characteristics (such as walking speed, Gait Deviation Index - GDI, and maximum knee extension angle), while requiring fewer model components and eliminating the requirement for manual feature extraction."
        ],
        [
            "People with musculoskeletal issues and cognitive impairments face challenges in moving around, resulting in various physical and emotional repercussions. Timely recognition and treatment of these conditions are vital. Conventional gait analysis, which is an essential diagnostic approach, has primarily relied on expensive optical motion capture systems. However, advancements in computer vision and deep learning offer more budget-friendly and convenient solutions. In our research, we suggest employing a novel spatio-temporal transformer network to assess key gait attributes from regular RGB videos recorded with a standard camera. Preliminary results from a publicly accessible dataset of cerebral palsy patients suggest that this model surpasses existing methods and improves the assessment of vital gait features (like walking speed, Gait Deviation Index - GDI, and maximum knee flexion angle), while using fewer model elements and omitting the need for manual characteristic extraction."
        ],
        [
            "Individuals dealing with musculoskeletal problems and cognitive impairments encounter difficulties in mobility, leading to both physical and emotional consequences. Early identification and treatment of these conditions are crucial. Traditional gait analysis, a crucial diagnostic method, has mainly depended on costly optical motion capture systems. However, progress in computer vision and deep learning provides more affordable and practical alternatives. In our study, we propose utilizing a new spatio-temporal transformer network to evaluate essential gait characteristics from standard RGB videos captured with a regular camera. Preliminary findings from a publicly accessible dataset of cerebral palsy patients indicate that this model exceeds current methods and enhances the evaluation of essential gait features (such as walking speed, Gait Deviation Index - GDI, and maximum knee flexion angle), while using fewer model components and eliminating the requirement for manual feature extraction."
        ],
        [
            "People with musculoskeletal issues and cognitive impairments face challenges in moving around, resulting in physical and emotional repercussions. prompt diagnosis and treatment of these conditions are essential. Conventional gait analysis, a vital diagnostic tool, has largely relied on expensive optical motion capture systems. However, advancements in computer vision and deep learning offer more cost-effective and practical options. In our research, we suggest employing a new spatio-temporal transformer network to assess vital gait features from typical RGB videos captured using a standard camera. Preliminary results from a publicly available dataset of cerebral palsy patients suggest that this model surpasses existing methods and enhances the assessment of essential gait attributes (such as walking speed, Gait Deviation Index - GDI, and maximum knee flexion angle), while requiring fewer model components and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals dealing with musculoskeletal problems and cognitive impairments encounter difficulties in mobilizing, leading to both physical and emotional consequences. Early identification and treatment of these conditions are crucial. Traditional gait analysis, a crucial diagnostic method, has primarily utilized expensive optical motion capture systems. However, recent advancements in computer vision and deep learning present more economical and convenient alternatives. In our study, we propose utilizing a novel spatio-temporal transformer network to evaluate crucial gait characteristics from regular RGB videos captured using a standard camera. Preliminary findings from a publicly accessible dataset of cerebral palsy patients indicate that this model outperforms current techniques and improves the evaluation of essential gait attributes (including walking speed, Gait Deviation Index - GDI, and maximum knee flexion angle), while reducing the number of required model components and eliminating the necessity for manual feature extraction."
        ],
        [
            "People facing musculoskeletal issues and cognitive impairments experience challenges in moving around, resulting in physical and emotional repercussions. Swift identification and treatment of these conditions are essential. Conventional gait analysis, a vital diagnostic approach, has predominantly relied on costly optical motion capture systems. However, advances in computer vision and deep learning offer more affordable and practical alternatives. In our research, we suggest employing a novel spatio-temporal transformer network to assess vital gait features from standard RGB videos captured using an ordinary camera. Preliminary data from a publicly accessible dataset of cerebral palsy patients suggest that this model surpasses current methods and enhances the assessment of essential gait characteristics (such as walking speed, Gait Deviation Index - GDI, and maximum knee flexion angle), all while diminishing the quantity of model components and removing the need for manual feature extraction."
        ],
        [
            "Individuals dealing with musculoskeletal problems and cognitive impairments encounter difficulties in navigating, leading to both physical and emotional consequences. Early detection and treatment of these conditions are crucial. Traditional gait analysis, a key diagnostic method, has mainly depended on expensive optical motion capture systems. Nevertheless, progress in computer vision and deep learning delivers more economical and convenient options. In our study, we propose utilizing a new spatio-temporal transformer network to evaluate crucial gait elements from standard RGB videos recorded using a basic camera. Preliminary results from a publicly available dataset of cerebral palsy patients indicate that this model outperforms existing techniques and improves the evaluation of essential gait features (like walking speed, Gait Deviation Index - GDI, and maximum knee flexion angle), all while reducing the model's complexity and eliminating the need for manual feature extraction."
        ],
        [
            "People facing musculoskeletal issues and cognitive impairments experience challenges in getting around, resulting in both physical and emotional repercussions. The importance of early detection and treatment for these conditions cannot be overstated. Conventional gait analysis, which is a vital diagnostic tool, has relied predominantly on costly optical motion capture systems. However, advancements in computer vision and deep learning provide more affordable and practical alternatives. In our research, we suggest employing a novel spatio-temporal transformer network to assess critical gait components from standard RGB videos taken using a simple camera. Preliminary findings from a publicly accessible dataset of cerebral palsy patients demonstrate that this model surpasses current methods and enhances the assessment of significant gait features (such as walking speed, Gait Deviation Index - GDI, and maximum knee flexion angle), all while decreasing the model's intricacy and dispensing with the need for manual characteristic extraction."
        ],
        [
            "Individuals dealing with musculoskeletal problems and cognitive impairments encounter difficulties in mobility, leading to physical and emotional consequences. The significance of identifying and addressing these conditions at an early stage is paramount. Traditional gait analysis, a crucial diagnostic method, has largely relied on expensive optical motion capture systems. Nevertheless, innovations in computer vision and deep learning offer more economical and user-friendly options. In our study, we propose utilizing a novel spatio-temporal transformer network to evaluate essential gait elements from common RGB videos recorded using a basic camera. Preliminary results from a publicly accessible dataset of cerebral palsy patients indicate that this model outperforms existing techniques and improves the evaluation of key gait characteristics (including walking speed, Gait Deviation Index - GDI, and maximum knee flexion angle), all while reducing the model's complexity and eliminating the requirement for manual feature extraction."
        ],
        [
            "People with musculoskeletal issues and cognitive impairments face challenges in moving around, resulting in both physical and emotional repercussions. Early recognition and treatment of these conditions are essential. Conventional gait analysis, an essential diagnostic tool, has mainly depended on pricey optical motion capture systems. However, advancements in computer vision and deep learning present more affordable and user-friendly alternatives. In our research, we suggest employing a new spatio-temporal transformer network to assess fundamental gait features from routine RGB videos taken with a standard camera. Preliminary findings from a publicly available dataset of cerebral palsy patients suggest that this model surpasses current methods and enhances the assessment of crucial gait traits (such as walking speed, Gait Deviation Index - GDI, and maximum knee flexion angle), all while decreasing the model's intricacy and omitting the need for manual attribute extraction."
        ],
        [
            "Individuals dealing with musculoskeletal problems and cognitive impairments encounter difficulties in mobility, leading to physical and emotional consequences. timely identification and intervention of these conditions are crucial. Traditional gait analysis, an essential diagnostic technique, has primarily relied on expensive optical motion capture systems. However, advancements in computer vision and deep learning offer more affordable and user-friendly options. In our study, we propose utilizing a novel spatio-temporal transformer network to evaluate fundamental gait characteristics from common RGB videos captured using a standard camera. Preliminary results from a publicly accessible dataset of cerebral palsy patients indicate that this model outperforms existing methods and enhances the evaluation of essential gait characteristics (such as walking speed, Gait Deviation Index - GDI, and maximum knee flexion angle), all while reducing the model's complexity and eliminating the requirement for manual attribute extraction."
        ],
        [
            "People experiencing mobility issues due to musculoskeletal problems and cognitive impairments face both physical and emotional challenges. Early detection and treatment of these conditions are vital. Conventionally, gait analysis, a crucial diagnostic method, has largely depended on costly optical motion capture systems. However, recent advancements in computer vision and deep learning provide more affordable and user-friendly alternatives. In our research, we suggest employing a novel spatio-temporal transformer network to assess fundamental gait features from standard RGB videos captured with a regular camera. Preliminary findings from a publicly accessible dataset of cerebral palsy patients suggest that this model surpasses current methods and improves the assessment of essential gait characteristics (such as walking speed, Gait Deviation Index - GDI, and maximum knee flexion angle), while simultaneously simplifying the model and eliminating the need for manual attribute extraction."
        ],
        [
            "Individuals dealing with mobility concerns caused by musculoskeletal disorders and cognitive impairments encounter physical and emotional hurdles. It is crucial to identify and address these conditions as early as possible. Traditionally, gait analysis, a vital diagnostic tool, has relied heavily on expensive optical motion capture systems. However, progress in computer vision and deep learning offers more affordable and accessible solutions. In our study, we propose utilizing a new spatio-temporal transformer network to evaluate fundamental gait characteristics from standard RGB videos taken with a conventional camera. Preliminary results from a publicly available dataset of cerebral palsy patients indicate that this model outperforms existing methods and enhances the evaluation of essential gait attributes (such as walking pace, Gait Deviation Index - GDI, and maximum knee flexion angle), all while streamlining the model and eliminating the requirement for manual attribute extraction."
        ],
        [
            "People with mobility issues resulting from musculoskeletal disorders and cognitive impairments face both physical and emotional challenges. Early identification and treatment of these conditions are essential. Gait analysis, an essential diagnostic method, has historically relied on costly optical motion capture systems. However, advancements in computer vision and deep learning provide more budget-friendly and accessible alternatives. In our research, we suggest employing a novel spatio-temporal transformer network to assess fundamental gait features from standard RGB videos captured using a regular camera. Preliminary data from a publicly accessible dataset of cerebral palsy patients demonstrate that this model surpasses previous techniques and improves the assessment of vital gait attributes (including walking speed, Gait Deviation Index - GDI, and maximum knee flexion angle), all while simplifying the model and dispensing with the need for manual attribute extraction."
        ],
        [
            "Individuals dealing with mobility problems caused by musculoskeletal disorders and cognitive impairments encounter both physical and emotional hurdles. Early recognition and treatment of these health conditions are crucial. Traditionally, gait analysis, a crucial diagnostic approach, has depended on high-priced optical motion capture systems. However, advancements in computer vision and deep learning offer more affordable and accessible options. In our study, we propose using a new spatio-temporal transformer network to evaluate fundamental gait characteristics from typical RGB videos obtained using a standard camera. Preliminary findings from a publicly available dataset of cerebral palsy cases suggest that this model outperforms previous methods and enhances the evaluation of essential gait traits (including walking pace, Gait Deviation Index - GDI, and maximum knee flexion angle), all while streamlining the model and eliminating the requirement for manual attribute extraction."
        ],
        [
            "People facing mobility challenges due to musculoskeletal disorders and cognitive impairments encounter both physical and emotional barriers. Early identification and treatment of these health issues are essential. Historically, gait analysis, a vital diagnostic method, has relied on expensive optical motion capture systems. However, advancements in computer vision and deep learning provide more economical and accessible alternatives. In our research, we suggest utilizing a new spatio-temporal transformer network to assess fundamental gait features from standard RGB videos recorded using a regular camera. Preliminary results from a publicly accessible dataset of cerebral palsy cases indicate that this model surpasses previous techniques and improves the assessment of essential gait characteristics (including walking speed, Gait Deviation Index - GDI, and maximum knee flexion angle), all while simplifying the model and omitting the need for manual attribute extraction."
        ],
        [
            "Individuals with musculoskeletal disorders and cognitive impairments that limit their mobility encounter both practical and emotional obstacles. Identifying and addressing these health concerns as early as possible is crucial. Traditionally, gait analysis, an essential diagnostic method, has required expensive optical motion capture systems. However, recent advancements in computer vision and deep learning offer more affordable and accessible options. In our study, we propose employing a novel spatio-temporal transformer network to evaluate essential gait characteristics from standard RGB videos taken using a standard camera. Preliminary findings from a publicly available dataset of cerebral palsy cases suggest that this model surpasses earlier techniques and enhances the evaluation of crucial gait attributes (such as walking speed, Gait Deviation Index - GDI, and maximum knee flexion angle), all while streamlining the model and eliminating the requirement for manual attribute extraction."
        ],
        [
            "People with musculoskeletal disorders and cognitive limitations affecting their mobility face both functional and emotional challenges. Early identification and management of these health issues are vital. Gait analysis, a key diagnostic method, has historically relied on costly optical motion capture systems. However, progress in computer vision and deep learning now presents more budget-friendly and accessible alternatives. In our research, we suggest utilizing a new spatio-temporal transformer network to assess crucial gait features from regular RGB videos recorded using a standard camera. Preliminary results from a publicly accessible dataset of cerebral palsy patients indicate that this model outperforms previous methods and improves the assessment of vital gait attributes (like walking speed, Gait Deviation Index - GDI, and maximum knee flexion angle), all while simplifying the model and obviating the need for manual attribute extraction."
        ],
        [
            "Individuals dealing with musculoskeletal disorders and cognitive limitations impacting their mobility encounter significant functional and emotional hurdles. The importance of early detection and treatment for these health concerns cannot be overstated. Traditionally, gait analysis, an essential diagnostic technique, has depended on expensive optical motion capture systems. However, advancements in computer vision and deep learning are now providing more affordable and accessible options. In our study, we propose employing a novel spatio-temporal transformer network to extract vital gait characteristics from standard RGB videos captured using a regular camera. Preliminary findings from a publicly shared dataset of cerebral palsy patients suggest that this model surpasses prior approaches and enhances the evaluation of crucial gait attributes (including walking speed, Gait Deviation Index - GDI, and maximum knee flexion angle), all while streamlining the model and eliminating the need for manual attribute extraction."
        ],
        [
            "People with musculoskeletal disorders and mobility limitations due to cognitive impairments face substantial functional and emotional challenges. The significance of identifying and addressing these health issues at an early stage cannot be emphasized enough. Gait analysis, a crucial diagnostic method, has historically relied on costly optical motion capture systems. However, innovations in computer vision and deep learning are now offering more budget-friendly and accessible alternatives. In our research, we suggest utilizing a new spatio-temporal transformer network to isolate essential gait features from standard RGB videos recorded using a common camera. Preliminary results from a publicly accessible dataset of cerebral palsy cases indicate that this model outperforms previous methods and boosts the assessment of critical gait characteristics (including walking pace, Gait Deviation Index - GDI, and maximum knee flexion angle), all while simplifying the model and dispensing with the requirement for manual feature extraction."
        ],
        [
            "Individuals dealing with musculoskeletal disorders and restricted mobility caused by cognitive impairments encounter considerable functional and emotional obstacles. Early identification and treatment of these health concerns are vital. Traditionally, gait analysis, a key diagnostic method, has depended on expensive optical motion capture systems. However, advancements in computer vision and deep learning now provide more affordable and accessible options. In our study, we propose employing a novel spatio-temporal transformer network to extract essential gait features from standard RGB videos captured using a common camera. Preliminary findings from a publicly accessible dataset of cerebral palsy cases suggest that this model surpasses previous techniques and enhances the evaluation of critical gait features (such as walking speed, Gait Deviation Index - GDI, and maximum knee flexion angle), all while streamlining the model and eliminating the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal disorders and mobility limitations caused by cognitive impairments face significant functional and emotional challenges. Identifying and addressing these health issues at an early stage is crucial. Gait analysis, a crucial diagnostic method, has historically relied on costly optical motion capture systems. However, advancements in computer vision and deep learning now offer more affordable and accessible alternatives. In our research, we suggest utilizing a new spatio-temporal transformer network to extract vital gait characteristics from standard RGB videos captured using a standard camera. Preliminary results from a publicly available dataset of cerebral palsy cases indicate that this model surpasses previous methods and improves the assessment of essential gait features, including walking speed, Gait Deviation Index (GDI), and maximum knee flexion angle, all while simplifying the model and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals dealing with musculoskeletal disorders and mobility restrictions resulting from cognitive impairments encounter substantial functional and emotional obstacles. Early identification and treatment of these health concerns are vital. Traditionally, gait analysis, a key diagnostic method, has depended on expensive optical motion capture systems. However, recent progress in computer vision and deep learning provides more economical and accessible options. In our study, we propose employing a new spatio-temporal transformer network to isolate critical gait traits from standard RGB videos recorded using a regular camera. Preliminary findings from a publicly shared dataset of cerebral palsy cases suggest that this model surpasses existing methods and enhances the evaluation of fundamental gait attributes, including walking speed, Gait Deviation Index (GDI), and peak knee flexion angle, all while streamlining the model and removing the necessity for manual feature extraction."
        ],
        [
            "People with musculoskeletal issues and mobility limitations caused by cognitive impairments face significant functional and emotional challenges. Timely identification and treatment of these health problems are essential. Conventionally, gait analysis, an essential diagnostic tool, has relied on costly optical motion capture systems. However, advancements in computer vision and deep learning offer more affordable and accessible alternatives. In our research, we suggest utilizing a new spatio-temporal transformer network to distinguish essential gait characteristics from standard RGB videos captured using an ordinary camera. Preliminary results from a publicly accessible dataset of cerebral palsy cases indicate that this model outperforms current methods and improves the assessment of fundamental gait features, including walking speed, Gait Deviation Index (GDI), and maximum knee flexion angle, all while simplifying the model and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals dealing with musculoskeletal problems and restricted mobility due to cognitive impairments encounter substantial functional and emotional hurdles. Prompt recognition and treatment of these health concerns are crucial. Traditionally, gait analysis, a vital diagnostic method, has depended on pricey optical motion capture systems. However, recent progress in computer vision and deep learning presents more affordable and accessible alternatives. In our study, we propose employing a new spatio-temporal transformer network to discern key gait features from standard RGB videos recorded using a regular camera. Preliminary findings from a publicly available dataset of cerebral palsy instances suggest that this model surpasses existing techniques and enhances the evaluation of fundamental gait traits, like walking speed, Gait Deviation Index (GDI), and maximum knee flexion angle, all while streamlining the model and eliminating the requirement for manual feature extraction."
        ],
        [
            "People with musculoskeletal issues and limited mobility caused by cognitive impairments face significant functional and emotional challenges. Early identification and treatment of these health matters are essential. Gait analysis, a crucial diagnostic approach, has historically relied on expensive optical motion capture systems. However, advancements in computer vision and deep learning offer more affordable and accessible options. In our research, we suggest utilizing a novel spatio-temporal transformer network to identify essential gait characteristics from standard RGB videos recorded using a common camera. Preliminary results from a publicly accessible dataset of cerebral palsy cases indicate that this model outperforms current methods and improves the assessment of fundamental gait features, such as walking speed, Gait Deviation Index (GDI), and maximum knee flexion angle, all while simplifying the model and obviating the need for manual feature extraction."
        ],
        [
            "Individuals dealing with musculoskeletal problems and restricted mobility due to cognitive impairments encounter substantial functional and emotional hurdles. Proactively identifying and addressing these health concerns is imperative. Traditionally, gait analysis, an essential diagnostic method, has relied on costly optical motion capture systems. However, advancements in computer vision and deep learning present more budget-friendly and accessible alternatives. In our study, we propose applying a unique spatio-temporal transformer network to discern crucial gait characteristics from routine RGB videos captured with a typical camera. Preliminary findings from a publicly shared dataset of cerebral palsy instances suggest that this model surpasses existing methods and enhances the evaluation of fundamental gait traits, including walking pace, Gait Deviation Index (GDI), and maximum knee bend angle, all while streamlining the model and eliminating the need for manual characteristic extraction."
        ],
        [
            "People with musculoskeletal issues and limited mobility caused by cognitive impairments face significant functional and emotional challenges. It's crucial to identify and tackle these health concerns in a proactive manner. Gait analysis, a vital diagnostic method, has historically depended on expensive optical motion capture systems. However, recent progress in computer vision and deep learning offers more affordable and accessible options. In our research, we suggest employing a distinctive spatio-temporal transformer network to extract vital gait features from standard RGB videos taken with a common camera. Preliminary results from a publicly available dataset of cerebral palsy cases indicate that this model outperforms existing techniques and improves the assessment of fundamental gait features, including walking speed, Gait Deviation Index (GDI), and maximum knee bend angle, all while simplifying the model and removing the need for manual feature extraction."
        ],
        [
            "Individuals dealing with musculoskeletal problems and restricted mobility resulting from cognitive impairments encounter substantial functional and emotional hurdles. It's essential to address these health matters actively. Traditionally, gait analysis \u2013 an essential diagnostic tool \u2013 has relied on costly optical motion capture systems. However, advances in computer vision and deep learning present more economical and accessible alternatives. In our study, we propose using a unique spatio-temporal transformer network to isolate crucial gait characteristics from standard RGB videos shot with an everyday camera. Preliminary findings from a publicly accessible dataset of cerebral palsy instances suggest that this model surpasses existing methods and enhances the evaluation of fundamental gait attributes, such as walking velocity, Gait Deviation Index (GDI), and maximum knee flexion angle, without complicating the design and eliminating the need for manual attribute extraction."
        ],
        [
            "People experiencing musculoskeletal issues and limited mobility due to cognitive impairments face significant functional and emotional challenges. Actively addressing these health concerns is crucial. Gait analysis, a crucial diagnostic method, has historically depended on expensive optical motion capture systems. However, recent advances in computer vision and deep learning offer more affordable and accessible options. In our research, we suggest implementing a distinctive spatio-temporal transformer network to distinguish essential gait features from standard RGB videos recorded with an everyday camera. Preliminary results from a publicly available dataset of cerebral palsy cases indicate that this model outperforms existing techniques and improves the assessment of fundamental gait traits, including walking speed, Gait Deviation Index (GDI), and maximum knee flexion angle, without adding complexity and eliminating the requirement for manual attribute extraction."
        ],
        [
            "Individuals dealing with musculoskeletal problems and restricted mobility caused by cognitive impairments encounter substantial functional and emotional obstacles. Addressing these health matters is essential. Traditionally, gait analysis, a vital diagnostic method, has relied on costly optical motion capture systems. However, modern advancements in computer vision and deep learning provide more budget-friendly and accessible alternatives. In our study, we propose utilizing a unique spatio-temporal transformer network to distinguish vital gait characteristics from standard RGB videos recorded using a common camera. Preliminary data from a publicly accessible dataset of cerebral palsy cases suggest that this model surpasses existing methods and enhances the evaluation of fundamental gait features, including walking pace, Gait Deviation Index (GDI), and peak knee flexion angle, without increasing intricacy and omitting the need for manual attribute extraction."
        ],
        [
            "People with musculoskeletal issues and limited mobility due to cognitive impairments face significant functional and emotional challenges in their daily lives. It is crucial to address these health concerns. Historically, gait analysis, an essential diagnostic tool, has depended on expensive optical motion capture systems. However, recent progress in computer vision and deep learning offers more economical and accessible solutions. In our research, we suggest employing a distinctive spatio-temporal transformer network to identify essential gait characteristics from standard RGB videos captured with a regular camera. Preliminary findings from a publicly accessible dataset of cerebral palsy cases indicate that this model outperforms existing methods and improves the assessment of fundamental gait traits, such as walking speed, Gait Deviation Index (GDI), and maximum knee flexion angle, without introducing complexity and eliminating the requirement for manual feature extraction."
        ],
        [
            "Individuals dealing with musculoskeletal problems and restricted mobility caused by cognitive impairments encounter substantial functional and emotional hurdles in their daily routines. It is imperative to tackle these health issues. Traditionally, gait analysis, a crucial diagnostic method, has relied on costly optical motion capture systems. However, advances in computer vision and deep learning now present more affordable and accessible alternatives. In our study, we propose utilizing a unique spatio-temporal transformer network to identify vital gait features from standard RGB videos recorded with a conventional camera. Preliminary results from a publicly available dataset of cerebral palsy instances suggest that this model surpasses existing techniques and enhances the evaluation of basic gait attributes, including walking speed, Gait Deviation Index (GDI), and maximum knee flexion angle, without adding complexity and removing the need for manual feature extraction."
        ],
        [
            "People with musculoskeletal issues and mobility limitations due to cognitive impairments face significant functional and emotional challenges in their daily activities. Addressing these health concerns is essential. In the past, gait analysis, an essential diagnostic method, has relied on expensive optical motion capture systems. However, recent progress in computer vision and deep learning offers more affordable and accessible alternatives. In our research, we suggest employing a distinct spatio-temporal transformer network to extract crucial gait features from standard RGB videos obtained using a regular camera. Preliminary findings from a publicly accessible dataset of cerebral palsy cases indicate that this model outperforms existing methods and improves the assessment of fundamental gait characteristics, such as walking speed, Gait Deviation Index (GDI), and maximum knee flexion angle, without increasing complexity and eliminating the need for manual feature extraction."
        ],
        [
            "Individuals dealing with musculoskeletal problems and restricted mobility caused by cognitive impairments encounter considerable functional and emotional hurdles in their daily tasks. It is important to tackle these health matters. Historically, gait analysis, a crucial diagnostic approach, has relied on costly optical motion capture systems. However, advances in computer vision and deep learning provide more economical and accessible alternatives. In our study, we propose utilizing a unique spatio-temporal transformer network to extract vital gait characteristics from standard RGB videos captured using a conventional camera. Preliminary results from a publicly available dataset of cerebral palsy cases suggest that this model surpasses current methods and enhances the evaluation of basic gait attributes, including walking pace, Gait Deviation Index (GDI), and maximum knee flexion angle, without adding complexity and omitting the need for manual feature extraction."
        ]
    ]
}